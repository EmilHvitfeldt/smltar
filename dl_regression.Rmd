# Regression {#dlregression}

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(message = FALSE, warning = FALSE, cache = FALSE, eval = TRUE,
               tidy = "styler", fig.width = 8, fig.height = 5)
suppressPackageStartupMessages(library(tidyverse))
theme_set(theme_light())
options(crayon.enabled = FALSE)
doParallel::registerDoParallel()

## for Julia's local environment
#spacyr::spacy_initialize(condaenv = "r-spacyr", entity = FALSE)
#online <- FALSE

## for GH actions
online <- TRUE
``` 

In this chapter, we will predict continuous values, much like we did in Chapter \@ref(mlregression), but we will use deep learning methods instead of methods such as regularized linear regression. Let's consider a dataset of press releases from the United States Department of Justice (DOJ), which [they release on their website](https://www.justice.gov/news).

```{r doj}
library(tidyverse)

doj_press <- read_csv("data/press_releases.csv.gz")
doj_press
```

We know the `date` that each of these press releases was published, and predicting this date from other characteristics of the press releases, such as the main agency within the DOJ involved, the `title`, and the main `contents` of the press release, is a regression problem.

```{r dojhist, dependson="doj", fig.cap="Distribution of Department of Justice press releases over time"}
library(lubridate)

doj_press %>%
  count(month = floor_date(date, unit = "months"), name = "releases") %>%
  ggplot(aes(month, releases)) +
  geom_area(alpha = 0.8) +
  geom_smooth() +
  labs(x = NULL, y = "Releases per month")
```

This dataset includes all press releases from the DOJ from the beginning of 2009 through July 2018. There is some month-to-month variation and an overall increase in releases, but there is good coverage over the timeframe for which we would like to build a model.

There are `r n_distinct(doj_press$agency)` distinct main agencies associated with these releases, but some press releases have no agency associated with them. A few agencies, such as the Criminal Division, Civil Right Division, and Tax Division, account for many more press releases than other agencies.

```{r agencycounts, dependson="doj", fig.cap="Main agency associated with Department of Justice press releases"}
doj_press %>%
  count(agency) %>%
  slice_max(n, n = 10) %>%
  ggplot(aes(n, fct_reorder(agency, n))) +
  geom_col() +
  labs(x = "Number of press releases", y = NULL)
```

```{block, type = "rmdnote"}
The DOJ press releases are relatively _long_ documents; we will take this into consideration as we build neural network architectures for modeling.
```

```{r agencycounts, dependson="doj", fig.cap="Distribution of character count for Department of Justice press releases"}
doj_press %>%
  ggplot(aes(nchar(contents))) +
  geom_histogram(bins = 25, alpha = 0.8) +
  scale_x_log10(labels = scales::comma_format()) +
  labs(x = "Number of characters per press release",
       y = "Number of press releases")
```

Compared to the documents we built deep learning models for in Chapter \@ref(dlclassification), these press releases are long, with a median character count of `r comma(median(nchar(doj_press$contents), na.rm = TRUE))` for the `contents` of the press releases. We can use deep learning models to model these longer sequences.

Some examples, such as this press release from the end of 2016, are quite short:

> Deputy Attorney General Sally Q. Yates released the following statement after President Obama granted commutation of sentence to 153 individuals: "Today, another 153 individuals were granted commutations by the President.  Over the last eight years, President Obama has given a second chance to over 1,100 inmates who have paid their debt to society.  Our work is ongoing and we look forward to additional announcements from the President before the end of his term."


## A first regression model {#firstdlregression}

```{block, type = "rmdnote"}
As we walk through building a deep learning model, notice which steps are different and which steps are the same now that we use a neural network architecture.
```

Much like all our previous modeling, our first step is to split our data into training and testing sets. We will still use our training set to build models and save the testing set for a final estimate of how our model will perform on new data. It is very easy to overfit deep learning models, so an unbiased estimate of future performance from a test set is more important than ever.

We use `initial_split()` to define the training/testing split, after removing examples that have a `title` but no `contents` in the press release. We will focus mainly on modeling the `contents` in this chapter, althought the title is also text that could be handled in a deep learning model.

```{r dojsplit, dependson="doj"}
library(tidymodels)
set.seed(1234)
doj_split <- doj_press %>%
  filter(!is.na(contents)) %>%
  initial_split()

doj_train <- training(doj_split)
doj_test <- testing(doj_split)
```

There are `r comma(nrow(doj_train))` press releases in the training set and `r comma(nrow(doj_test))` in the testing set.




### Modeling

### Evaluation

## Preprocessing

## putting your layers together

Express difference from classification model.

## Model tuning

## Look at different deep learning architecture

## Full game

All bells and whistles.
<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>References | Supervised Machine Learning for Text Analysis in R</title>
  <meta name="description" content="References | Supervised Machine Learning for Text Analysis in R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="References | Supervised Machine Learning for Text Analysis in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="References | Supervised Machine Learning for Text Analysis in R" />
  <meta name="github-repo" content="EmilHvitfeldt/smltar" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="References | Supervised Machine Learning for Text Analysis in R" />
  
  <meta name="twitter:description" content="References | Supervised Machine Learning for Text Analysis in R" />
  

<meta name="author" content="Emil Hvitfeldt and Julia Silge" />


<meta name="date" content="2021-04-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="appendixbaseline.html"/>

<script src="libs/header-attrs-2.7.10/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/plot_text_explanations-0.1.0/plot_text_explanations.css" rel="stylesheet" />
<script src="libs/plot_text_explanations-binding-0.5.2/plot_text_explanations.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="smltar.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Supervised Machine Learning for Text Analysis in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome to Supervised Machine Learning for Text Analysis in R</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#topics-this-book-will-not-cover"><i class="fa fa-check"></i>Topics this book will not cover</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who is this book for?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#colophon"><i class="fa fa-check"></i>Colophon</a></li>
</ul></li>
<li class="part"><span><b>I Natural Language Features</b></span></li>
<li class="chapter" data-level="1" data-path="language.html"><a href="language.html"><i class="fa fa-check"></i><b>1</b> Language and modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="language.html"><a href="language.html#linguistics-for-text-analysis"><i class="fa fa-check"></i><b>1.1</b> Linguistics for text analysis</a></li>
<li class="chapter" data-level="1.2" data-path="language.html"><a href="language.html#morphology"><i class="fa fa-check"></i><b>1.2</b> A glimpse into one area: morphology</a></li>
<li class="chapter" data-level="1.3" data-path="language.html"><a href="language.html#different-languages"><i class="fa fa-check"></i><b>1.3</b> Different languages</a></li>
<li class="chapter" data-level="1.4" data-path="language.html"><a href="language.html#other-ways-text-can-vary"><i class="fa fa-check"></i><b>1.4</b> Other ways text can vary</a></li>
<li class="chapter" data-level="1.5" data-path="language.html"><a href="language.html#languagesummary"><i class="fa fa-check"></i><b>1.5</b> Summary</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="language.html"><a href="language.html#in-this-chapter-you-learned"><i class="fa fa-check"></i><b>1.5.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tokenization.html"><a href="tokenization.html"><i class="fa fa-check"></i><b>2</b> Tokenization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tokenization.html"><a href="tokenization.html#what-is-a-token"><i class="fa fa-check"></i><b>2.1</b> What is a token?</a></li>
<li class="chapter" data-level="2.2" data-path="tokenization.html"><a href="tokenization.html#types-of-tokens"><i class="fa fa-check"></i><b>2.2</b> Types of tokens</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="tokenization.html"><a href="tokenization.html#character-tokens"><i class="fa fa-check"></i><b>2.2.1</b> Character tokens</a></li>
<li class="chapter" data-level="2.2.2" data-path="tokenization.html"><a href="tokenization.html#word-tokens"><i class="fa fa-check"></i><b>2.2.2</b> Word tokens</a></li>
<li class="chapter" data-level="2.2.3" data-path="tokenization.html"><a href="tokenization.html#tokenizingngrams"><i class="fa fa-check"></i><b>2.2.3</b> Tokenizing by n-grams</a></li>
<li class="chapter" data-level="2.2.4" data-path="tokenization.html"><a href="tokenization.html#lines-sentence-and-paragraph-tokens"><i class="fa fa-check"></i><b>2.2.4</b> Lines, sentence, and paragraph tokens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="tokenization.html"><a href="tokenization.html#where-does-tokenization-break-down"><i class="fa fa-check"></i><b>2.3</b> Where does tokenization break down?</a></li>
<li class="chapter" data-level="2.4" data-path="tokenization.html"><a href="tokenization.html#building-your-own-tokenizer"><i class="fa fa-check"></i><b>2.4</b> Building your own tokenizer</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="tokenization.html"><a href="tokenization.html#tokenize-to-characters-only-keeping-letters"><i class="fa fa-check"></i><b>2.4.1</b> Tokenize to characters, only keeping letters</a></li>
<li class="chapter" data-level="2.4.2" data-path="tokenization.html"><a href="tokenization.html#allow-for-hyphenated-words"><i class="fa fa-check"></i><b>2.4.2</b> Allow for hyphenated words</a></li>
<li class="chapter" data-level="2.4.3" data-path="tokenization.html"><a href="tokenization.html#wrapping-it-in-a-function"><i class="fa fa-check"></i><b>2.4.3</b> Wrapping it in a function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tokenization.html"><a href="tokenization.html#tokenization-for-non-latin-alphabets"><i class="fa fa-check"></i><b>2.5</b> Tokenization for non-Latin alphabets</a></li>
<li class="chapter" data-level="2.6" data-path="tokenization.html"><a href="tokenization.html#tokenization-benchmark"><i class="fa fa-check"></i><b>2.6</b> Tokenization benchmark</a></li>
<li class="chapter" data-level="2.7" data-path="tokenization.html"><a href="tokenization.html#tokensummary"><i class="fa fa-check"></i><b>2.7</b> Summary</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="tokenization.html"><a href="tokenization.html#in-this-chapter-you-learned-1"><i class="fa fa-check"></i><b>2.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stopwords.html"><a href="stopwords.html"><i class="fa fa-check"></i><b>3</b> Stop words</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stopwords.html"><a href="stopwords.html#premadestopwords"><i class="fa fa-check"></i><b>3.1</b> Using premade stop word lists</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="stopwords.html"><a href="stopwords.html#stop-word-removal-in-r"><i class="fa fa-check"></i><b>3.1.1</b> Stop word removal in R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="stopwords.html"><a href="stopwords.html#homemadestopwords"><i class="fa fa-check"></i><b>3.2</b> Creating your own stop words list</a></li>
<li class="chapter" data-level="3.3" data-path="stopwords.html"><a href="stopwords.html#all-stop-word-lists-are-context-specific"><i class="fa fa-check"></i><b>3.3</b> All stop word lists are context-specific</a></li>
<li class="chapter" data-level="3.4" data-path="stopwords.html"><a href="stopwords.html#what-happens-when-you-remove-stop-words"><i class="fa fa-check"></i><b>3.4</b> What happens when you remove stop words</a></li>
<li class="chapter" data-level="3.5" data-path="stopwords.html"><a href="stopwords.html#stop-words-in-languages-other-than-english"><i class="fa fa-check"></i><b>3.5</b> Stop words in languages other than English</a></li>
<li class="chapter" data-level="3.6" data-path="stopwords.html"><a href="stopwords.html#stopwordssummary"><i class="fa fa-check"></i><b>3.6</b> Summary</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="stopwords.html"><a href="stopwords.html#in-this-chapter-you-learned-2"><i class="fa fa-check"></i><b>3.6.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stemming.html"><a href="stemming.html"><i class="fa fa-check"></i><b>4</b> Stemming</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stemming.html"><a href="stemming.html#how-to-stem-text-in-r"><i class="fa fa-check"></i><b>4.1</b> How to stem text in R</a></li>
<li class="chapter" data-level="4.2" data-path="stemming.html"><a href="stemming.html#should-you-use-stemming-at-all"><i class="fa fa-check"></i><b>4.2</b> Should you use stemming at all?</a></li>
<li class="chapter" data-level="4.3" data-path="stemming.html"><a href="stemming.html#understand-a-stemming-algorithm"><i class="fa fa-check"></i><b>4.3</b> Understand a stemming algorithm</a></li>
<li class="chapter" data-level="4.4" data-path="stemming.html"><a href="stemming.html#handling-punctuation-when-stemming"><i class="fa fa-check"></i><b>4.4</b> Handling punctuation when stemming</a></li>
<li class="chapter" data-level="4.5" data-path="stemming.html"><a href="stemming.html#compare-some-stemming-options"><i class="fa fa-check"></i><b>4.5</b> Compare some stemming options</a></li>
<li class="chapter" data-level="4.6" data-path="stemming.html"><a href="stemming.html#lemmatization"><i class="fa fa-check"></i><b>4.6</b> Lemmatization and stemming</a></li>
<li class="chapter" data-level="4.7" data-path="stemming.html"><a href="stemming.html#stemming-and-stop-words"><i class="fa fa-check"></i><b>4.7</b> Stemming and stop words</a></li>
<li class="chapter" data-level="4.8" data-path="stemming.html"><a href="stemming.html#stemmingsummary"><i class="fa fa-check"></i><b>4.8</b> Summary</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="stemming.html"><a href="stemming.html#in-this-chapter-you-learned-3"><i class="fa fa-check"></i><b>4.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="embeddings.html"><a href="embeddings.html"><i class="fa fa-check"></i><b>5</b> Word Embeddings</a>
<ul>
<li class="chapter" data-level="5.1" data-path="embeddings.html"><a href="embeddings.html#motivatingsparse"><i class="fa fa-check"></i><b>5.1</b> Motivating embeddings for sparse, high-dimensional data</a></li>
<li class="chapter" data-level="5.2" data-path="embeddings.html"><a href="embeddings.html#understand-word-embeddings-by-finding-them-yourself"><i class="fa fa-check"></i><b>5.2</b> Understand word embeddings by finding them yourself</a></li>
<li class="chapter" data-level="5.3" data-path="embeddings.html"><a href="embeddings.html#exploring-cfpb-word-embeddings"><i class="fa fa-check"></i><b>5.3</b> Exploring CFPB word embeddings</a></li>
<li class="chapter" data-level="5.4" data-path="embeddings.html"><a href="embeddings.html#glove"><i class="fa fa-check"></i><b>5.4</b> Use pre-trained word embeddings</a></li>
<li class="chapter" data-level="5.5" data-path="embeddings.html"><a href="embeddings.html#fairnessembeddings"><i class="fa fa-check"></i><b>5.5</b> Fairness and word embeddings</a></li>
<li class="chapter" data-level="5.6" data-path="embeddings.html"><a href="embeddings.html#using-word-embeddings-in-the-real-world"><i class="fa fa-check"></i><b>5.6</b> Using word embeddings in the real world</a></li>
<li class="chapter" data-level="5.7" data-path="embeddings.html"><a href="embeddings.html#embeddingssummary"><i class="fa fa-check"></i><b>5.7</b> Summary</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="embeddings.html"><a href="embeddings.html#in-this-chapter-you-learned-4"><i class="fa fa-check"></i><b>5.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Machine Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html"><i class="fa fa-check"></i>Foreword</a>
<ul>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#should-we-even-be-doing-this"><i class="fa fa-check"></i>Should we even be doing this?</a></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#what-bias-is-already-in-the-data"><i class="fa fa-check"></i>What bias is already in the data?</a></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#can-the-code-and-data-be-audited"><i class="fa fa-check"></i>Can the code and data be audited?</a></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#what-are-the-error-rates-for-sub-groups"><i class="fa fa-check"></i>What are the error rates for sub-groups?</a></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#what-is-the-accuracy-of-a-simple-rule-based-alternative"><i class="fa fa-check"></i>What is the accuracy of a simple rule-based alternative?</a></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#what-processes-are-in-place-to-handle-appeals-or-mistakes"><i class="fa fa-check"></i>What processes are in place to handle appeals or mistakes?</a></li>
<li class="chapter" data-level="" data-path="mlforeword.html"><a href="mlforeword.html#how-diverse-is-the-team-that-built-it"><i class="fa fa-check"></i>How diverse is the team that built it?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mlregression.html"><a href="mlregression.html"><i class="fa fa-check"></i><b>6</b> Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mlregression.html"><a href="mlregression.html#firstmlregression"><i class="fa fa-check"></i><b>6.1</b> A first regression model</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="mlregression.html"><a href="mlregression.html#firstregression"><i class="fa fa-check"></i><b>6.1.1</b> Building our first regression model</a></li>
<li class="chapter" data-level="6.1.2" data-path="mlregression.html"><a href="mlregression.html#firstregressionevaluation"><i class="fa fa-check"></i><b>6.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="mlregression.html"><a href="mlregression.html#regnull"><i class="fa fa-check"></i><b>6.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="6.3" data-path="mlregression.html"><a href="mlregression.html#comparerf"><i class="fa fa-check"></i><b>6.3</b> Compare to a random forest model</a></li>
<li class="chapter" data-level="6.4" data-path="mlregression.html"><a href="mlregression.html#casestudystopwords"><i class="fa fa-check"></i><b>6.4</b> Case study: removing stop words</a></li>
<li class="chapter" data-level="6.5" data-path="mlregression.html"><a href="mlregression.html#casestudyngrams"><i class="fa fa-check"></i><b>6.5</b> Case study: varying n-grams</a></li>
<li class="chapter" data-level="6.6" data-path="mlregression.html"><a href="mlregression.html#mlregressionlemmatization"><i class="fa fa-check"></i><b>6.6</b> Case study: lemmatization</a></li>
<li class="chapter" data-level="6.7" data-path="mlregression.html"><a href="mlregression.html#case-study-feature-hashing"><i class="fa fa-check"></i><b>6.7</b> Case study: feature hashing</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="mlregression.html"><a href="mlregression.html#text-normalization"><i class="fa fa-check"></i><b>6.7.1</b> Text normalization</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="mlregression.html"><a href="mlregression.html#what-evaluation-metrics-are-appropriate"><i class="fa fa-check"></i><b>6.8</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="6.9" data-path="mlregression.html"><a href="mlregression.html#mlregressionfull"><i class="fa fa-check"></i><b>6.9</b> The full game: regression</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="mlregression.html"><a href="mlregression.html#preprocess-the-data"><i class="fa fa-check"></i><b>6.9.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="6.9.2" data-path="mlregression.html"><a href="mlregression.html#specify-the-model"><i class="fa fa-check"></i><b>6.9.2</b> Specify the model</a></li>
<li class="chapter" data-level="6.9.3" data-path="mlregression.html"><a href="mlregression.html#tune-the-model"><i class="fa fa-check"></i><b>6.9.3</b> Tune the model</a></li>
<li class="chapter" data-level="6.9.4" data-path="mlregression.html"><a href="mlregression.html#regression-final-evaluation"><i class="fa fa-check"></i><b>6.9.4</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="mlregression.html"><a href="mlregression.html#mlregressionsummary"><i class="fa fa-check"></i><b>6.10</b> Summary</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="mlregression.html"><a href="mlregression.html#in-this-chapter-you-learned-5"><i class="fa fa-check"></i><b>6.10.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mlclassification.html"><a href="mlclassification.html"><i class="fa fa-check"></i><b>7</b> Classification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstattemptlookatdata"><i class="fa fa-check"></i><b>7.1</b> A first classification model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstmodel"><i class="fa fa-check"></i><b>7.1.1</b> Building our first classification model</a></li>
<li class="chapter" data-level="7.1.2" data-path="mlclassification.html"><a href="mlclassification.html#evaluation"><i class="fa fa-check"></i><b>7.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="mlclassification.html"><a href="mlclassification.html#classnull"><i class="fa fa-check"></i><b>7.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="7.3" data-path="mlclassification.html"><a href="mlclassification.html#comparetolasso"><i class="fa fa-check"></i><b>7.3</b> Compare to a lasso classification model</a></li>
<li class="chapter" data-level="7.4" data-path="mlclassification.html"><a href="mlclassification.html#tunelasso"><i class="fa fa-check"></i><b>7.4</b> Tuning lasso hyperparameters</a></li>
<li class="chapter" data-level="7.5" data-path="mlclassification.html"><a href="mlclassification.html#casestudysparseencoding"><i class="fa fa-check"></i><b>7.5</b> Case study: sparse encoding</a></li>
<li class="chapter" data-level="7.6" data-path="mlclassification.html"><a href="mlclassification.html#mlmulticlass"><i class="fa fa-check"></i><b>7.6</b> Two class or multiclass?</a></li>
<li class="chapter" data-level="7.7" data-path="mlclassification.html"><a href="mlclassification.html#case-study-including-non-text-data"><i class="fa fa-check"></i><b>7.7</b> Case study: including non-text data</a></li>
<li class="chapter" data-level="7.8" data-path="mlclassification.html"><a href="mlclassification.html#case-study-data-censoring"><i class="fa fa-check"></i><b>7.8</b> Case study: data censoring</a></li>
<li class="chapter" data-level="7.9" data-path="mlclassification.html"><a href="mlclassification.html#customfeatures"><i class="fa fa-check"></i><b>7.9</b> Case study: custom features</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="mlclassification.html"><a href="mlclassification.html#detect-credit-cards"><i class="fa fa-check"></i><b>7.9.1</b> Detect credit cards</a></li>
<li class="chapter" data-level="7.9.2" data-path="mlclassification.html"><a href="mlclassification.html#calculate-percentage-censoring"><i class="fa fa-check"></i><b>7.9.2</b> Calculate percentage censoring</a></li>
<li class="chapter" data-level="7.9.3" data-path="mlclassification.html"><a href="mlclassification.html#detect-monetary-amounts"><i class="fa fa-check"></i><b>7.9.3</b> Detect monetary amounts</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="mlclassification.html"><a href="mlclassification.html#what-evaluation-metrics-are-appropriate-1"><i class="fa fa-check"></i><b>7.10</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="7.11" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationfull"><i class="fa fa-check"></i><b>7.11</b> The full game: classification</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="mlclassification.html"><a href="mlclassification.html#feature-selection"><i class="fa fa-check"></i><b>7.11.1</b> Feature selection</a></li>
<li class="chapter" data-level="7.11.2" data-path="mlclassification.html"><a href="mlclassification.html#specify-the-model-1"><i class="fa fa-check"></i><b>7.11.2</b> Specify the model</a></li>
<li class="chapter" data-level="7.11.3" data-path="mlclassification.html"><a href="mlclassification.html#classification-final-evaluation"><i class="fa fa-check"></i><b>7.11.3</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationsummary"><i class="fa fa-check"></i><b>7.12</b> Summary</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="mlclassification.html"><a href="mlclassification.html#in-this-chapter-you-learned-6"><i class="fa fa-check"></i><b>7.12.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Deep Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="dlforeword.html"><a href="dlforeword.html"><i class="fa fa-check"></i>Foreword</a>
<ul>
<li class="chapter" data-level="" data-path="dlforeword.html"><a href="dlforeword.html#spending-your-data-budget"><i class="fa fa-check"></i>Spending your data budget</a></li>
<li class="chapter" data-level="" data-path="dlforeword.html"><a href="dlforeword.html#feature-engineering"><i class="fa fa-check"></i>Feature engineering</a></li>
<li class="chapter" data-level="" data-path="dlforeword.html"><a href="dlforeword.html#fitting-and-tuning"><i class="fa fa-check"></i>Fitting and tuning</a></li>
<li class="chapter" data-level="" data-path="dlforeword.html"><a href="dlforeword.html#model-evaluation"><i class="fa fa-check"></i>Model evaluation</a></li>
<li class="chapter" data-level="" data-path="dlforeword.html"><a href="dlforeword.html#putting-the-model-process-in-context"><i class="fa fa-check"></i>Putting the model process in context</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="dldnn.html"><a href="dldnn.html"><i class="fa fa-check"></i><b>8</b> Dense neural networks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dldnn.html"><a href="dldnn.html#kickstarter"><i class="fa fa-check"></i><b>8.1</b> Kickstarter data</a></li>
<li class="chapter" data-level="8.2" data-path="dldnn.html"><a href="dldnn.html#firstdlclassification"><i class="fa fa-check"></i><b>8.2</b> A first deep learning model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="dldnn.html"><a href="dldnn.html#dnnrecipe"><i class="fa fa-check"></i><b>8.2.1</b> Preprocessing for deep learning</a></li>
<li class="chapter" data-level="8.2.2" data-path="dldnn.html"><a href="dldnn.html#onehotsequence"><i class="fa fa-check"></i><b>8.2.2</b> One-hot sequence embedding of text</a></li>
<li class="chapter" data-level="8.2.3" data-path="dldnn.html"><a href="dldnn.html#simple-flattened-dense-network"><i class="fa fa-check"></i><b>8.2.3</b> Simple flattened dense network</a></li>
<li class="chapter" data-level="8.2.4" data-path="dldnn.html"><a href="dldnn.html#evaluate-dnn"><i class="fa fa-check"></i><b>8.2.4</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="dldnn.html"><a href="dldnn.html#using-bag-of-words-features"><i class="fa fa-check"></i><b>8.3</b> Using bag-of-words features</a></li>
<li class="chapter" data-level="8.4" data-path="dldnn.html"><a href="dldnn.html#using-pre-trained-word-embeddings"><i class="fa fa-check"></i><b>8.4</b> Using pre-trained word embeddings</a></li>
<li class="chapter" data-level="8.5" data-path="dldnn.html"><a href="dldnn.html#dnncross"><i class="fa fa-check"></i><b>8.5</b> Cross-validation for deep learning models</a></li>
<li class="chapter" data-level="8.6" data-path="dldnn.html"><a href="dldnn.html#compare-and-evaluate-dnn-models"><i class="fa fa-check"></i><b>8.6</b> Compare and evaluate DNN models</a></li>
<li class="chapter" data-level="8.7" data-path="dldnn.html"><a href="dldnn.html#dllimitations"><i class="fa fa-check"></i><b>8.7</b> Limitations of deep learning</a></li>
<li class="chapter" data-level="8.8" data-path="dldnn.html"><a href="dldnn.html#dldnnsummary"><i class="fa fa-check"></i><b>8.8</b> Summary</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="dldnn.html"><a href="dldnn.html#in-this-chapter-you-learned-7"><i class="fa fa-check"></i><b>8.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dllstm.html"><a href="dllstm.html"><i class="fa fa-check"></i><b>9</b> Long short-term memory (LSTM) networks</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dllstm.html"><a href="dllstm.html#firstlstm"><i class="fa fa-check"></i><b>9.1</b> A first LSTM model</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="dllstm.html"><a href="dllstm.html#building-an-lstm"><i class="fa fa-check"></i><b>9.1.1</b> Building an LSTM</a></li>
<li class="chapter" data-level="9.1.2" data-path="dllstm.html"><a href="dllstm.html#lstmevaluation"><i class="fa fa-check"></i><b>9.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="dllstm.html"><a href="dllstm.html#compare-to-a-recurrent-neural-network"><i class="fa fa-check"></i><b>9.2</b> Compare to a recurrent neural network</a></li>
<li class="chapter" data-level="9.3" data-path="dllstm.html"><a href="dllstm.html#bilstm"><i class="fa fa-check"></i><b>9.3</b> Case study: bidirectional LSTM</a></li>
<li class="chapter" data-level="9.4" data-path="dllstm.html"><a href="dllstm.html#case-study-stacking-lstm-layers"><i class="fa fa-check"></i><b>9.4</b> Case study: stacking LSTM layers</a></li>
<li class="chapter" data-level="9.5" data-path="dllstm.html"><a href="dllstm.html#lstmpadding"><i class="fa fa-check"></i><b>9.5</b> Case study: padding</a></li>
<li class="chapter" data-level="9.6" data-path="dllstm.html"><a href="dllstm.html#case-study-training-a-regression-model"><i class="fa fa-check"></i><b>9.6</b> Case study: training a regression model</a></li>
<li class="chapter" data-level="9.7" data-path="dllstm.html"><a href="dllstm.html#case-study-vocabulary-size"><i class="fa fa-check"></i><b>9.7</b> Case study: vocabulary size</a></li>
<li class="chapter" data-level="9.8" data-path="dllstm.html"><a href="dllstm.html#lstmfull"><i class="fa fa-check"></i><b>9.8</b> The full game: LSTM</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="dllstm.html"><a href="dllstm.html#lstmfullpreprocess"><i class="fa fa-check"></i><b>9.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="9.8.2" data-path="dllstm.html"><a href="dllstm.html#lstmfullmodel"><i class="fa fa-check"></i><b>9.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="dllstm.html"><a href="dllstm.html#dllstmsummary"><i class="fa fa-check"></i><b>9.9</b> Summary</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="dllstm.html"><a href="dllstm.html#in-this-chapter-you-learned-8"><i class="fa fa-check"></i><b>9.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dlcnn.html"><a href="dlcnn.html"><i class="fa fa-check"></i><b>10</b> Convolutional neural networks</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dlcnn.html"><a href="dlcnn.html#what-are-cnns"><i class="fa fa-check"></i><b>10.1</b> What are CNNs?</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="dlcnn.html"><a href="dlcnn.html#kernel"><i class="fa fa-check"></i><b>10.1.1</b> Kernel</a></li>
<li class="chapter" data-level="10.1.2" data-path="dlcnn.html"><a href="dlcnn.html#kernel-size"><i class="fa fa-check"></i><b>10.1.2</b> Kernel size</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="dlcnn.html"><a href="dlcnn.html#firstcnn"><i class="fa fa-check"></i><b>10.2</b> A first CNN model</a></li>
<li class="chapter" data-level="10.3" data-path="dlcnn.html"><a href="dlcnn.html#case-study-adding-more-layers"><i class="fa fa-check"></i><b>10.3</b> Case study: adding more layers</a></li>
<li class="chapter" data-level="10.4" data-path="dlcnn.html"><a href="dlcnn.html#case-study-byte-pair-encoding"><i class="fa fa-check"></i><b>10.4</b> Case study: byte pair encoding</a></li>
<li class="chapter" data-level="10.5" data-path="dlcnn.html"><a href="dlcnn.html#lime"><i class="fa fa-check"></i><b>10.5</b> Case study: explainability with LIME</a></li>
<li class="chapter" data-level="10.6" data-path="dlcnn.html"><a href="dlcnn.html#keras-hyperparameter"><i class="fa fa-check"></i><b>10.6</b> Case study: hyperparameter search</a></li>
<li class="chapter" data-level="10.7" data-path="dlcnn.html"><a href="dlcnn.html#cross-validation-for-evaluation"><i class="fa fa-check"></i><b>10.7</b> Cross-validation for evaluation</a></li>
<li class="chapter" data-level="10.8" data-path="dlcnn.html"><a href="dlcnn.html#cnnfull"><i class="fa fa-check"></i><b>10.8</b> The full game: CNN</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullpreprocess"><i class="fa fa-check"></i><b>10.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="10.8.2" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullmodel"><i class="fa fa-check"></i><b>10.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="dlcnn.html"><a href="dlcnn.html#dlcnnsummary"><i class="fa fa-check"></i><b>10.9</b> Summary</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="dlcnn.html"><a href="dlcnn.html#in-this-chapter-you-learned-9"><i class="fa fa-check"></i><b>10.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="" data-path="text-models-in-the-real-world.html"><a href="text-models-in-the-real-world.html"><i class="fa fa-check"></i>Text models in the real world</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="regexp.html"><a href="regexp.html"><i class="fa fa-check"></i><b>A</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="A.1" data-path="regexp.html"><a href="regexp.html#literal-characters"><i class="fa fa-check"></i><b>A.1</b> Literal characters</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="regexp.html"><a href="regexp.html#meta-characters"><i class="fa fa-check"></i><b>A.1.1</b> Meta characters</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="regexp.html"><a href="regexp.html#full-stop-the-wildcard"><i class="fa fa-check"></i><b>A.2</b> Full stop, the wildcard</a></li>
<li class="chapter" data-level="A.3" data-path="regexp.html"><a href="regexp.html#character-classes"><i class="fa fa-check"></i><b>A.3</b> Character classes</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="regexp.html"><a href="regexp.html#shorthand-character-classes"><i class="fa fa-check"></i><b>A.3.1</b> Shorthand character classes</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="regexp.html"><a href="regexp.html#quantifiers"><i class="fa fa-check"></i><b>A.4</b> Quantifiers</a></li>
<li class="chapter" data-level="A.5" data-path="regexp.html"><a href="regexp.html#anchors"><i class="fa fa-check"></i><b>A.5</b> Anchors</a></li>
<li class="chapter" data-level="A.6" data-path="regexp.html"><a href="regexp.html#additional-resources"><i class="fa fa-check"></i><b>A.6</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixdata.html"><a href="appendixdata.html"><i class="fa fa-check"></i><b>B</b> Data</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixdata.html"><a href="appendixdata.html#hcandersen"><i class="fa fa-check"></i><b>B.1</b> Hans Christian Andersen fairy tales</a></li>
<li class="chapter" data-level="B.2" data-path="appendixdata.html"><a href="appendixdata.html#scotus-opinions"><i class="fa fa-check"></i><b>B.2</b> Opinions of the Supreme Court of the United States</a></li>
<li class="chapter" data-level="B.3" data-path="appendixdata.html"><a href="appendixdata.html#cfpb-complaints"><i class="fa fa-check"></i><b>B.3</b> Consumer Financial Protection Bureau (CFPB) complaints</a></li>
<li class="chapter" data-level="B.4" data-path="appendixdata.html"><a href="appendixdata.html#kickstarter-blurbs"><i class="fa fa-check"></i><b>B.4</b> Kickstarter campaign blurbs</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appendixbaseline.html"><a href="appendixbaseline.html"><i class="fa fa-check"></i><b>C</b> Baseline linear classifier</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appendixbaseline.html"><a href="appendixbaseline.html#read-in-the-data"><i class="fa fa-check"></i><b>C.1</b> Read in the data</a></li>
<li class="chapter" data-level="C.2" data-path="appendixbaseline.html"><a href="appendixbaseline.html#split-into-testtrain-and-create-resampling-folds"><i class="fa fa-check"></i><b>C.2</b> Split into test/train and create resampling folds</a></li>
<li class="chapter" data-level="C.3" data-path="appendixbaseline.html"><a href="appendixbaseline.html#recipe-for-data-preprocessing"><i class="fa fa-check"></i><b>C.3</b> Recipe for data preprocessing</a></li>
<li class="chapter" data-level="C.4" data-path="appendixbaseline.html"><a href="appendixbaseline.html#lasso-regularized-classification-model"><i class="fa fa-check"></i><b>C.4</b> Lasso regularized classification model</a></li>
<li class="chapter" data-level="C.5" data-path="appendixbaseline.html"><a href="appendixbaseline.html#a-model-workflow"><i class="fa fa-check"></i><b>C.5</b> A model workflow</a></li>
<li class="chapter" data-level="C.6" data-path="appendixbaseline.html"><a href="appendixbaseline.html#tune-the-workflow"><i class="fa fa-check"></i><b>C.6</b> Tune the workflow</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supervised Machine Learning for Text Analysis in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
2007. <em>Boost C Libraries</em>. <a href="https://www.boost.org/doc/libs/1_44_0/libs/regex/doc/html/boost_regex/syntax/basic_extended.html">https://www.boost.org/doc/libs/1_44_0/libs/regex/doc/html/boost_regex/syntax/basic_extended.html</a>.
</div>
<div class="csl-entry">
Allaire, JJ, and François Chollet. 2020. <em>Keras: R Interface to ’Keras’</em>. <a href="https://CRAN.R-project.org/package=keras">https://CRAN.R-project.org/package=keras</a>.
</div>
<div class="csl-entry">
Appleby, Austin. 2008. <span>“MurmurHash.”</span> <a href="https://sites.google.com/site/murmurhash">https://sites.google.com/site/murmurhash</a>.
</div>
<div class="csl-entry">
Arnold, Taylor. 2017. <span>“A Tidy Data Model for Natural Language Processing Using cleanNLP.”</span> <em>The R Journal</em> 9 (2): 1–20. <a href="https://journal.r-project.org/archive/2017/RJ-2017-035/index.html">https://journal.r-project.org/archive/2017/RJ-2017-035/index.html</a>.
</div>
<div class="csl-entry">
Bates, Douglas, and Martin Maechler. 2019. <em>Matrix: Sparse and Dense Matrix Classes and Methods</em>. <a href="https://CRAN.R-project.org/package=Matrix">https://CRAN.R-project.org/package=Matrix</a>.
</div>
<div class="csl-entry">
Bender, Emily M. 2011. <span>“On Achieving and Evaluating Language-Independence in NLP.”</span> <em>Linguistic Issues in Language Technology</em> 6 (3): 1–26.
</div>
<div class="csl-entry">
———. 2013. <span>“Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax.”</span> <em>Synthesis Lectures on Human Language Technologies</em> 6 (3): 1–184.
</div>
<div class="csl-entry">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <span>“On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜.”</span> In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 610–23. FAccT ’21. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div class="csl-entry">
Benoit, Kenneth, and Akitaka Matsuo. 2019. <em>Spacyr: Wrapper to the ’spaCy’ ’NLP’ Library</em>. <a href="https://CRAN.R-project.org/package=spacyr">https://CRAN.R-project.org/package=spacyr</a>.
</div>
<div class="csl-entry">
Benoit, Kenneth, David Muhr, and Kohei Watanabe. 2019. <em>Stopwords: Multilingual Stopword Lists</em>. <a href="https://CRAN.R-project.org/package=stopwords">https://CRAN.R-project.org/package=stopwords</a>.
</div>
<div class="csl-entry">
Boehmke, Brad, and Brandon M. Greenwell. 2019. <em>Hands-on Machine Learning with r</em>. 1st ed. Boca Raton: CRC Press.
</div>
<div class="csl-entry">
Bojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2016. <span>“Enriching Word Vectors with Subword Information.”</span> <em>CoRR</em> abs/1607.04606. <a href="http://arxiv.org/abs/1607.04606">http://arxiv.org/abs/1607.04606</a>.
</div>
<div class="csl-entry">
Bolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam Tauman Kalai. 2016. <span>“Quantifying and Reducing Stereotypes in Word Embeddings.”</span> <em>CoRR</em> abs/1606.06121. <a href="http://arxiv.org/abs/1606.06121">http://arxiv.org/abs/1606.06121</a>.
</div>
<div class="csl-entry">
Boser, Bernhard E, Isabelle M Guyon, and Vladimir N Vapnik. 1992. <span>“A Training Algorithm for Optimal Margin Classifiers.”</span> In <em>Proceedings of the Fifth Annual Workshop on Computational Learning Theory</em>, 144–52.
</div>
<div class="csl-entry">
Breiman, Leo, Jerome Friedman, Charles J Stone, and Richard A Olshen. 1984. <em>Classification and Regression Trees</em>. CRC press.
</div>
<div class="csl-entry">
Briscoe, Ted. 2013. <span>“Introduction to Linguistics for Natural Language Processing.”</span> <a href="https://www.cl.cam.ac.uk/teaching/1314/L100/introling.pdf">https://www.cl.cam.ac.uk/teaching/1314/L100/introling.pdf</a>.
</div>
<div class="csl-entry">
Carlini, Nicholas, Chang Liu, Úlfar Erlingsson, Jernej Kos, and Dawn Song. 2018. <span>“The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks.”</span> <a href="http://arxiv.org/abs/1802.08232">http://arxiv.org/abs/1802.08232</a>.
</div>
<div class="csl-entry">
Caruana, Rich, Nikos Karampatziakis, and Ainur Yessenalina. 2008. <span>“An Empirical Evaluation of Supervised Learning in High Dimensions.”</span> In <em>Proceedings of the 25th International Conference on Machine Learning</em>, 96–103.
</div>
<div class="csl-entry">
Chollet, F., and J. J. Allaire. 2018. <em>Deep Learning with r</em>. Manning Publications. <a href="https://www.manning.com/books/deep-learning-with-r">https://www.manning.com/books/deep-learning-with-r</a>.
</div>
<div class="csl-entry">
Edmondson, Mark. 2020. <em>googleLanguageR: Call Google’s ’Natural Language’ API, ’Cloud Translation’ API, ’Cloud Speech’ API and ’Cloud Text-to-Speech’ API</em>. <a href="https://CRAN.R-project.org/package=googleLanguageR">https://CRAN.R-project.org/package=googleLanguageR</a>.
</div>
<div class="csl-entry">
Elman, Jeffrey L. 1990. <span>“Finding Structure in Time.”</span> <em>Cognitive Science</em> 14 (2): 179–211. https://doi.org/<a href="https://doi.org/10.1016/0364-0213(90)90002-E">https://doi.org/10.1016/0364-0213(90)90002-E</a>.
</div>
<div class="csl-entry">
Ethayarajh, Kawin, David Duvenaud, and Graeme Hirst. 2019. <span>“Understanding Undesirable Word Embedding Associations.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 1696–1705. Florence, Italy: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P19-1166">https://doi.org/10.18653/v1/P19-1166</a>.
</div>
<div class="csl-entry">
Feathers, Todd. 2019. <span>“Flawed Algorithms Are Grading Millions of Students’ Essays.”</span> <em>Motherboard</em>. VICE. <a href="https://www.vice.com/en/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays">https://www.vice.com/en/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays</a>.
</div>
<div class="csl-entry">
Feldman, R., and J. Sanger. 2007. <em>The Text Mining Handbook</em>. Cambridge university press.
</div>
<div class="csl-entry">
Forman, George, and Evan Kirshenbaum. 2008. <span>“Extremely Fast Text Feature Extraction for Classification and Indexing.”</span> In <em>Proceedings of the 17th ACM Conference on Information and Knowledge Management</em>, 1221–30. CIKM ’08. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/1458082.1458243">https://doi.org/10.1145/1458082.1458243</a>.
</div>
<div class="csl-entry">
Frank, Eibe, and Remco R. Bouckaert. 2006. <span>“Naive Bayes for Text Classification with Unbalanced Classes.”</span> In <em>Knowledge Discovery in Databases: PKDD 2006</em>, edited by Johannes Fürnkranz, Tobias Scheffer, and Myra Spiliopoulou, 503–10. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div class="csl-entry">
Fredrikson, Matthew, Eric Lantz, Somesh Jha, Simon Lin, David Page, and Thomas Ristenpart. 2014. <span>“Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing.”</span> In <em>23rd <span>USENIX</span> Security Symposium (<span>USENIX</span> Security 14)</em>, 17–32. San Diego, CA: <span>USENIX</span> Association. <a href="https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson_matthew">https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson_matthew</a>.
</div>
<div class="csl-entry">
Fredrikson, Matt, Somesh Jha, and Thomas Ristenpart. 2015. <span>“Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures.”</span> In, 1322–33. <a href="https://doi.org/10.1145/2810103.2813677">https://doi.org/10.1145/2810103.2813677</a>.
</div>
<div class="csl-entry">
Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2010. <span>“Regularization Paths for Generalized Linear Models via Coordinate Descent.”</span> <em>Journal of Statistical Software</em> 33 (1): 1–22. <a href="http://www.jstatsoft.org/v33/i01/">http://www.jstatsoft.org/v33/i01/</a>.
</div>
<div class="csl-entry">
Gage, P. 1994. <span>“A New Algorithm for Data Compression.”</span> <em>The C Users Journal Archive</em> 12: 23–38.
</div>
<div class="csl-entry">
Gagolewski, Marek. 2019. <em>R Package Stringi: Character String Processing Facilities</em>. <a href="http://www.gagolewski.com/software/stringi/">http://www.gagolewski.com/software/stringi/</a>.
</div>
<div class="csl-entry">
Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. <span>“Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes.”</span> <em>Proceedings of the National Academy of Sciences</em> 115 (16): E3635–44. <a href="https://doi.org/10.1073/pnas.1720347115">https://doi.org/10.1073/pnas.1720347115</a>.
</div>
<div class="csl-entry">
Golub, G. H., and C. Reinsch. 1970. <span>“Singular Value Decomposition and Least Squares Solutions.”</span> <em>Numer. Math.</em> 14 (5): 403–20. <a href="https://doi.org/10.1007/BF02163027">https://doi.org/10.1007/BF02163027</a>.
</div>
<div class="csl-entry">
Gonen, Hila, and Yoav Goldberg. 2019. <span>“Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings but Do Not Remove Them.”</span> <em>CoRR</em> abs/1903.03862. <a href="http://arxiv.org/abs/1903.03862">http://arxiv.org/abs/1903.03862</a>.
</div>
<div class="csl-entry">
Group, The Open. 2018. <span>“The Open Group Base Specifications Issue 7, 2018 Edition.”</span> <a href="https://pubs.opengroup.org/onlinepubs/9699919799/">https://pubs.opengroup.org/onlinepubs/9699919799/</a>.
</div>
<div class="csl-entry">
Guidotti, Riccardo, Anna Monreale, Salvatore Ruggieri, Franco Turini, Dino Pedreschi, and Fosca Giannotti. 2018. <span>“A Survey of Methods for Explaining Black Box Models.”</span> <a href="http://arxiv.org/abs/1802.01933">http://arxiv.org/abs/1802.01933</a>.
</div>
<div class="csl-entry">
Harman, Donna. 1991. <span>“How Effective Is Suffixing?”</span> <em>Journal of the American Society for Information Science</em> 42 (1): 7–15.
</div>
<div class="csl-entry">
Helleputte, Thibault. 2017. <em>LiblineaR: Linear Predictive Models Based on the LIBLINEAR c/c++ Library</em>.
</div>
<div class="csl-entry">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Comput.</em> 9 (8): 1735–80. <a href="https://doi.org/10.1162/neco.1997.9.8.1735">https://doi.org/10.1162/neco.1997.9.8.1735</a>.
</div>
<div class="csl-entry">
Honnibal, Matthew, and Ines Montani. 2017. <span>“<span class="nocase">spaCy 2</span>: Natural Language Understanding with <span>B</span>loom Embeddings, Convolutional Neural Networks and Incremental Parsing.”</span>
</div>
<div class="csl-entry">
Howard, Jeremy, and Sebastian Ruder. 2018. <span>“Fine-Tuned Language Models for Text Classification.”</span> <em>CoRR</em> abs/1801.06146. <a href="http://arxiv.org/abs/1801.06146">http://arxiv.org/abs/1801.06146</a>.
</div>
<div class="csl-entry">
Huang, Weipeng, Xingyi Cheng, Kunlong Chen, Taifeng Wang, and Wei Chu. 2019. <span>“Toward Fast and Accurate Neural Chinese Word Segmentation with Multi-Criteria Learning.”</span>
</div>
<div class="csl-entry">
Huston, Samuel, and W. Bruce Croft. 2010. <span>“Evaluating Verbose Query Processing Techniques.”</span> In <em>Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, 291–98. SIGIR ’10. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/1835449.1835499">https://doi.org/10.1145/1835449.1835499</a>.
</div>
<div class="csl-entry">
Hvitfeldt, Emil. 2019a. <em>Hcandersenr: H.c. Andersens Fairy Tales</em>. <a href="https://CRAN.R-project.org/package=hcandersenr">https://CRAN.R-project.org/package=hcandersenr</a>.
</div>
<div class="csl-entry">
———. 2019b. <em>Scotus: Collection of Supreme Court of the United States’ Opinions</em>. <a href="https://github.com/EmilHvitfeldt/scotus">https://github.com/EmilHvitfeldt/scotus</a>.
</div>
<div class="csl-entry">
———. 2020a. <em>Textdata: Download and Load Various Text Datasets</em>. <a href="https://github.com/EmilHvitfeldt/textdata">https://github.com/EmilHvitfeldt/textdata</a>.
</div>
<div class="csl-entry">
———. 2020b. <em>Textrecipes: Extra ’Recipes’ for Text Processing</em>. <a href="https://CRAN.R-project.org/package=textrecipes">https://CRAN.R-project.org/package=textrecipes</a>.
</div>
<div class="csl-entry">
———. 2020c. <em>Wordsalad: Provide Tools to Extract and Analyze Word Vectors</em>. <a href="https://CRAN.R-project.org/package=wordsalad">https://CRAN.R-project.org/package=wordsalad</a>.
</div>
<div class="csl-entry">
Islam, Aylin Caliskan, Joanna J. Bryson, and Arvind Narayanan. 2016. <span>“Semantics Derived Automatically from Language Corpora Necessarily Contain Human Biases.”</span> <em>CoRR</em> abs/1608.07187. <a href="http://arxiv.org/abs/1608.07187">http://arxiv.org/abs/1608.07187</a>.
</div>
<div class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.
</div>
<div class="csl-entry">
Joachims, Thorsten. 1998. <span>“Text Categorization with Support Vector Machines: Learning with Many Relevant Features.”</span> In <em>Proceedings of the 10th European Conference on Machine Learning</em>, 137–42. ECML’98. Berlin, Heidelberg: Springer-Verlag. <a href="https://doi.org/10.1007/BFb0026683">https://doi.org/10.1007/BFb0026683</a>.
</div>
<div class="csl-entry">
Johnson, Stephen B. 1999. <span>“A Semantic Lexicon for Medical Language Processing.”</span> <em>Journal of the American Medical Informatics Association</em> 6 (3): 205–18.
</div>
<div class="csl-entry">
Kearney, Michael W. 2019. <em>Textfeatures: Extracts Features from Text</em>. <a href="https://CRAN.R-project.org/package=textfeatures">https://CRAN.R-project.org/package=textfeatures</a>.
</div>
<div class="csl-entry">
Kibriya, Ashraf M., Eibe Frank, Bernhard Pfahringer, and Geoffrey Holmes. 2005. <span>“Multinomial Naive Bayes for Text Categorization Revisited.”</span> In <em>AI 2004: Advances in Artificial Intelligence</em>, edited by Geoffrey I. Webb and Xinghuo Yu, 488–99. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div class="csl-entry">
Kim, Yoon. 2014. <span>“Convolutional Neural Networks for Sentence Classification.”</span> In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span>)</em>, 1746–51. Doha, Qatar: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/D14-1181">https://doi.org/10.3115/v1/D14-1181</a>.
</div>
<div class="csl-entry">
Kingma, Diederik P., and Jimmy Ba. 2017. <span>“Adam: A Method for Stochastic Optimization.”</span> <a href="http://arxiv.org/abs/1412.6980">http://arxiv.org/abs/1412.6980</a>.
</div>
<div class="csl-entry">
Lampinen, Andrew K., and James L. McClelland. 2018. <span>“One-Shot and Few-Shot Learning of Word Embeddings.”</span> <a href="http://arxiv.org/abs/1710.10280">http://arxiv.org/abs/1710.10280</a>.
</div>
<div class="csl-entry">
Le, Quoc V., and Tomas Mikolov. 2014. <span>“Distributed Representations of Sentences and Documents.”</span> <em>CoRR</em> abs/1405.4053. <a href="http://arxiv.org/abs/1405.4053">http://arxiv.org/abs/1405.4053</a>.
</div>
<div class="csl-entry">
Levy, Omer, and Yoav Goldberg. 2014. <span>“Dependency-Based Word Embeddings.”</span> In <em>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, 302–8. Baltimore, Maryland: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/P14-2050">https://doi.org/10.3115/v1/P14-2050</a>.
</div>
<div class="csl-entry">
Lewis, David D., Yiming Yang, Tony G. Rose, and Fan Li. 2004. <span>“Rcv1: A New Benchmark Collection for Text Categorization Research.”</span> <em>J. Mach. Learn. Res.</em> 5 (December): 361–97. <a href="http://dl.acm.org/citation.cfm?id=1005332.1005345">http://dl.acm.org/citation.cfm?id=1005332.1005345</a>.
</div>
<div class="csl-entry">
Lex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and Hanspeter Pfister. 2014. <span>“UpSet: Visualization of Intersecting Sets.”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em> 20 (12): 1983–92.
</div>
<div class="csl-entry">
Lingolia. 2021. <span>“Articles in German Grammar.”</span> <a href="https://deutsch.lingolia.com/en/grammar/nouns-and-articles/articles-noun-markers">https://deutsch.lingolia.com/en/grammar/nouns-and-articles/articles-noun-markers</a>.
</div>
<div class="csl-entry">
Lovins, Julie B. 1968. <span>“Development of a Stemming Algorithm.”</span> <em>Mechanical Translation and Computational Linguistics</em> 11: 22–31.
</div>
<div class="csl-entry">
Lu, Kaiji, Piotr Mardziel, Fangjing Wu, Preetam Amancharla, and Anupam Datta. 2018. <span>“Gender Bias in Neural Natural Language Processing.”</span> <em>CoRR</em> abs/1807.11714. <a href="http://arxiv.org/abs/1807.11714">http://arxiv.org/abs/1807.11714</a>.
</div>
<div class="csl-entry">
Luhn, H. P. 1960. <span>“Key Word-in-Context Index for Technical Literature (Kwic Index).”</span> <em>American Documentation</em> 11 (4): 288–95. <a href="https://doi.org/10.1002/asi.5090110403">https://doi.org/10.1002/asi.5090110403</a>.
</div>
<div class="csl-entry">
Ma, Ji, Kuzman Ganchev, and David Weiss. 2018. <span>“State-of-the-Art <span>C</span>hinese Word Segmentation with Bi-<span>LSTM</span>s.”</span> In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, 4902–8. Brussels, Belgium: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D18-1529">https://doi.org/10.18653/v1/D18-1529</a>.
</div>
<div class="csl-entry">
Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. 2008. <em>Introduction to Information Retrieval</em>. New York, NY, USA: Cambridge University Press.
</div>
<div class="csl-entry">
McCulloch, Gretchen. 2015. <span>“Move over Shakespeare, Teen Girls Are the Real Language Disruptors.”</span> <em>Quartz</em>. Quartz. <a href="https://qz.com/474671/move-over-shakespeare-teen-girls-are-the-real-language-disruptors/">https://qz.com/474671/move-over-shakespeare-teen-girls-are-the-real-language-disruptors/</a>.
</div>
<div class="csl-entry">
Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. <span>“Efficient Estimation of Word Representations in Vector Space.”</span> <em>arXiv Preprint arXiv:1301.3781</em>.
</div>
<div class="csl-entry">
Miller, George A. 1995. <span>“WordNet: A Lexical Database for English.”</span> <em>Commun. ACM</em> 38 (11): 39–41. <a href="https://doi.org/10.1145/219717.219748">https://doi.org/10.1145/219717.219748</a>.
</div>
<div class="csl-entry">
Minaee, Shervin, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2020. <span>“Deep Learning Based Text Classification: A Comprehensive Review.”</span> <em>arXiv Preprint arXiv:2004.03705</em>.
</div>
<div class="csl-entry">
Mohammad, Saif M., and Peter D. Turney. 2013. <span>“CROWDSOURCING a WORD–EMOTION ASSOCIATION LEXICON.”</span> <em>Computational Intelligence</em> 29 (3): 436–65. <a href="https://doi.org/10.1111/j.1467-8640.2012.00460.x">https://doi.org/10.1111/j.1467-8640.2012.00460.x</a>.
</div>
<div class="csl-entry">
Moody, Chris. 2017. <span>“Stop Using Word2vec.”</span> <em>Multithreaded</em>. StitchFix. <a href="https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/">https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/</a>.
</div>
<div class="csl-entry">
Mullen, Lincoln A., Kenneth Benoit, Os Keyes, Dmitry Selivanov, and Jeffrey Arnold. 2018. <span>“Fast, Consistent Tokenization of Natural Language Text.”</span> <em>Journal of Open Source Software</em> 3: 655. <a href="https://doi.org/10.21105/joss.00655">https://doi.org/10.21105/joss.00655</a>.
</div>
<div class="csl-entry">
Nothman, Joel, Hanmin Qin, and Roman Yurchak. 2018. <span>“Stop Word Lists in Free Open-Source Software Packages.”</span> In <em>Proceedings of Workshop for <span>NLP</span> Open Source Software (<span>NLP</span>-<span>OSS</span>)</em>, 7–12. Melbourne, Australia: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/W18-2502">https://doi.org/10.18653/v1/W18-2502</a>.
</div>
<div class="csl-entry">
Olson, Randal S., William La Cava, Zairah Mustahsan, Akshay Varik, and Jason H. Moore. 2017. <span>“Data-Driven Advice for Applying Machine Learning to Bioinformatics Problems.”</span> <a href="http://arxiv.org/abs/1708.05070">http://arxiv.org/abs/1708.05070</a>.
</div>
<div class="csl-entry">
Ooms, Jeroen. 2020. <em>Pdftools: Text Extraction, Rendering and Converting of PDF Documents</em>. <a href="https://CRAN.R-project.org/package=pdftools">https://CRAN.R-project.org/package=pdftools</a>.
</div>
<div class="csl-entry">
Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. 2014. <span>“GloVe: Global Vectors for Word Representation.”</span> In <em>Empirical Methods in Natural Language Processing (EMNLP)</em>, 1532–43. <a href="http://www.aclweb.org/anthology/D14-1162">http://www.aclweb.org/anthology/D14-1162</a>.
</div>
<div class="csl-entry">
Perry, Patrick O. 2020. <em>Corpus: Text Corpus Analysis</em>. <a href="https://CRAN.R-project.org/package=corpus">https://CRAN.R-project.org/package=corpus</a>.
</div>
<div class="csl-entry">
Peters, Matthew E., Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. <span>“Deep Contextualized Word Representations.”</span> <em>CoRR</em> abs/1802.05365. <a href="http://arxiv.org/abs/1802.05365">http://arxiv.org/abs/1802.05365</a>.
</div>
<div class="csl-entry">
Porter, Martin F. 1980. <span>“An Algorithm for Suffix Stripping.”</span> <em>Program</em> 14 (3): 130–37. <a href="https://doi.org/10.1108/eb046814">https://doi.org/10.1108/eb046814</a>.
</div>
<div class="csl-entry">
Porter, Martin F. 2001. <span>“Snowball: A Language for Stemming Algorithms.”</span>
</div>
<div class="csl-entry">
<span>“Quantifiers <span>, *, ?</span> And <span class="nocase">n</span>.”</span> 2019. <em>The Modern Javascript Tutorial</em>. <a href="https://javascript.info/regexp-quantifiers">https://javascript.info/regexp-quantifiers</a>.
</div>
<div class="csl-entry">
Ramineni, Chaitanya, and David Williamson. 2018. <span>“Understanding Mean Score Differences Between the e-Rater® Automated Scoring Engine and Humans for Demographically Based Groups in the GRE® General Test.”</span> <em>ETS Research Report Series</em> 2018 (1): 1–31. https://doi.org/<a href="https://doi.org/10.1002/ets2.12192">https://doi.org/10.1002/ets2.12192</a>.
</div>
<div class="csl-entry">
Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. <span>“"Why Should i Trust You?": Explaining the Predictions of Any Classifier.”</span> <a href="http://arxiv.org/abs/1602.04938">http://arxiv.org/abs/1602.04938</a>.
</div>
<div class="csl-entry">
Sang-Bum Kim, Kyoung-Soo Han, Hae-Chang Rim, and Sung Hyon Myaeng. 2006. <span>“Some Effective Techniques for Naive Bayes Text Classification.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 18 (11): 1457–66.
</div>
<div class="csl-entry">
Sap, Maarten, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A. Smith. 2019. <span>“The Risk of Racial Bias in Hate Speech Detection.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 1668–78. Florence, Italy: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P19-1163">https://doi.org/10.18653/v1/P19-1163</a>.
</div>
<div class="csl-entry">
Schofield, Alexandra, and David Mimno. 2016. <span>“Comparing Apples to Apple: The Effects of Stemmers on Topic Models.”</span> <em>Transactions of the Association for Computational Linguistics</em> 4: 287–300. <a href="https://doi.org/10.1162/tacl_a_00099">https://doi.org/10.1162/tacl_a_00099</a>.
</div>
<div class="csl-entry">
Selivanov, Dmitriy, and Qing Wang. 2018. <em>Text2vec: Modern Text Mining Framework for r</em>. <a href="https://CRAN.R-project.org/package=text2vec">https://CRAN.R-project.org/package=text2vec</a>.
</div>
<div class="csl-entry">
Sheng, Emily, Kai-Wei Chang, Premkumar Natarajan, and Nanyun Peng. 2019. <span>“The Woman Worked as a Babysitter: On Biases in Language Generation.”</span> <a href="http://arxiv.org/abs/1909.01326">http://arxiv.org/abs/1909.01326</a>.
</div>
<div class="csl-entry">
Shrikumar, Avanti, Peyton Greenside, and Anshul Kundaje. 2019. <span>“Learning Important Features Through Propagating Activation Differences.”</span> <a href="http://arxiv.org/abs/1704.02685">http://arxiv.org/abs/1704.02685</a>.
</div>
<div class="csl-entry">
Shwartz-Ziv, Ravid, and Naftali Tishby. 2017. <span>“Opening the Black Box of Deep Neural Networks via Information.”</span> <a href="http://arxiv.org/abs/1703.00810">http://arxiv.org/abs/1703.00810</a>.
</div>
<div class="csl-entry">
Silge, Julia, and David Robinson. 2016. <span>“Tidytext: Text Mining and Analysis Using Tidy Data Principles in r.”</span> <em>JOSS</em> 1 (3). <a href="https://doi.org/10.21105/joss.00037">https://doi.org/10.21105/joss.00037</a>.
</div>
<div class="csl-entry">
———. 2017. <em>Text Mining with r: A Tidy Approach</em>. 1st ed. O’Reilly Media, Inc.
</div>
<div class="csl-entry">
Speer, Robyn. 2017. <span>“How to Make a Racist AI Without Really Trying.”</span> <em>ConceptNet Blog</em>. <a href="http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/">http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/</a>.
</div>
<div class="csl-entry">
Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. <span>“Dropout: A Simple Way to Prevent Neural Networks from Overfitting.”</span> <em>Journal of Machine Learning Research</em> 15 (56): 1929–58. <a href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a>.
</div>
<div class="csl-entry">
Sugisaki, Kyoko, and Don Tuggener. 2018. <span>“German Compound Splitting Using the Compound Productivity of Morphemes,”</span> October.
</div>
<div class="csl-entry">
Sweeney, Latanya. 2000. <span>“Simple Demographics Often Identify People Uniquely.”</span> <em>Health (San Francisco)</em> 671 (2000): 1–34.
</div>
<div class="csl-entry">
Tang, Cheng, Damien Garreau, and Ulrike von Luxburg. 2018. <span>“When Do Random Forests Fail?”</span> In <em>Advances in Neural Information Processing Systems</em>, 2983–93.
</div>
<div class="csl-entry">
Tibshirani, Robert. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 58 (1): 267–88.
</div>
<div class="csl-entry">
<span>“Unicode Text Segmentation.”</span> 2019. <a href="https://www.unicode.org/reports/tr29/tr29-35.html#Default_Word_Boundaries">https://www.unicode.org/reports/tr29/tr29-35.html#Default_Word_Boundaries</a>.
</div>
<div class="csl-entry">
Ushey, Kevin, JJ Allaire, and Yuan Tang. 2020. <em>Reticulate: Interface to ’Python’</em>. <a href="https://github.com/rstudio/reticulate">https://github.com/rstudio/reticulate</a>.
</div>
<div class="csl-entry">
Van-Tu, Nguyen, and Le Anh-Cuong. 2016. <span>“Improving Question Classification by Feature Extraction and Selection.”</span> <em>Indian Journal of Science and Technology</em> 9 (May). <a href="https://doi.org/10.17485/ijst/2016/v9i17/93160">https://doi.org/10.17485/ijst/2016/v9i17/93160</a>.
</div>
<div class="csl-entry">
Vaughan, Davis. 2020. <em>Slider: Sliding Window Functions</em>. <a href="https://CRAN.R-project.org/package=slider">https://CRAN.R-project.org/package=slider</a>.
</div>
<div class="csl-entry">
Vaughan, Davis, and Matt Dancho. 2018. <em>Furrr: Apply Mapping Functions in Parallel Using Futures</em>. <a href="https://CRAN.R-project.org/package=furrr">https://CRAN.R-project.org/package=furrr</a>.
</div>
<div class="csl-entry">
Vosoughi, Soroush, Prashanth Vijayaraghavan, and Deb Roy. 2016. <span>“Tweet2Vec: Learning Tweet Embeddings Using Character-Level CNN-LSTM Encoder-Decoder.”</span> In, 1041–44. <a href="https://doi.org/10.1145/2911451.2914762">https://doi.org/10.1145/2911451.2914762</a>.
</div>
<div class="csl-entry">
Wagner, Claudia, Eduardo Graells-Garrido, David Garcia, and Filippo Menczer. 2016. <span>“Women Through the Glass Ceiling: Gender Asymmetries in Wikipedia.”</span> <em>EPJ Data Science</em> 5 (1): 5.
</div>
<div class="csl-entry">
Weinberger, Kilian, Anirban Dasgupta, John Langford, Alex Smola, and Josh Attenberg. 2009. <span>“Feature Hashing for Large Scale Multitask Learning.”</span> In <em>Proceedings of the 26th Annual International Conference on Machine Learning</em>, 1113–20. ICML ’09. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/1553374.1553516">https://doi.org/10.1145/1553374.1553516</a>.
</div>
<div class="csl-entry">
Wickham, Hadley. 2019. <em>Stringr: Simple<span>,</span> Consistent Wrappers for Common String Operations</em>. <a href="https://CRAN.R-project.org/package=stringr">https://CRAN.R-project.org/package=stringr</a>.
</div>
<div class="csl-entry">
———. 2020. <em>Httr: Tools for Working with URLs and HTTP</em>. <a href="https://CRAN.R-project.org/package=httr">https://CRAN.R-project.org/package=httr</a>.
</div>
<div class="csl-entry">
Wickham, Hadley, and Garrett Grolemund. 2017. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. 1st ed. O’Reilly Media, Inc.
</div>
<div class="csl-entry">
Wickham, Hadley, and Jim Hester. 2020. <em>Readr: Read Rectangular Text Data</em>. <a href="https://CRAN.R-project.org/package=readr">https://CRAN.R-project.org/package=readr</a>.
</div>
<div class="csl-entry">
Willett, P. 2006. <span>“The Porter Stemming Algorithm: Then and Now.”</span> <em>Program: Electronic Library and Information Systems</em> 40 (3): 219–23. <a href="http://eprints.whiterose.ac.uk/1434/">http://eprints.whiterose.ac.uk/1434/</a>.
</div>
<div class="csl-entry">
Zhang, Xiang, Junbo Zhao, and Yann LeCun. 2015. <span>“Character-Level Convolutional Networks for Text Classification.”</span> In <em>Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1</em>, 649–57. NIPS’15. Cambridge, MA, USA: MIT Press.
</div>
<div class="csl-entry">
Zou, Feng, Fu Lee Wang, Xiaotie Deng, and Song Han. 2006. <span>“Evaluation of Stop Word Lists in Chinese Language,”</span> January.
</div>
<div class="csl-entry">
Zou, Feng, Fu Lee Wang, Xiaotie Deng, Song Han, and Lu Sheng Wang. 2006. <span>“Automatic Construction of Chinese Stop Word List.”</span> In <em>Proceedings of the 5th WSEAS International Conference on Applied Computer Science</em>, 1009–14. ACOS’06. Stevens Point, Wisconsin, USA: World Scientific; Engineering Academy; Society (WSEAS). <a href="http://dl.acm.org/citation.cfm?id=1973598.1973793">http://dl.acm.org/citation.cfm?id=1973598.1973793</a>.
</div>
</div>
</div>






















            </section>

          </div>
        </div>
      </div>
<a href="appendixbaseline.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": null,
"edit": {
"link": "https://github.com/EmilHvitfeldt/smltar/edit/master/references.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

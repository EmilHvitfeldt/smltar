<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>References | Supervised Machine Learning for Text Analysis in R</title>
  <meta name="description" content="References | Supervised Machine Learning for Text Analysis in R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="References | Supervised Machine Learning for Text Analysis in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="References | Supervised Machine Learning for Text Analysis in R" />
  <meta name="github-repo" content="EmilHvitfeldt/smltar" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="References | Supervised Machine Learning for Text Analysis in R" />
  
  <meta name="twitter:description" content="References | Supervised Machine Learning for Text Analysis in R" />
  

<meta name="author" content="Emil Hvitfeldt and Julia Silge" />


<meta name="date" content="2021-07-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="appendixbaseline.html"/>

<script src="libs/header-attrs-2.9.4/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/plot_text_explanations-0.1.0/plot_text_explanations.css" rel="stylesheet" />
<script src="libs/plot_text_explanations-binding-0.5.2/plot_text_explanations.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="smltar.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Supervised Machine Learning for Text Analysis in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome to Supervised Machine Learning for Text Analysis in R</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#topics-this-book-will-not-cover"><i class="fa fa-check"></i>Topics this book will not cover</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who is this book for?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#colophon"><i class="fa fa-check"></i>Colophon</a></li>
</ul></li>
<li class="part"><span><b>I Natural Language Features</b></span></li>
<li class="chapter" data-level="1" data-path="language.html"><a href="language.html"><i class="fa fa-check"></i><b>1</b> Language and modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="language.html"><a href="language.html#linguistics-for-text-analysis"><i class="fa fa-check"></i><b>1.1</b> Linguistics for text analysis</a></li>
<li class="chapter" data-level="1.2" data-path="language.html"><a href="language.html#morphology"><i class="fa fa-check"></i><b>1.2</b> A glimpse into one area: morphology</a></li>
<li class="chapter" data-level="1.3" data-path="language.html"><a href="language.html#different-languages"><i class="fa fa-check"></i><b>1.3</b> Different languages</a></li>
<li class="chapter" data-level="1.4" data-path="language.html"><a href="language.html#other-ways-text-can-vary"><i class="fa fa-check"></i><b>1.4</b> Other ways text can vary</a></li>
<li class="chapter" data-level="1.5" data-path="language.html"><a href="language.html#languagesummary"><i class="fa fa-check"></i><b>1.5</b> Summary</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="language.html"><a href="language.html#in-this-chapter-you-learned"><i class="fa fa-check"></i><b>1.5.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tokenization.html"><a href="tokenization.html"><i class="fa fa-check"></i><b>2</b> Tokenization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tokenization.html"><a href="tokenization.html#what-is-a-token"><i class="fa fa-check"></i><b>2.1</b> What is a token?</a></li>
<li class="chapter" data-level="2.2" data-path="tokenization.html"><a href="tokenization.html#types-of-tokens"><i class="fa fa-check"></i><b>2.2</b> Types of tokens</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="tokenization.html"><a href="tokenization.html#character-tokens"><i class="fa fa-check"></i><b>2.2.1</b> Character tokens</a></li>
<li class="chapter" data-level="2.2.2" data-path="tokenization.html"><a href="tokenization.html#word-tokens"><i class="fa fa-check"></i><b>2.2.2</b> Word tokens</a></li>
<li class="chapter" data-level="2.2.3" data-path="tokenization.html"><a href="tokenization.html#tokenizingngrams"><i class="fa fa-check"></i><b>2.2.3</b> Tokenizing by n-grams</a></li>
<li class="chapter" data-level="2.2.4" data-path="tokenization.html"><a href="tokenization.html#lines-sentence-and-paragraph-tokens"><i class="fa fa-check"></i><b>2.2.4</b> Lines, sentence, and paragraph tokens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="tokenization.html"><a href="tokenization.html#where-does-tokenization-break-down"><i class="fa fa-check"></i><b>2.3</b> Where does tokenization break down?</a></li>
<li class="chapter" data-level="2.4" data-path="tokenization.html"><a href="tokenization.html#building-your-own-tokenizer"><i class="fa fa-check"></i><b>2.4</b> Building your own tokenizer</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="tokenization.html"><a href="tokenization.html#tokenize-to-characters-only-keeping-letters"><i class="fa fa-check"></i><b>2.4.1</b> Tokenize to characters, only keeping letters</a></li>
<li class="chapter" data-level="2.4.2" data-path="tokenization.html"><a href="tokenization.html#allow-for-hyphenated-words"><i class="fa fa-check"></i><b>2.4.2</b> Allow for hyphenated words</a></li>
<li class="chapter" data-level="2.4.3" data-path="tokenization.html"><a href="tokenization.html#wrapping-it-in-a-function"><i class="fa fa-check"></i><b>2.4.3</b> Wrapping it in a function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tokenization.html"><a href="tokenization.html#tokenization-for-non-latin-alphabets"><i class="fa fa-check"></i><b>2.5</b> Tokenization for non-Latin alphabets</a></li>
<li class="chapter" data-level="2.6" data-path="tokenization.html"><a href="tokenization.html#tokenization-benchmark"><i class="fa fa-check"></i><b>2.6</b> Tokenization benchmark</a></li>
<li class="chapter" data-level="2.7" data-path="tokenization.html"><a href="tokenization.html#tokensummary"><i class="fa fa-check"></i><b>2.7</b> Summary</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="tokenization.html"><a href="tokenization.html#in-this-chapter-you-learned-1"><i class="fa fa-check"></i><b>2.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stopwords.html"><a href="stopwords.html"><i class="fa fa-check"></i><b>3</b> Stop words</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stopwords.html"><a href="stopwords.html#premadestopwords"><i class="fa fa-check"></i><b>3.1</b> Using premade stop word lists</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="stopwords.html"><a href="stopwords.html#stop-word-removal-in-r"><i class="fa fa-check"></i><b>3.1.1</b> Stop word removal in R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="stopwords.html"><a href="stopwords.html#homemadestopwords"><i class="fa fa-check"></i><b>3.2</b> Creating your own stop words list</a></li>
<li class="chapter" data-level="3.3" data-path="stopwords.html"><a href="stopwords.html#all-stop-word-lists-are-context-specific"><i class="fa fa-check"></i><b>3.3</b> All stop word lists are context-specific</a></li>
<li class="chapter" data-level="3.4" data-path="stopwords.html"><a href="stopwords.html#what-happens-when-you-remove-stop-words"><i class="fa fa-check"></i><b>3.4</b> What happens when you remove stop words</a></li>
<li class="chapter" data-level="3.5" data-path="stopwords.html"><a href="stopwords.html#stop-words-in-languages-other-than-english"><i class="fa fa-check"></i><b>3.5</b> Stop words in languages other than English</a></li>
<li class="chapter" data-level="3.6" data-path="stopwords.html"><a href="stopwords.html#stopwordssummary"><i class="fa fa-check"></i><b>3.6</b> Summary</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="stopwords.html"><a href="stopwords.html#in-this-chapter-you-learned-2"><i class="fa fa-check"></i><b>3.6.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stemming.html"><a href="stemming.html"><i class="fa fa-check"></i><b>4</b> Stemming</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stemming.html"><a href="stemming.html#how-to-stem-text-in-r"><i class="fa fa-check"></i><b>4.1</b> How to stem text in R</a></li>
<li class="chapter" data-level="4.2" data-path="stemming.html"><a href="stemming.html#should-you-use-stemming-at-all"><i class="fa fa-check"></i><b>4.2</b> Should you use stemming at all?</a></li>
<li class="chapter" data-level="4.3" data-path="stemming.html"><a href="stemming.html#understand-a-stemming-algorithm"><i class="fa fa-check"></i><b>4.3</b> Understand a stemming algorithm</a></li>
<li class="chapter" data-level="4.4" data-path="stemming.html"><a href="stemming.html#handling-punctuation-when-stemming"><i class="fa fa-check"></i><b>4.4</b> Handling punctuation when stemming</a></li>
<li class="chapter" data-level="4.5" data-path="stemming.html"><a href="stemming.html#compare-some-stemming-options"><i class="fa fa-check"></i><b>4.5</b> Compare some stemming options</a></li>
<li class="chapter" data-level="4.6" data-path="stemming.html"><a href="stemming.html#lemmatization"><i class="fa fa-check"></i><b>4.6</b> Lemmatization and stemming</a></li>
<li class="chapter" data-level="4.7" data-path="stemming.html"><a href="stemming.html#stemming-and-stop-words"><i class="fa fa-check"></i><b>4.7</b> Stemming and stop words</a></li>
<li class="chapter" data-level="4.8" data-path="stemming.html"><a href="stemming.html#stemmingsummary"><i class="fa fa-check"></i><b>4.8</b> Summary</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="stemming.html"><a href="stemming.html#in-this-chapter-you-learned-3"><i class="fa fa-check"></i><b>4.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="embeddings.html"><a href="embeddings.html"><i class="fa fa-check"></i><b>5</b> Word Embeddings</a>
<ul>
<li class="chapter" data-level="5.1" data-path="embeddings.html"><a href="embeddings.html#motivatingsparse"><i class="fa fa-check"></i><b>5.1</b> Motivating embeddings for sparse, high-dimensional data</a></li>
<li class="chapter" data-level="5.2" data-path="embeddings.html"><a href="embeddings.html#understand-word-embeddings-by-finding-them-yourself"><i class="fa fa-check"></i><b>5.2</b> Understand word embeddings by finding them yourself</a></li>
<li class="chapter" data-level="5.3" data-path="embeddings.html"><a href="embeddings.html#exploring-cfpb-word-embeddings"><i class="fa fa-check"></i><b>5.3</b> Exploring CFPB word embeddings</a></li>
<li class="chapter" data-level="5.4" data-path="embeddings.html"><a href="embeddings.html#glove"><i class="fa fa-check"></i><b>5.4</b> Use pre-trained word embeddings</a></li>
<li class="chapter" data-level="5.5" data-path="embeddings.html"><a href="embeddings.html#fairnessembeddings"><i class="fa fa-check"></i><b>5.5</b> Fairness and word embeddings</a></li>
<li class="chapter" data-level="5.6" data-path="embeddings.html"><a href="embeddings.html#using-word-embeddings-in-the-real-world"><i class="fa fa-check"></i><b>5.6</b> Using word embeddings in the real world</a></li>
<li class="chapter" data-level="5.7" data-path="embeddings.html"><a href="embeddings.html#embeddingssummary"><i class="fa fa-check"></i><b>5.7</b> Summary</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="embeddings.html"><a href="embeddings.html#in-this-chapter-you-learned-4"><i class="fa fa-check"></i><b>5.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Machine Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#should-we-even-be-doing-this"><i class="fa fa-check"></i>Should we even be doing this?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-bias-is-already-in-the-data"><i class="fa fa-check"></i>What bias is already in the data?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#can-the-code-and-data-be-audited"><i class="fa fa-check"></i>Can the code and data be audited?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-are-the-error-rates-for-sub-groups"><i class="fa fa-check"></i>What are the error rates for sub-groups?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-is-the-accuracy-of-a-simple-rule-based-alternative"><i class="fa fa-check"></i>What is the accuracy of a simple rule-based alternative?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-processes-are-in-place-to-handle-appeals-or-mistakes"><i class="fa fa-check"></i>What processes are in place to handle appeals or mistakes?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#how-diverse-is-the-team-that-built-it"><i class="fa fa-check"></i>How diverse is the team that built it?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mlregression.html"><a href="mlregression.html"><i class="fa fa-check"></i><b>6</b> Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mlregression.html"><a href="mlregression.html#firstmlregression"><i class="fa fa-check"></i><b>6.1</b> A first regression model</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="mlregression.html"><a href="mlregression.html#firstregression"><i class="fa fa-check"></i><b>6.1.1</b> Building our first regression model</a></li>
<li class="chapter" data-level="6.1.2" data-path="mlregression.html"><a href="mlregression.html#firstregressionevaluation"><i class="fa fa-check"></i><b>6.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="mlregression.html"><a href="mlregression.html#regnull"><i class="fa fa-check"></i><b>6.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="6.3" data-path="mlregression.html"><a href="mlregression.html#comparerf"><i class="fa fa-check"></i><b>6.3</b> Compare to a random forest model</a></li>
<li class="chapter" data-level="6.4" data-path="mlregression.html"><a href="mlregression.html#casestudystopwords"><i class="fa fa-check"></i><b>6.4</b> Case study: removing stop words</a></li>
<li class="chapter" data-level="6.5" data-path="mlregression.html"><a href="mlregression.html#casestudyngrams"><i class="fa fa-check"></i><b>6.5</b> Case study: varying n-grams</a></li>
<li class="chapter" data-level="6.6" data-path="mlregression.html"><a href="mlregression.html#mlregressionlemmatization"><i class="fa fa-check"></i><b>6.6</b> Case study: lemmatization</a></li>
<li class="chapter" data-level="6.7" data-path="mlregression.html"><a href="mlregression.html#case-study-feature-hashing"><i class="fa fa-check"></i><b>6.7</b> Case study: feature hashing</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="mlregression.html"><a href="mlregression.html#text-normalization"><i class="fa fa-check"></i><b>6.7.1</b> Text normalization</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="mlregression.html"><a href="mlregression.html#what-evaluation-metrics-are-appropriate"><i class="fa fa-check"></i><b>6.8</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="6.9" data-path="mlregression.html"><a href="mlregression.html#mlregressionfull"><i class="fa fa-check"></i><b>6.9</b> The full game: regression</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="mlregression.html"><a href="mlregression.html#preprocess-the-data"><i class="fa fa-check"></i><b>6.9.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="6.9.2" data-path="mlregression.html"><a href="mlregression.html#specify-the-model"><i class="fa fa-check"></i><b>6.9.2</b> Specify the model</a></li>
<li class="chapter" data-level="6.9.3" data-path="mlregression.html"><a href="mlregression.html#tune-the-model"><i class="fa fa-check"></i><b>6.9.3</b> Tune the model</a></li>
<li class="chapter" data-level="6.9.4" data-path="mlregression.html"><a href="mlregression.html#regression-final-evaluation"><i class="fa fa-check"></i><b>6.9.4</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="mlregression.html"><a href="mlregression.html#mlregressionsummary"><i class="fa fa-check"></i><b>6.10</b> Summary</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="mlregression.html"><a href="mlregression.html#in-this-chapter-you-learned-5"><i class="fa fa-check"></i><b>6.10.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mlclassification.html"><a href="mlclassification.html"><i class="fa fa-check"></i><b>7</b> Classification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstattemptlookatdata"><i class="fa fa-check"></i><b>7.1</b> A first classification model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstmodel"><i class="fa fa-check"></i><b>7.1.1</b> Building our first classification model</a></li>
<li class="chapter" data-level="7.1.2" data-path="mlclassification.html"><a href="mlclassification.html#evaluation"><i class="fa fa-check"></i><b>7.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="mlclassification.html"><a href="mlclassification.html#classnull"><i class="fa fa-check"></i><b>7.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="7.3" data-path="mlclassification.html"><a href="mlclassification.html#comparetolasso"><i class="fa fa-check"></i><b>7.3</b> Compare to a lasso classification model</a></li>
<li class="chapter" data-level="7.4" data-path="mlclassification.html"><a href="mlclassification.html#tunelasso"><i class="fa fa-check"></i><b>7.4</b> Tuning lasso hyperparameters</a></li>
<li class="chapter" data-level="7.5" data-path="mlclassification.html"><a href="mlclassification.html#casestudysparseencoding"><i class="fa fa-check"></i><b>7.5</b> Case study: sparse encoding</a></li>
<li class="chapter" data-level="7.6" data-path="mlclassification.html"><a href="mlclassification.html#mlmulticlass"><i class="fa fa-check"></i><b>7.6</b> Two-class or multiclass?</a></li>
<li class="chapter" data-level="7.7" data-path="mlclassification.html"><a href="mlclassification.html#case-study-including-non-text-data"><i class="fa fa-check"></i><b>7.7</b> Case study: including non-text data</a></li>
<li class="chapter" data-level="7.8" data-path="mlclassification.html"><a href="mlclassification.html#case-study-data-censoring"><i class="fa fa-check"></i><b>7.8</b> Case study: data censoring</a></li>
<li class="chapter" data-level="7.9" data-path="mlclassification.html"><a href="mlclassification.html#customfeatures"><i class="fa fa-check"></i><b>7.9</b> Case study: custom features</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="mlclassification.html"><a href="mlclassification.html#detect-credit-cards"><i class="fa fa-check"></i><b>7.9.1</b> Detect credit cards</a></li>
<li class="chapter" data-level="7.9.2" data-path="mlclassification.html"><a href="mlclassification.html#calculate-percentage-censoring"><i class="fa fa-check"></i><b>7.9.2</b> Calculate percentage censoring</a></li>
<li class="chapter" data-level="7.9.3" data-path="mlclassification.html"><a href="mlclassification.html#detect-monetary-amounts"><i class="fa fa-check"></i><b>7.9.3</b> Detect monetary amounts</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="mlclassification.html"><a href="mlclassification.html#what-evaluation-metrics-are-appropriate-1"><i class="fa fa-check"></i><b>7.10</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="7.11" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationfull"><i class="fa fa-check"></i><b>7.11</b> The full game: classification</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="mlclassification.html"><a href="mlclassification.html#feature-selection"><i class="fa fa-check"></i><b>7.11.1</b> Feature selection</a></li>
<li class="chapter" data-level="7.11.2" data-path="mlclassification.html"><a href="mlclassification.html#specify-the-model-1"><i class="fa fa-check"></i><b>7.11.2</b> Specify the model</a></li>
<li class="chapter" data-level="7.11.3" data-path="mlclassification.html"><a href="mlclassification.html#classification-final-evaluation"><i class="fa fa-check"></i><b>7.11.3</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationsummary"><i class="fa fa-check"></i><b>7.12</b> Summary</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="mlclassification.html"><a href="mlclassification.html#in-this-chapter-you-learned-6"><i class="fa fa-check"></i><b>7.12.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Deep Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#spending-your-data-budget"><i class="fa fa-check"></i>Spending your data budget</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#feature-engineering"><i class="fa fa-check"></i>Feature engineering</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#fitting-and-tuning"><i class="fa fa-check"></i>Fitting and tuning</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#model-evaluation"><i class="fa fa-check"></i>Model evaluation</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#putting-the-model-process-in-context"><i class="fa fa-check"></i>Putting the model process in context</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="dldnn.html"><a href="dldnn.html"><i class="fa fa-check"></i><b>8</b> Dense neural networks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dldnn.html"><a href="dldnn.html#kickstarter"><i class="fa fa-check"></i><b>8.1</b> Kickstarter data</a></li>
<li class="chapter" data-level="8.2" data-path="dldnn.html"><a href="dldnn.html#firstdlclassification"><i class="fa fa-check"></i><b>8.2</b> A first deep learning model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="dldnn.html"><a href="dldnn.html#dnnrecipe"><i class="fa fa-check"></i><b>8.2.1</b> Preprocessing for deep learning</a></li>
<li class="chapter" data-level="8.2.2" data-path="dldnn.html"><a href="dldnn.html#onehotsequence"><i class="fa fa-check"></i><b>8.2.2</b> One-hot sequence embedding of text</a></li>
<li class="chapter" data-level="8.2.3" data-path="dldnn.html"><a href="dldnn.html#simple-flattened-dense-network"><i class="fa fa-check"></i><b>8.2.3</b> Simple flattened dense network</a></li>
<li class="chapter" data-level="8.2.4" data-path="dldnn.html"><a href="dldnn.html#evaluate-dnn"><i class="fa fa-check"></i><b>8.2.4</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="dldnn.html"><a href="dldnn.html#using-bag-of-words-features"><i class="fa fa-check"></i><b>8.3</b> Using bag-of-words features</a></li>
<li class="chapter" data-level="8.4" data-path="dldnn.html"><a href="dldnn.html#using-pre-trained-word-embeddings"><i class="fa fa-check"></i><b>8.4</b> Using pre-trained word embeddings</a></li>
<li class="chapter" data-level="8.5" data-path="dldnn.html"><a href="dldnn.html#dnncross"><i class="fa fa-check"></i><b>8.5</b> Cross-validation for deep learning models</a></li>
<li class="chapter" data-level="8.6" data-path="dldnn.html"><a href="dldnn.html#compare-and-evaluate-dnn-models"><i class="fa fa-check"></i><b>8.6</b> Compare and evaluate DNN models</a></li>
<li class="chapter" data-level="8.7" data-path="dldnn.html"><a href="dldnn.html#dllimitations"><i class="fa fa-check"></i><b>8.7</b> Limitations of deep learning</a></li>
<li class="chapter" data-level="8.8" data-path="dldnn.html"><a href="dldnn.html#dldnnsummary"><i class="fa fa-check"></i><b>8.8</b> Summary</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="dldnn.html"><a href="dldnn.html#in-this-chapter-you-learned-7"><i class="fa fa-check"></i><b>8.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dllstm.html"><a href="dllstm.html"><i class="fa fa-check"></i><b>9</b> Long short-term memory (LSTM) networks</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dllstm.html"><a href="dllstm.html#firstlstm"><i class="fa fa-check"></i><b>9.1</b> A first LSTM model</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="dllstm.html"><a href="dllstm.html#building-an-lstm"><i class="fa fa-check"></i><b>9.1.1</b> Building an LSTM</a></li>
<li class="chapter" data-level="9.1.2" data-path="dllstm.html"><a href="dllstm.html#lstmevaluation"><i class="fa fa-check"></i><b>9.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="dllstm.html"><a href="dllstm.html#compare-to-a-recurrent-neural-network"><i class="fa fa-check"></i><b>9.2</b> Compare to a recurrent neural network</a></li>
<li class="chapter" data-level="9.3" data-path="dllstm.html"><a href="dllstm.html#bilstm"><i class="fa fa-check"></i><b>9.3</b> Case study: bidirectional LSTM</a></li>
<li class="chapter" data-level="9.4" data-path="dllstm.html"><a href="dllstm.html#case-study-stacking-lstm-layers"><i class="fa fa-check"></i><b>9.4</b> Case study: stacking LSTM layers</a></li>
<li class="chapter" data-level="9.5" data-path="dllstm.html"><a href="dllstm.html#lstmpadding"><i class="fa fa-check"></i><b>9.5</b> Case study: padding</a></li>
<li class="chapter" data-level="9.6" data-path="dllstm.html"><a href="dllstm.html#case-study-training-a-regression-model"><i class="fa fa-check"></i><b>9.6</b> Case study: training a regression model</a></li>
<li class="chapter" data-level="9.7" data-path="dllstm.html"><a href="dllstm.html#case-study-vocabulary-size"><i class="fa fa-check"></i><b>9.7</b> Case study: vocabulary size</a></li>
<li class="chapter" data-level="9.8" data-path="dllstm.html"><a href="dllstm.html#lstmfull"><i class="fa fa-check"></i><b>9.8</b> The full game: LSTM</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="dllstm.html"><a href="dllstm.html#lstmfullpreprocess"><i class="fa fa-check"></i><b>9.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="9.8.2" data-path="dllstm.html"><a href="dllstm.html#lstmfullmodel"><i class="fa fa-check"></i><b>9.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="dllstm.html"><a href="dllstm.html#dllstmsummary"><i class="fa fa-check"></i><b>9.9</b> Summary</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="dllstm.html"><a href="dllstm.html#in-this-chapter-you-learned-8"><i class="fa fa-check"></i><b>9.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dlcnn.html"><a href="dlcnn.html"><i class="fa fa-check"></i><b>10</b> Convolutional neural networks</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dlcnn.html"><a href="dlcnn.html#what-are-cnns"><i class="fa fa-check"></i><b>10.1</b> What are CNNs?</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="dlcnn.html"><a href="dlcnn.html#kernel"><i class="fa fa-check"></i><b>10.1.1</b> Kernel</a></li>
<li class="chapter" data-level="10.1.2" data-path="dlcnn.html"><a href="dlcnn.html#kernel-size"><i class="fa fa-check"></i><b>10.1.2</b> Kernel size</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="dlcnn.html"><a href="dlcnn.html#firstcnn"><i class="fa fa-check"></i><b>10.2</b> A first CNN model</a></li>
<li class="chapter" data-level="10.3" data-path="dlcnn.html"><a href="dlcnn.html#case-study-adding-more-layers"><i class="fa fa-check"></i><b>10.3</b> Case study: adding more layers</a></li>
<li class="chapter" data-level="10.4" data-path="dlcnn.html"><a href="dlcnn.html#case-study-byte-pair-encoding"><i class="fa fa-check"></i><b>10.4</b> Case study: byte pair encoding</a></li>
<li class="chapter" data-level="10.5" data-path="dlcnn.html"><a href="dlcnn.html#lime"><i class="fa fa-check"></i><b>10.5</b> Case study: explainability with LIME</a></li>
<li class="chapter" data-level="10.6" data-path="dlcnn.html"><a href="dlcnn.html#keras-hyperparameter"><i class="fa fa-check"></i><b>10.6</b> Case study: hyperparameter search</a></li>
<li class="chapter" data-level="10.7" data-path="dlcnn.html"><a href="dlcnn.html#cross-validation-for-evaluation"><i class="fa fa-check"></i><b>10.7</b> Cross-validation for evaluation</a></li>
<li class="chapter" data-level="10.8" data-path="dlcnn.html"><a href="dlcnn.html#cnnfull"><i class="fa fa-check"></i><b>10.8</b> The full game: CNN</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullpreprocess"><i class="fa fa-check"></i><b>10.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="10.8.2" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullmodel"><i class="fa fa-check"></i><b>10.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="dlcnn.html"><a href="dlcnn.html#dlcnnsummary"><i class="fa fa-check"></i><b>10.9</b> Summary</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="dlcnn.html"><a href="dlcnn.html#in-this-chapter-you-learned-9"><i class="fa fa-check"></i><b>10.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="" data-path="text-models-in-the-real-world.html"><a href="text-models-in-the-real-world.html"><i class="fa fa-check"></i>Text models in the real world</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="regexp.html"><a href="regexp.html"><i class="fa fa-check"></i><b>A</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="A.1" data-path="regexp.html"><a href="regexp.html#literal-characters"><i class="fa fa-check"></i><b>A.1</b> Literal characters</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="regexp.html"><a href="regexp.html#meta-characters"><i class="fa fa-check"></i><b>A.1.1</b> Meta characters</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="regexp.html"><a href="regexp.html#full-stop-the-wildcard"><i class="fa fa-check"></i><b>A.2</b> Full stop, the wildcard</a></li>
<li class="chapter" data-level="A.3" data-path="regexp.html"><a href="regexp.html#character-classes"><i class="fa fa-check"></i><b>A.3</b> Character classes</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="regexp.html"><a href="regexp.html#shorthand-character-classes"><i class="fa fa-check"></i><b>A.3.1</b> Shorthand character classes</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="regexp.html"><a href="regexp.html#quantifiers"><i class="fa fa-check"></i><b>A.4</b> Quantifiers</a></li>
<li class="chapter" data-level="A.5" data-path="regexp.html"><a href="regexp.html#anchors"><i class="fa fa-check"></i><b>A.5</b> Anchors</a></li>
<li class="chapter" data-level="A.6" data-path="regexp.html"><a href="regexp.html#additional-resources"><i class="fa fa-check"></i><b>A.6</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixdata.html"><a href="appendixdata.html"><i class="fa fa-check"></i><b>B</b> Data</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixdata.html"><a href="appendixdata.html#hcandersen"><i class="fa fa-check"></i><b>B.1</b> Hans Christian Andersen fairy tales</a></li>
<li class="chapter" data-level="B.2" data-path="appendixdata.html"><a href="appendixdata.html#scotus-opinions"><i class="fa fa-check"></i><b>B.2</b> Opinions of the Supreme Court of the United States</a></li>
<li class="chapter" data-level="B.3" data-path="appendixdata.html"><a href="appendixdata.html#cfpb-complaints"><i class="fa fa-check"></i><b>B.3</b> Consumer Financial Protection Bureau (CFPB) complaints</a></li>
<li class="chapter" data-level="B.4" data-path="appendixdata.html"><a href="appendixdata.html#kickstarter-blurbs"><i class="fa fa-check"></i><b>B.4</b> Kickstarter campaign blurbs</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appendixbaseline.html"><a href="appendixbaseline.html"><i class="fa fa-check"></i><b>C</b> Baseline linear classifier</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appendixbaseline.html"><a href="appendixbaseline.html#read-in-the-data"><i class="fa fa-check"></i><b>C.1</b> Read in the data</a></li>
<li class="chapter" data-level="C.2" data-path="appendixbaseline.html"><a href="appendixbaseline.html#split-into-testtrain-and-create-resampling-folds"><i class="fa fa-check"></i><b>C.2</b> Split into test/train and create resampling folds</a></li>
<li class="chapter" data-level="C.3" data-path="appendixbaseline.html"><a href="appendixbaseline.html#recipe-for-data-preprocessing"><i class="fa fa-check"></i><b>C.3</b> Recipe for data preprocessing</a></li>
<li class="chapter" data-level="C.4" data-path="appendixbaseline.html"><a href="appendixbaseline.html#lasso-regularized-classification-model"><i class="fa fa-check"></i><b>C.4</b> Lasso regularized classification model</a></li>
<li class="chapter" data-level="C.5" data-path="appendixbaseline.html"><a href="appendixbaseline.html#a-model-workflow"><i class="fa fa-check"></i><b>C.5</b> A model workflow</a></li>
<li class="chapter" data-level="C.6" data-path="appendixbaseline.html"><a href="appendixbaseline.html#tune-the-workflow"><i class="fa fa-check"></i><b>C.6</b> Tune the workflow</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supervised Machine Learning for Text Analysis in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Allaire, J., and Chollet, F. 2021. <em><span class="nocase">keras</span>: R Interface to <span>‘Keras’</span></em>. R package version 2.4.0. <a href="https://CRAN.R-project.org/package=keras">https://CRAN.R-project.org/package=keras</a>.
</div>
<div class="csl-entry">
Appleby, A. 2008. <span>“MurmurHash.”</span> <a href="https://sites.google.com/site/murmurhash">https://sites.google.com/site/murmurhash</a>.
</div>
<div class="csl-entry">
Arnold, T. 2017. <span>“<span class="nocase">A Tidy Data Model for Natural Language Processing using cleanNLP</span>.”</span> <em><span>The R Journal</span></em> 9 (2): 248–267. <a href="https://doi.org/10.32614/RJ-2017-035">https://doi.org/10.32614/RJ-2017-035</a>.
</div>
<div class="csl-entry">
Bates, D., and Maechler, M. 2021. <em>Matrix: Sparse and Dense Matrix Classes and Methods</em>. R package version 1.3-2. <a href="https://CRAN.R-project.org/package=Matrix">https://CRAN.R-project.org/package=Matrix</a>.
</div>
<div class="csl-entry">
Bender, E. M. 2011. <span>“On Achieving and Evaluating Language-Independence in NLP.”</span> <em>Linguistic Issues in Language Technology</em> 6 (3): 1–26.
</div>
<div class="csl-entry">
Bender, E. M. 2013. <span>“Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax.”</span> <em>Synthesis Lectures on Human Language Technologies</em> 6 (3). Morgan &amp; Claypool Publishers: 1–184.
</div>
<div class="csl-entry">
Bender, E. M. 2019. <span>“The #BenderRule: On Naming the Languages We Study and Why It Matters.”</span> <em>The Gradient</em>. <a href="https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/">https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/</a>.
</div>
<div class="csl-entry">
Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. 2021. <span>“On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜.”</span> In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 610–623. FAccT ’21. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div class="csl-entry">
Benoit, K., and Matsuo, A. 2020. <em><span class="nocase">spacyr</span>: Wrapper to the <span>‘spaCy’</span> <span>‘NLP’</span> Library</em>. R package version 1.2.1. <a href="https://CRAN.R-project.org/package=spacyr">https://CRAN.R-project.org/package=spacyr</a>.
</div>
<div class="csl-entry">
Benoit, K., Muhr, D., and Watanabe, K. 2021. <em><span class="nocase">stopwords</span>: Multilingual Stopword Lists</em>. R package version 2.2. <a href="https://CRAN.R-project.org/package=stopwords">https://CRAN.R-project.org/package=stopwords</a>.
</div>
<div class="csl-entry">
Benoit, K., Watanabe, K., Wang, H., Nulty, P., Obeng, A., Müller, S., and Matsuo, A. 2018. <span>“<span class="nocase">quanteda</span>: An <span>R</span> Package for the Quantitative Analysis of Textual Data.”</span> <em>Journal of Open Source Software</em> 3 (30): 774. <a href="https://doi.org/10.21105/joss.00774">https://doi.org/10.21105/joss.00774</a>.
</div>
<div class="csl-entry">
Boehmke, B., and Greenwell, B. M. 2019. <em><span class="nocase">Hands-on Machine Learning with R</span></em>. Boca Raton: CRC Press.
</div>
<div class="csl-entry">
Bojanowski, P., Grave, E., Joulin, A., and Mikolov, T. 2017. <span>“Enriching Word Vectors with Subword Information.”</span> <em>Transactions of the Association for Computational Linguistics</em> 5: 135–146. <a href="https://www.aclweb.org/anthology/Q17-1010">https://www.aclweb.org/anthology/Q17-1010</a>.
</div>
<div class="csl-entry">
Bolukbasi, T., Chang, K.-W., Zou, J. Y., Saligrama, V., and Kalai, A. T. 2016. <span>“Quantifying and Reducing Stereotypes in Word Embeddings.”</span> <em>CoRR</em> abs/1606.06121. <a href="http://arxiv.org/abs/1606.06121">http://arxiv.org/abs/1606.06121</a>.
</div>
<div class="csl-entry">
Boser, B. E., Guyon, I. M., and Vapnik, V. N. 1992. <span>“A Training Algorithm for Optimal Margin Classifiers.”</span> In <em><span class="nocase">Proceedings of the Fifth Annual Workshop on Computational Learning Theory</span></em>, 144–152. COLT ’92. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/130385.130401">https://doi.org/10.1145/130385.130401</a>.
</div>
<div class="csl-entry">
Bouchet-Valat, M. 2020. <em>SnowballC: Snowball Stemmers Based on the <span>C</span> <span>‘<span class="nocase">libstemmer</span>’</span> UTF-8 Library</em>. R package version 0.7.0. <a href="https://CRAN.R-project.org/package=SnowballC">https://CRAN.R-project.org/package=SnowballC</a>.
</div>
<div class="csl-entry">
Breiman, L., Friedman, J., Stone, C. J., and Olshen, R. A. 1984. <em><span class="nocase">Classification and Regression Trees</span></em>. Boca Raton: CRC Press.
</div>
<div class="csl-entry">
Briscoe, T. 2013. <span>“Introduction to Linguistics for Natural Language Processing.”</span> <a href="https://www.cl.cam.ac.uk/teaching/1314/L100/introling.pdf">https://www.cl.cam.ac.uk/teaching/1314/L100/introling.pdf</a>.
</div>
<div class="csl-entry">
Caliskan, A., Bryson, J. J., and Narayanan, A. 2017. <span>“Semantics Derived Automatically from Language Corpora Contain Human-Like Biases.”</span> <em>Science</em> 356 (6334). American Association for the Advancement of Science: 183–186. <a href="https://science.sciencemag.org/content/356/6334/183">https://science.sciencemag.org/content/356/6334/183</a>.
</div>
<div class="csl-entry">
Carlini, N., Liu, C., Erlingsson, Ú., Kos, J., and Song, D. 2019. <span>“The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks.”</span> In <em>Proceedings of the 28th USENIX Conference on Security Symposium</em>, 267–284. SEC’19. USA: USENIX Association.
</div>
<div class="csl-entry">
Caruana, R., Karampatziakis, N., and Yessenalina, A. 2008. <span>“An Empirical Evaluation of Supervised Learning in High Dimensions.”</span> In <em>Proceedings of the 25th International Conference on Machine Learning</em>, 96–103. ICML ’08. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/1390156.1390169">https://doi.org/10.1145/1390156.1390169</a>.
</div>
<div class="csl-entry">
Chin, M. 2020. <span>“These Students Figured Out Their Tests Were Graded by AI.”</span> The Verge. <a href="https://www.theverge.com/2020/9/2/21419012/edgenuity-online-class-ai-grading-keyword-mashing-students-school-cheating-algorithm-glitch">https://www.theverge.com/2020/9/2/21419012/edgenuity-online-class-ai-grading-keyword-mashing-students-school-cheating-algorithm-glitch</a>.
</div>
<div class="csl-entry">
Chollet, F., and Allaire, J. J. 2018. <em>Deep Learning with <span>R</span></em>. Shelter Island, NY: Manning Publications. <a href="https://www.manning.com/books/deep-learning-with-r">https://www.manning.com/books/deep-learning-with-r</a>.
</div>
<div class="csl-entry">
Edmondson, M. 2020. <em><span class="nocase">googleLanguageR</span>: Call Google’s <span>‘Natural Language’</span> API, <span>‘Cloud Translation’</span> API, <span>‘Cloud Speech’</span> API and <span>‘Cloud Text-to-Speech’</span> API</em>. R package version 0.3.0. <a href="https://CRAN.R-project.org/package=googleLanguageR">https://CRAN.R-project.org/package=googleLanguageR</a>.
</div>
<div class="csl-entry">
Elman, J. L. 1990. <span>“Finding Structure in Time.”</span> <em>Cognitive Science</em> 14 (2): 179–211. <a href="https://doi.org/10.1207/s15516709cog1402_1">https://doi.org/10.1207/s15516709cog1402_1</a>.
</div>
<div class="csl-entry">
Ethayarajh, K., Duvenaud, D., and Hirst, G. 2019. <span>“Understanding Undesirable Word Embedding Associations.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 1696–1705. Florence, Italy: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/P19-1166">https://www.aclweb.org/anthology/P19-1166</a>.
</div>
<div class="csl-entry">
Feathers, T. 2019. <span>“Flawed Algorithms Are Grading Millions of Students’ Essays.”</span> <em>Motherboard</em>. VICE. <a href="https://www.vice.com/en/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays">https://www.vice.com/en/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays</a>.
</div>
<div class="csl-entry">
Feldman, R., and Sanger, J. 2007. <em>The Text Mining Handbook</em>. Cambridge: Cambridge University Press.
</div>
<div class="csl-entry">
Forman, G., and Kirshenbaum, E. 2008. <span>“Extremely Fast Text Feature Extraction for Classification and Indexing.”</span> In <em>Proceedings of the 17th ACM Conference on Information and Knowledge Management</em>, 1221–1230. CIKM ’08. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/1458082.1458243">https://doi.org/10.1145/1458082.1458243</a>.
</div>
<div class="csl-entry">
Frank, E., and Bouckaert, R. R. 2006. <span>“Naive Bayes for Text Classification with Unbalanced Classes.”</span> In <em>Knowledge Discovery in Databases: PKDD 2006</em>, edited by Johannes Fürnkranz, Tobias Scheffer, and Myra Spiliopoulou, 503–510. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/11871637_49">https://doi.org/10.1007/11871637_49</a>.
</div>
<div class="csl-entry">
Fredrikson, Matt, Jha, S., and Ristenpart, T. 2015. <span>“Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures.”</span> In, 1322–1333. CCS ’15. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/2810103.2813677">https://doi.org/10.1145/2810103.2813677</a>.
</div>
<div class="csl-entry">
Fredrikson, Matthew, Lantz, E., Jha, S., Lin, S., Page, D., and Ristenpart, T. 2014. <span>“Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing.”</span> In <em>Proceedings of the 23rd USENIX Conference on Security Symposium</em>, 17–32. SEC’14. USA: USENIX Association.
</div>
<div class="csl-entry">
Friedman, J. H., Hastie, T., and Tibshirani, R. 2010. <span>“Regularization Paths for Generalized Linear Models via Coordinate Descent.”</span> <em>Journal of Statistical Software, Articles</em> 33 (1): 1–22. <a href="https://www.jstatsoft.org/v033/i01">https://www.jstatsoft.org/v033/i01</a>.
</div>
<div class="csl-entry">
Gage, P. 1994. <span>“A New Algorithm for Data Compression.”</span> <em>The C Users Journal Archive</em> 12: 23–38.
</div>
<div class="csl-entry">
Gagolewski, M. 2020. <em><span class="nocase">stringi</span>: Character String Processing Facilities</em>. R package version 1.6.2. <a href="http://www.gagolewski.com/software/stringi/">http://www.gagolewski.com/software/stringi/</a>.
</div>
<div class="csl-entry">
Garg, N., Schiebinger, L., Jurafsky, D., and Zou, J. 2018. <span>“Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes.”</span> <em>Proceedings of the National Academy of Sciences</em> 115 (16). National Academy of Sciences: E3635–E3644. <a href="https://www.pnas.org/content/115/16/E3635">https://www.pnas.org/content/115/16/E3635</a>.
</div>
<div class="csl-entry">
Golub, G. H., and Reinsch, C. 1970. <span>“Singular Value Decomposition and Least Squares Solutions.”</span> <em>Numerische Mathematik</em> 14 (5). Berlin, Heidelberg: Springer-Verlag: 403–420. <a href="https://doi.org/10.1007/BF02163027">https://doi.org/10.1007/BF02163027</a>.
</div>
<div class="csl-entry">
Gonen, H., and Goldberg, Y. 2019. <span>“Lipstick on a Pig: <span>D</span>ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings but Do Not Remove Them.”</span> In <em>Proceedings of the 2019 Conference of the North <span>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, 609–614. Minneapolis, Minnesota: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/N19-1061">https://www.aclweb.org/anthology/N19-1061</a>.
</div>
<div class="csl-entry">
Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., and Pedreschi, D. 2018. <span>“A Survey of Methods for Explaining Black Box Models.”</span> <em>ACM Computing Surveys</em> 51 (5). New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/3236009">https://doi.org/10.1145/3236009</a>.
</div>
<div class="csl-entry">
Harman, D. 1991. <span>“How Effective Is Suffixing?”</span> <em>Journal of the American Society for Information Science</em> 42 (1): 7–15. <a href="https://doi.org/10.1002/(SICI)1097-4571(199101)42:1&lt;7::AID-ASI2&gt;3.0.CO;2-P">https://doi.org/10.1002/(SICI)1097-4571(199101)42:1&lt;7::AID-ASI2&gt;3.0.CO;2-P</a>.
</div>
<div class="csl-entry">
Helleputte, T. 2021. <em>LiblineaR: Linear Predictive Models Based on the <span>LIBLINEAR C/C++</span> Library</em>. R package version 2.10-12. <a href="https://CRAN.R-project.org/package=LiblineaR">https://CRAN.R-project.org/package=LiblineaR</a>.
</div>
<div class="csl-entry">
Hochreiter, S., and Schmidhuber, J. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Comput.</em> 9 (8). Cambridge, MA: MIT Press: 1735–1780. <a href="https://doi.org/10.1162/neco.1997.9.8.1735">https://doi.org/10.1162/neco.1997.9.8.1735</a>.
</div>
<div class="csl-entry">
Honnibal, M., Montani, I., Van Landeghem, S., and Boyd, A. 2020. <em><span class="nocase">spaCy: Industrial-strength Natural Language Processing in Python</span></em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.1212303">https://doi.org/10.5281/zenodo.1212303</a>.
</div>
<div class="csl-entry">
Howard, J., and Ruder, S. 2018. <span>“Universal Language Model Fine-Tuning for Text Classification.”</span> In <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 328–339. Melbourne, Australia: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/P18-1031">https://www.aclweb.org/anthology/P18-1031</a>.
</div>
<div class="csl-entry">
Huang, W., Cheng, X., Chen, K., Wang, T., and Chu, W. 2020. <span>“Towards Fast and Accurate Neural <span>C</span>hinese Word Segmentation with Multi-Criteria Learning.”</span> In <em>Proceedings of the 28th International Conference on Computational Linguistics</em>, 2062–2072. Barcelona, Spain (Online): International Committee on Computational Linguistics. <a href="https://www.aclweb.org/anthology/2020.coling-main.186">https://www.aclweb.org/anthology/2020.coling-main.186</a>.
</div>
<div class="csl-entry">
Huston, S., and Croft, W. B. 2010. <span>“Evaluating Verbose Query Processing Techniques.”</span> In <em>Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, 291–298. SIGIR ’10. New York, NY: ACM. <a href="http://doi.acm.org/10.1145/1835449.1835499">http://doi.acm.org/10.1145/1835449.1835499</a>.
</div>
<div class="csl-entry">
Hvitfeldt, E. 2019b. <em><span class="nocase">scotus</span>: Collection of Supreme Court of the United States’ Opinions</em>. R package version 1.0.0. <a href="https://github.com/EmilHvitfeldt/scotus">https://github.com/EmilHvitfeldt/scotus</a>.
</div>
<div class="csl-entry">
Hvitfeldt, E. 2019a. <em><span class="nocase">hcandersenr</span>: <span class="nocase">H.C. Andersen’s</span> Fairy Tales</em>. R package version 0.2.0. <a href="https://CRAN.R-project.org/package=hcandersenr">https://CRAN.R-project.org/package=hcandersenr</a>.
</div>
<div class="csl-entry">
Hvitfeldt, E. 2020b. <em><span class="nocase">textdata</span>: Download and Load Various Text Datasets</em>. R package version 0.4.1. <a href="https://CRAN.R-project.org/package=textdata">https://CRAN.R-project.org/package=textdata</a>.
</div>
<div class="csl-entry">
Hvitfeldt, E. 2020a. <em><span class="nocase">textrecipes</span>: Extra <span>‘Recipes’</span> for Text Processing</em>. R package version 0.4.1. <a href="https://CRAN.R-project.org/package=textrecipes">https://CRAN.R-project.org/package=textrecipes</a>.
</div>
<div class="csl-entry">
Hvitfeldt, E. 2020c. <em><span class="nocase">wordsalad</span>: Provide Tools to Extract and Analyze Word Vectors</em>. R package version 0.2.0. <a href="https://CRAN.R-project.org/package=wordsalad">https://CRAN.R-project.org/package=wordsalad</a>.
</div>
<div class="csl-entry">
Hvitfeldt, E. 2020d. <em><span class="nocase">themis</span>: Extra Recipe Steps for Dealing with Unbalanced Data</em>. R package version 0.1.4. <a href="https://CRAN.R-project.org/package=themis">https://CRAN.R-project.org/package=themis</a>.
</div>
<div class="csl-entry">
James, G., Witten, D., Hastie, T., and Tibshirani, R. 2013. <em>An Introduction to Statistical Learning</em>. New York: Springer.
</div>
<div class="csl-entry">
Joachims, T. 1998. <span>“Text Categorization with Support Vector Machines: Learning with Many Relevant Features.”</span> In <em>Proceedings of the 10th European Conference on Machine Learning</em>, 137–142. ECML’98. Berlin, Heidelberg: Springer-Verlag. <a href="https://doi.org/10.1007/BFb0026683">https://doi.org/10.1007/BFb0026683</a>.
</div>
<div class="csl-entry">
Johnson, S. B. 1999. <span>“A Semantic Lexicon for Medical Language Processing.”</span> <em>Journal of the American Medical Informatics Association</em> 6 (3). BMJ Group BMA House, Tavistock Square, London, WC1H 9JR: 205–218. <a href="https://doi.org/10.1136/jamia.1999.0060205">https://doi.org/10.1136/jamia.1999.0060205</a>.
</div>
<div class="csl-entry">
Kearney, M. W. 2019. <em><span class="nocase">textfeatures</span>: Extracts Features from Text</em>. R package version 0.3.3. <a href="https://CRAN.R-project.org/package=textfeatures">https://CRAN.R-project.org/package=textfeatures</a>.
</div>
<div class="csl-entry">
Kibriya, A. M., Frank, E., Pfahringer, B., and Holmes, G. 2005. <span>“Multinomial Naive Bayes for Text Categorization Revisited.”</span> In <em>AI 2004: Advances in Artificial Intelligence</em>, edited by Geoffrey I. Webb and Xinghuo Yu, 488–499. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-540-30549-1_43">https://doi.org/10.1007/978-3-540-30549-1_43</a>.
</div>
<div class="csl-entry">
Kim, S., Han, K., Rim, H., and Myaeng, S. H. 2006. <span>“Some Effective Techniques for Naive Bayes Text Classification.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 18 (11): 1457–1466. <a href="https://doi.org/10.1109/TKDE.2006.180">https://doi.org/10.1109/TKDE.2006.180</a>.
</div>
<div class="csl-entry">
Kim, Y. 2014. <span>“Convolutional Neural Networks for Sentence Classification.”</span> In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span>)</em>, 1746–1751. Doha, Qatar: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/D14-1181">https://www.aclweb.org/anthology/D14-1181</a>.
</div>
<div class="csl-entry">
Kingma, D. P., and Ba, J. 2017. <span>“Adam: A Method for Stochastic Optimization.”</span> <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>.
</div>
<div class="csl-entry">
Kuhn, M. 2020. <em><span class="nocase">dials</span>: Tools for Creating Tuning Parameter Values</em>. R package version 0.0.9. <a href="https://CRAN.R-project.org/package=dials">https://CRAN.R-project.org/package=dials</a>.
</div>
<div class="csl-entry">
Kuhn, M., and Vaughan, D. 2021b. <em><span class="nocase">parsnip</span>: A Common API to Modeling and Analysis Functions</em>. R package version 0.1.6. <a href="https://CRAN.R-project.org/package=parsnip">https://CRAN.R-project.org/package=parsnip</a>.
</div>
<div class="csl-entry">
Kuhn, M., and Vaughan, D. 2021a. <em><span class="nocase">yardstick</span>: Tidy Characterizations of Model Performance</em>. R package version 0.0.8. <a href="https://CRAN.R-project.org/package=yardstick">https://CRAN.R-project.org/package=yardstick</a>.
</div>
<div class="csl-entry">
Kuhn, M., and Wickham, H. 2021a. <span>“Tidymodels: A Collection of Packages for Modeling and Machine Learning Using Tidyverse Principles.”</span> RStudio PBC. <a href="https://www.tidymodels.org">https://www.tidymodels.org</a>.
</div>
<div class="csl-entry">
Kuhn, M., and Wickham, H. 2021b. <em><span class="nocase">recipes</span>: Preprocessing Tools to Create Design Matrices</em>. R package version 0.1.16. <a href="https://CRAN.R-project.org/package=recipes">https://CRAN.R-project.org/package=recipes</a>.
</div>
<div class="csl-entry">
Lampinen, A. K., and McClelland, J. L. 2018. <span>“One-Shot and Few-Shot Learning of Word Embeddings.”</span> <a href="https://arxiv.org/abs/1710.10280">https://arxiv.org/abs/1710.10280</a>.
</div>
<div class="csl-entry">
Le, Q., and Mikolov, T. 2014. <span>“Distributed Representations of Sentences and Documents.”</span> In <em>Proceedings of the 31st International Conference on Machine Learning</em>, edited by Eric P. Xing and Tony Jebara, 32:1188–1196. Proceedings of Machine Learning Research 2. Bejing, China: PMLR. <a href="http://proceedings.mlr.press/v32/le14.html">http://proceedings.mlr.press/v32/le14.html</a>.
</div>
<div class="csl-entry">
Levithan, J. G. S. 2012. <em>Regular Expressions Cookbook</em>. Sebastopol: O’Reilly Media, Inc.
</div>
<div class="csl-entry">
Levy, O., and Goldberg, Y. 2014. <span>“Dependency-Based Word Embeddings.”</span> In <em>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, 302–308. Baltimore, Maryland: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/P14-2050">https://www.aclweb.org/anthology/P14-2050</a>.
</div>
<div class="csl-entry">
Lewis, D. D., Yang, Y., Rose, T. G., and Li, F. 2004. <span>“<span>Rcv1</span>: A New Benchmark Collection for Text Categorization Research.”</span> <em>Journal of Machine Learning Research</em> 5: 361–397. <a href="https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf">https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf</a>.
</div>
<div class="csl-entry">
Lex, A., Gehlenborg, N., Strobelt, H., Vuillemot, R., and Pfister, H. 2014. <span>“UpSet: Visualization of Intersecting Sets.”</span> <em><span>IEEE Transactions on Visualization and Computer Graphics</span></em> 20 (12): 1983–1992. <a href="https://doi.org/10.1109/TVCG.2014.2346248">https://doi.org/10.1109/TVCG.2014.2346248</a>.
</div>
<div class="csl-entry">
Lovins, J. B. 1968. <span>“Development of a Stemming Algorithm.”</span> <em>Mechanical Translation and Computational Linguistics</em> 11: 22–31.
</div>
<div class="csl-entry">
Lu, K., Mardziel, P., Wu, F., Amancharla, P., and Datta, A. 2020. <span>“Gender Bias in Neural Natural Language Processing.”</span> In <em>Logic, Language, and Security: Essays Dedicated to Andre Scedrov on the Occasion of His 65th Birthday</em>, edited by Vivek Nigam, Tajana Ban Kirigin, Carolyn Talcott, Joshua Guttman, Stepan Kuznetsov, Boon Thau Loo, and Mitsuhiro Okada, 189–202. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-62077-6_14">https://doi.org/10.1007/978-3-030-62077-6_14</a>.
</div>
<div class="csl-entry">
Luhn, H. P. 1960. <span>“Key Word-in-Context Index for Technical Literature (<span class="nocase">kwic</span> Index).”</span> <em>American Documentation</em> 11 (4): 288–295. <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.5090110403">https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.5090110403</a>.
</div>
<div class="csl-entry">
Ma, J., Ganchev, K., and Weiss, D. 2018. <span>“State-of-the-Art <span>C</span>hinese Word Segmentation with Bi-<span>LSTM</span>s.”</span> In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, 4902–4908. Brussels, Belgium: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/D18-1529">https://www.aclweb.org/anthology/D18-1529</a>.
</div>
<div class="csl-entry">
Manning, C. D., Raghavan, P., and Schütze, H. 2008. <em>Introduction to Information Retrieval</em>. New York, NY: Cambridge University Press.
</div>
<div class="csl-entry">
McCulloch, G. 2015. <span>“Move over <span>S</span>hakespeare, Teen Girls Are the Real Language Disruptors.”</span> <em>Quartz</em>. Quartz. <a href="https://qz.com/474671/move-over-shakespeare-teen-girls-are-the-real-language-disruptors/">https://qz.com/474671/move-over-shakespeare-teen-girls-are-the-real-language-disruptors/</a>.
</div>
<div class="csl-entry">
Mikolov, T., Chen, K., Corrado, G. S., and Dean, J. 2013. <span>“Efficient Estimation of Word Representations in Vector Space.”</span> <a href="http://arxiv.org/abs/1301.3781">http://arxiv.org/abs/1301.3781</a>.
</div>
<div class="csl-entry">
Miller, G. A. 1995. <span>“WordNet: A Lexical Database for <span>E</span>nglish.”</span> <em>Communications of the ACM</em> 38 (11). New York, NY: ACM: 39–41. <a href="http://doi.acm.org/10.1145/219717.219748">http://doi.acm.org/10.1145/219717.219748</a>.
</div>
<div class="csl-entry">
Minaee, S., Kalchbrenner, N., Cambria, E., Nikzad, N., Chenaghlu, M., and Gao, J. 2021. <span>“Deep Learning–Based Text Classification: A Comprehensive Review.”</span> <em>ACM Comput. Surv.</em> 54 (3). New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/3439726">https://doi.org/10.1145/3439726</a>.
</div>
<div class="csl-entry">
Mohammad, S. M., and Turney, P. D. 2013. <span>“Crowdsourcing a Word–Emotion Association Lexicon.”</span> <em>Computational Intelligence</em> 29 (3): 436–465. <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00460.x">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00460.x</a>.
</div>
<div class="csl-entry">
Moody, C. 2017. <span>“Stop Using <span class="nocase">word2vec</span>.”</span> <em>Multithreaded</em>. StitchFix. <a href="https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/">https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/</a>.
</div>
<div class="csl-entry">
Mullen, L. A., Benoit, K., Keyes, O., Selivanov, D., and Arnold, J. 2018. <span>“Fast, Consistent Tokenization of Natural Language Text.”</span> <em>Journal of Open Source Software</em> 3: 655. <a href="https://doi.org/10.21105/joss.00655">https://doi.org/10.21105/joss.00655</a>.
</div>
<div class="csl-entry">
Nothman, J., Qin, H., and Yurchak, R. 2018. <span>“Stop Word Lists in Free Open-Source Software Packages.”</span> In <em>Proceedings of Workshop for <span>NLP</span> Open Source Software (<span>NLP</span>-<span>OSS</span>)</em>, 7–12. Melbourne, Australia: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/W18-2502">https://www.aclweb.org/anthology/W18-2502</a>.
</div>
<div class="csl-entry">
Olson, R. S., Cava, W. L., Mustahsan, Z., Varik, A., and Moore, J. H. 2018. <span>“Data-Driven Advice for Applying Machine Learning to Bioinformatics Problems.”</span> In <em>Pacific Symposium on Biocomputing 2018: Proceedings of the Pacific Symposium</em>, 192–203. World Scientific. <a href="https://doi.org/10.1142/9789813235533_0018">https://doi.org/10.1142/9789813235533_0018</a>.
</div>
<div class="csl-entry">
Ooms, J. 2020a. <em><span class="nocase">pdftools</span>: Text Extraction, Rendering and Converting of PDF Documents</em>. R package version 2.3.1. <a href="https://CRAN.R-project.org/package=pdftools">https://CRAN.R-project.org/package=pdftools</a>.
</div>
<div class="csl-entry">
Ooms, J. 2020b. <em><span class="nocase">hunspell</span>: High-Performance Stemmer, Tokenizer, and Spell Checker</em>. R package version 3.0.1. <a href="https://CRAN.R-project.org/package=hunspell">https://CRAN.R-project.org/package=hunspell</a>.
</div>
<div class="csl-entry">
Pedersen, T. L., and Benesty, M. 2021. <em><span class="nocase">lime</span>: Local Interpretable Model-Agnostic Explanations</em>. R package version 0.5.2. <a href="https://CRAN.R-project.org/package=lime">https://CRAN.R-project.org/package=lime</a>.
</div>
<div class="csl-entry">
Pennington, J., Socher, R., and Manning, C. 2014. <span>“<span>G</span>lo<span>V</span>e: Global Vectors for Word Representation.”</span> In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span>)</em>, 1532–1543. Doha, Qatar: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/D14-1162">https://www.aclweb.org/anthology/D14-1162</a>.
</div>
<div class="csl-entry">
Perry, P. O. 2020. <em><span class="nocase">corpus</span>: Text Corpus Analysis</em>. R package version 0.10.2. <a href="https://CRAN.R-project.org/package=corpus">https://CRAN.R-project.org/package=corpus</a>.
</div>
<div class="csl-entry">
Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. 2018. <span>“Deep Contextualized Word Representations.”</span> In <em>Proceedings of the 2018 Conference of the North <span>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</em>, 2227–2237. New Orleans, Louisiana: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/N18-1202">https://www.aclweb.org/anthology/N18-1202</a>.
</div>
<div class="csl-entry">
Porter, M. F. 1980. <span>“An Algorithm for Suffix Stripping.”</span> <em>Program</em> 14 (3): 130–137. <a href="https://doi.org/10.1108/eb046814">https://doi.org/10.1108/eb046814</a>.
</div>
<div class="csl-entry">
Porter, M. F. 2001. <span>“Snowball: A Language for Stemming Algorithms.”</span> <a href="https://snowballstem.org">https://snowballstem.org</a>.
</div>
<div class="csl-entry">
Ramineni, C., and Williamson, D. 2018. <span>“Understanding Mean Score Differences Between the e-Rater® Automated Scoring Engine and Humans for Demographically Based Groups in the <span>GRE</span>® General Test.”</span> <em>ETS Research Report Series</em> 2018 (1): 1–31. <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ets2.12192">https://onlinelibrary.wiley.com/doi/abs/10.1002/ets2.12192</a>.
</div>
<div class="csl-entry">
Ribeiro, M. T., Singh, S., and Guestrin, C. 2016. <span>“<span>‘<span>Why</span> Should <span>I</span> Trust You?’</span>: Explaining the Predictions of Any Classifier.”</span> In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 1135–1144. KDD ’16. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/2939672.2939778">https://doi.org/10.1145/2939672.2939778</a>.
</div>
<div class="csl-entry">
Robinson, D. 2020. <em><span class="nocase">widyr</span>: Widen, Process, Then Re-Tidy Data</em>. R package version 0.1.3. <a href="https://CRAN.R-project.org/package=widyr">https://CRAN.R-project.org/package=widyr</a>.
</div>
<div class="csl-entry">
Sap, M., Card, D., Gabriel, S., Choi, Y., and Smith, N. A. 2019. <span>“The Risk of Racial Bias in Hate Speech Detection.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 1668–1678. Florence, Italy: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/P19-1163">https://www.aclweb.org/anthology/P19-1163</a>.
</div>
<div class="csl-entry">
Schofield, A., and Mimno, D. 2016. <span>“Comparing Apples to Apple: The Effects of Stemmers on Topic Models.”</span> <em>Transactions of the Association for Computational Linguistics</em> 4: 287–300. <a href="https://doi.org/10.1162/tacl_a_00099">https://doi.org/10.1162/tacl_a_00099</a>.
</div>
<div class="csl-entry">
Selivanov, D., Bickel, M., and Wang, Q. 2020. <em><span class="nocase">text2vec</span>: Modern Text Mining Framework for <span>R</span></em>. R package version 0.6. <a href="https://CRAN.R-project.org/package=text2vec">https://CRAN.R-project.org/package=text2vec</a>.
</div>
<div class="csl-entry">
Sheng, E., Chang, K.-W., Natarajan, P., and Peng, N. 2019. <span>“The Woman Worked as a Babysitter: On Biases in Language Generation.”</span> In <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, 3407–3412. Hong Kong: Association for Computational Linguistics. <a href="https://www.aclweb.org/anthology/D19-1339">https://www.aclweb.org/anthology/D19-1339</a>.
</div>
<div class="csl-entry">
Shrikumar, A., Greenside, P., and Kundaje, A. 2017. <span>“Learning Important Features Through Propagating Activation Differences.”</span> In <em>Proceedings of the 34th International Conference on Machine Learning - Volume 70</em>, 3145–3153. ICML’17. Sydney, NSW, Australia: JMLR.org.
</div>
<div class="csl-entry">
Shwartz-Ziv, R., and Tishby, N. 2017. <span>“Opening the Black Box of Deep Neural Networks via Information.”</span> <a href="https://arxiv.org/abs/1703.00810">https://arxiv.org/abs/1703.00810</a>.
</div>
<div class="csl-entry">
Silge, J., Chow, F., Kuhn, M., and Wickham, H. 2021. <em><span class="nocase">rsample</span>: General Resampling Infrastructure</em>. R package version 0.1.0. <a href="https://CRAN.R-project.org/package=rsample">https://CRAN.R-project.org/package=rsample</a>.
</div>
<div class="csl-entry">
Silge, J., and Robinson, D. 2016. <span>“Tidytext: Text Mining and Analysis Using Tidy Data Principles in <span>R</span>.”</span> <em>JOSS</em> 1 (3). The Open Journal. <a href="http://dx.doi.org/10.21105/joss.00037">http://dx.doi.org/10.21105/joss.00037</a>.
</div>
<div class="csl-entry">
Silge, J., and Robinson, D. 2017. <em>Text Mining with <span>R</span>: A Tidy Approach</em>. Sebastopol: O’Reilly Media, Inc.
</div>
<div class="csl-entry">
Speer, R. 2017. <span>“How to Make a Racist <span>AI</span> Without Really Trying.”</span> <em>ConceptNet Blog</em>. <a href="http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/">http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/</a>.
</div>
<div class="csl-entry">
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. 2014. <span>“Dropout: A Simple Way to Prevent Neural Networks from Overfitting.”</span> <em>Journal of Machine Learning Research</em> 15 (56): 1929–1958. <a href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a>.
</div>
<div class="csl-entry">
Sugisaki, K., and Tuggener, D. 2018. <span>“German Compound Splitting Using the Compound Productivity of Morphemes.”</span> Verlag der <span>Ö</span>sterreichischen Akademie der Wissenschaften.
</div>
<div class="csl-entry">
Sweeney, L. 2000. <em>Simple Demographics Often Identify People Uniquely</em>. Data Privacy Working Paper 3. Carnegie Mellon University. <a href="https://dataprivacylab.org/projects/identifiability/">https://dataprivacylab.org/projects/identifiability/</a>.
</div>
<div class="csl-entry">
Tang, C., Garreau, D., and Luxburg, U. von. 2018. <span>“When Do Random Forests Fail?”</span> In, 2987–2997. NIPS’18. Red Hook, NY: Curran Associates Inc.
</div>
<div class="csl-entry">
Tibshirani, R. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 58 (1). [Royal Statistical Society, Wiley]: 267–288. <a href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</a>.
</div>
<div class="csl-entry">
Ushey, K., Allaire, J., and Tang, Y. 2021. <em><span class="nocase">reticulate</span>: Interface to <span>‘Python’</span></em>. R package version 1.20. <a href="https://CRAN.R-project.org/package=reticulate">https://CRAN.R-project.org/package=reticulate</a>.
</div>
<div class="csl-entry">
Van-Tu, N., and Anh-Cuong, L. 2016. <span>“Improving Question Classification by Feature Extraction and Selection.”</span> <em>Indian Journal of Science and Technology</em> 9 (17): 1–8. <a href="https://doi.org/10.17485/ijst/2016/v9i17/93160">https://doi.org/10.17485/ijst/2016/v9i17/93160</a>.
</div>
<div class="csl-entry">
Vaughan, D. 2021a. <em><span class="nocase">slider</span>: Sliding Window Functions</em>. R package version 0.2.1. <a href="https://CRAN.R-project.org/package=slider">https://CRAN.R-project.org/package=slider</a>.
</div>
<div class="csl-entry">
Vaughan, D. 2021b. <em><span class="nocase">workflows</span>: Modeling Workflows</em>. R package version 0.2.2. <a href="https://CRAN.R-project.org/package=workflows">https://CRAN.R-project.org/package=workflows</a>.
</div>
<div class="csl-entry">
Vaughan, D., and Dancho, M. 2021. <em><span class="nocase">furrr</span>: Apply Mapping Functions in Parallel Using Futures</em>. R package version 0.2.2. <a href="https://CRAN.R-project.org/package=furrr">https://CRAN.R-project.org/package=furrr</a>.
</div>
<div class="csl-entry">
Vaughan, D., and Kuhn, M. 2020. <em><span class="nocase">hardhat</span>: Construct Modeling Packages</em>. R package version 0.1.5. <a href="https://CRAN.R-project.org/package=hardhat">https://CRAN.R-project.org/package=hardhat</a>.
</div>
<div class="csl-entry">
Vosoughi, S., Vijayaraghavan, P., and Roy, D. 2016. <span>“<span>Tweet2Vec</span>: Learning Tweet Embeddings Using Character-Level <span>CNN-LSTM</span> Encoder-Decoder.”</span> In <em>Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, 1041–1044. SIGIR ’16. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/2911451.2914762">https://doi.org/10.1145/2911451.2914762</a>.
</div>
<div class="csl-entry">
Wagner, C., Graells-Garrido, E., Garcia, D., and Menczer, F. 2016. <span>“Women Through the Glass Ceiling: Gender Asymmetries in <span>W</span>ikipedia.”</span> <em>EPJ Data Science</em> 5 (1). SpringerOpen: 5. <a href="https://doi.org/10.1140/epjds/s13688-016-0066-4">https://doi.org/10.1140/epjds/s13688-016-0066-4</a>.
</div>
<div class="csl-entry">
Weinberger, K., Dasgupta, A., Langford, J., Smola, A., and Attenberg, J. 2009. <span>“Feature Hashing for Large Scale Multitask Learning.”</span> In <em>Proceedings of the 26th Annual International Conference on Machine Learning</em>, 1113–1120. ICML ’09. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/1553374.1553516">https://doi.org/10.1145/1553374.1553516</a>.
</div>
<div class="csl-entry">
Wenfeng, Q., and Yanyi, W. 2019. <em><span class="nocase">jiebaR</span>: Chinese Text Segmentation</em>. R package version 0.11. <a href="https://CRAN.R-project.org/package=jiebaR">https://CRAN.R-project.org/package=jiebaR</a>.
</div>
<div class="csl-entry">
Wickham, H. 2019. <em><span class="nocase">stringr</span>: Simple<span>,</span> Consistent Wrappers for Common String Operations</em>. R package version 1.4.0. <a href="https://CRAN.R-project.org/package=stringr">https://CRAN.R-project.org/package=stringr</a>.
</div>
<div class="csl-entry">
Wickham, H. 2020. <em><span class="nocase">httr</span>: Tools for Working with URLs and HTTP</em>. R package version 1.4.2. <a href="https://CRAN.R-project.org/package=httr">https://CRAN.R-project.org/package=httr</a>.
</div>
<div class="csl-entry">
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., et al. 2019. <span>“Welcome to the Tidyverse.”</span> <em>Journal of Open Source Software</em> 4 (43). The Open Journal: 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div>
<div class="csl-entry">
Wickham, H., and Grolemund, G. 2017. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. Sebastopol: O’Reilly Media, Inc.
</div>
<div class="csl-entry">
Wickham, H., and Hester, J. 2020. <em><span class="nocase">readr</span>: Read Rectangular Text Data</em>. R package version 1.4.0. <a href="https://CRAN.R-project.org/package=readr">https://CRAN.R-project.org/package=readr</a>.
</div>
<div class="csl-entry">
Willett, P. 2006. <span>“The <span>P</span>orter Stemming Algorithm: Then and Now.”</span> <em>Program: Electronic Library and Information Systems</em> 40 (3). Emerald: 219–223. <a href="http://eprints.whiterose.ac.uk/1434/">http://eprints.whiterose.ac.uk/1434/</a>.
</div>
<div class="csl-entry">
Zhang, X., Zhao, J., and LeCun, Y. 2015. <span>“Character-Level Convolutional Networks for Text Classification.”</span> In <em>Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1</em>, 649–657. NIPS’15. Cambridge, MA: MIT Press.
</div>
<div class="csl-entry">
Zou, F., Wang, F. L., Deng, X., and Han, S. 2006. <span>“Evaluation of Stop Word Lists in <span>C</span>hinese Language.”</span> In <em>Proceedings of the Fifth International Conference on Language Resources and Evaluation (<span>LREC</span><span>’</span>06)</em>. Genoa, Italy: European Language Resources Association (ELRA). <a href="http://www.lrec-conf.org/proceedings/lrec2006/pdf/273_pdf.pdf">http://www.lrec-conf.org/proceedings/lrec2006/pdf/273_pdf.pdf</a>.
</div>
<div class="csl-entry">
Zou, F., Wang, F. L., Deng, X., Han, S., and Wang, L. S. 2006. <span>“Automatic Construction of <span>C</span>hinese Stop Word List.”</span> In <em>Proceedings of the 5th WSEAS International Conference on Applied Computer Science</em>, 1009–1014. ACOS’06. Stevens Point, Wisconsin: World Scientific; Engineering Academy; Society (WSEAS). <a href="http://dl.acm.org/citation.cfm?id=1973598.1973793">http://dl.acm.org/citation.cfm?id=1973598.1973793</a>.
</div>
</div>
</div>





















            </section>

          </div>
        </div>
      </div>
<a href="appendixbaseline.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": null,
"edit": {
"link": "https://github.com/EmilHvitfeldt/smltar/edit/master/references.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

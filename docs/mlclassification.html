<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Classification | Supervised Machine Learning for Text Analysis in R</title>
  <meta name="description" content="Chapter 7 Classification | Supervised Machine Learning for Text Analysis in R" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Classification | Supervised Machine Learning for Text Analysis in R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://smltar.com/cover.jpg" />
  <meta property="og:description" content="Chapter 7 Classification | Supervised Machine Learning for Text Analysis in R" />
  <meta name="github-repo" content="EmilHvitfeldt/smltar" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Classification | Supervised Machine Learning for Text Analysis in R" />
  
  <meta name="twitter:description" content="Chapter 7 Classification | Supervised Machine Learning for Text Analysis in R" />
  <meta name="twitter:image" content="https://smltar.com/cover.jpg" />

<meta name="author" content="Emil Hvitfeldt and Julia Silge" />


<meta name="date" content="2022-05-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mlregression.html"/>
<link rel="next" href="dloverview.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/plot_text_explanations-0.1.0/plot_text_explanations.css" rel="stylesheet" />
<script src="libs/plot_text_explanations-binding-0.5.2/plot_text_explanations.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="smltar.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Supervised Machine Learning for Text Analysis in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome to Supervised Machine Learning for Text Analysis in R</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#topics-this-book-will-not-cover"><i class="fa fa-check"></i>Topics this book will not cover</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who is this book for?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#colophon"><i class="fa fa-check"></i>Colophon</a></li>
</ul></li>
<li class="part"><span><b>I Natural Language Features</b></span></li>
<li class="chapter" data-level="1" data-path="language.html"><a href="language.html"><i class="fa fa-check"></i><b>1</b> Language and modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="language.html"><a href="language.html#linguistics-for-text-analysis"><i class="fa fa-check"></i><b>1.1</b> Linguistics for text analysis</a></li>
<li class="chapter" data-level="1.2" data-path="language.html"><a href="language.html#morphology"><i class="fa fa-check"></i><b>1.2</b> A glimpse into one area: morphology</a></li>
<li class="chapter" data-level="1.3" data-path="language.html"><a href="language.html#different-languages"><i class="fa fa-check"></i><b>1.3</b> Different languages</a></li>
<li class="chapter" data-level="1.4" data-path="language.html"><a href="language.html#other-ways-text-can-vary"><i class="fa fa-check"></i><b>1.4</b> Other ways text can vary</a></li>
<li class="chapter" data-level="1.5" data-path="language.html"><a href="language.html#languagesummary"><i class="fa fa-check"></i><b>1.5</b> Summary</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="language.html"><a href="language.html#in-this-chapter-you-learned"><i class="fa fa-check"></i><b>1.5.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tokenization.html"><a href="tokenization.html"><i class="fa fa-check"></i><b>2</b> Tokenization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tokenization.html"><a href="tokenization.html#what-is-a-token"><i class="fa fa-check"></i><b>2.1</b> What is a token?</a></li>
<li class="chapter" data-level="2.2" data-path="tokenization.html"><a href="tokenization.html#types-of-tokens"><i class="fa fa-check"></i><b>2.2</b> Types of tokens</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="tokenization.html"><a href="tokenization.html#character-tokens"><i class="fa fa-check"></i><b>2.2.1</b> Character tokens</a></li>
<li class="chapter" data-level="2.2.2" data-path="tokenization.html"><a href="tokenization.html#word-tokens"><i class="fa fa-check"></i><b>2.2.2</b> Word tokens</a></li>
<li class="chapter" data-level="2.2.3" data-path="tokenization.html"><a href="tokenization.html#tokenizingngrams"><i class="fa fa-check"></i><b>2.2.3</b> Tokenizing by n-grams</a></li>
<li class="chapter" data-level="2.2.4" data-path="tokenization.html"><a href="tokenization.html#lines-sentence-and-paragraph-tokens"><i class="fa fa-check"></i><b>2.2.4</b> Lines, sentence, and paragraph tokens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="tokenization.html"><a href="tokenization.html#where-does-tokenization-break-down"><i class="fa fa-check"></i><b>2.3</b> Where does tokenization break down?</a></li>
<li class="chapter" data-level="2.4" data-path="tokenization.html"><a href="tokenization.html#building-your-own-tokenizer"><i class="fa fa-check"></i><b>2.4</b> Building your own tokenizer</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="tokenization.html"><a href="tokenization.html#tokenize-to-characters-only-keeping-letters"><i class="fa fa-check"></i><b>2.4.1</b> Tokenize to characters, only keeping letters</a></li>
<li class="chapter" data-level="2.4.2" data-path="tokenization.html"><a href="tokenization.html#allow-for-hyphenated-words"><i class="fa fa-check"></i><b>2.4.2</b> Allow for hyphenated words</a></li>
<li class="chapter" data-level="2.4.3" data-path="tokenization.html"><a href="tokenization.html#wrapping-it-in-a-function"><i class="fa fa-check"></i><b>2.4.3</b> Wrapping it in a function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tokenization.html"><a href="tokenization.html#tokenization-for-non-latin-alphabets"><i class="fa fa-check"></i><b>2.5</b> Tokenization for non-Latin alphabets</a></li>
<li class="chapter" data-level="2.6" data-path="tokenization.html"><a href="tokenization.html#tokenization-benchmark"><i class="fa fa-check"></i><b>2.6</b> Tokenization benchmark</a></li>
<li class="chapter" data-level="2.7" data-path="tokenization.html"><a href="tokenization.html#tokensummary"><i class="fa fa-check"></i><b>2.7</b> Summary</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="tokenization.html"><a href="tokenization.html#in-this-chapter-you-learned-1"><i class="fa fa-check"></i><b>2.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stopwords.html"><a href="stopwords.html"><i class="fa fa-check"></i><b>3</b> Stop words</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stopwords.html"><a href="stopwords.html#premadestopwords"><i class="fa fa-check"></i><b>3.1</b> Using premade stop word lists</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="stopwords.html"><a href="stopwords.html#stop-word-removal-in-r"><i class="fa fa-check"></i><b>3.1.1</b> Stop word removal in R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="stopwords.html"><a href="stopwords.html#homemadestopwords"><i class="fa fa-check"></i><b>3.2</b> Creating your own stop words list</a></li>
<li class="chapter" data-level="3.3" data-path="stopwords.html"><a href="stopwords.html#all-stop-word-lists-are-context-specific"><i class="fa fa-check"></i><b>3.3</b> All stop word lists are context-specific</a></li>
<li class="chapter" data-level="3.4" data-path="stopwords.html"><a href="stopwords.html#what-happens-when-you-remove-stop-words"><i class="fa fa-check"></i><b>3.4</b> What happens when you remove stop words</a></li>
<li class="chapter" data-level="3.5" data-path="stopwords.html"><a href="stopwords.html#stop-words-in-languages-other-than-english"><i class="fa fa-check"></i><b>3.5</b> Stop words in languages other than English</a></li>
<li class="chapter" data-level="3.6" data-path="stopwords.html"><a href="stopwords.html#stopwordssummary"><i class="fa fa-check"></i><b>3.6</b> Summary</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="stopwords.html"><a href="stopwords.html#in-this-chapter-you-learned-2"><i class="fa fa-check"></i><b>3.6.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stemming.html"><a href="stemming.html"><i class="fa fa-check"></i><b>4</b> Stemming</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stemming.html"><a href="stemming.html#how-to-stem-text-in-r"><i class="fa fa-check"></i><b>4.1</b> How to stem text in R</a></li>
<li class="chapter" data-level="4.2" data-path="stemming.html"><a href="stemming.html#should-you-use-stemming-at-all"><i class="fa fa-check"></i><b>4.2</b> Should you use stemming at all?</a></li>
<li class="chapter" data-level="4.3" data-path="stemming.html"><a href="stemming.html#understand-a-stemming-algorithm"><i class="fa fa-check"></i><b>4.3</b> Understand a stemming algorithm</a></li>
<li class="chapter" data-level="4.4" data-path="stemming.html"><a href="stemming.html#handling-punctuation-when-stemming"><i class="fa fa-check"></i><b>4.4</b> Handling punctuation when stemming</a></li>
<li class="chapter" data-level="4.5" data-path="stemming.html"><a href="stemming.html#compare-some-stemming-options"><i class="fa fa-check"></i><b>4.5</b> Compare some stemming options</a></li>
<li class="chapter" data-level="4.6" data-path="stemming.html"><a href="stemming.html#lemmatization"><i class="fa fa-check"></i><b>4.6</b> Lemmatization and stemming</a></li>
<li class="chapter" data-level="4.7" data-path="stemming.html"><a href="stemming.html#stemming-and-stop-words"><i class="fa fa-check"></i><b>4.7</b> Stemming and stop words</a></li>
<li class="chapter" data-level="4.8" data-path="stemming.html"><a href="stemming.html#stemmingsummary"><i class="fa fa-check"></i><b>4.8</b> Summary</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="stemming.html"><a href="stemming.html#in-this-chapter-you-learned-3"><i class="fa fa-check"></i><b>4.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="embeddings.html"><a href="embeddings.html"><i class="fa fa-check"></i><b>5</b> Word Embeddings</a>
<ul>
<li class="chapter" data-level="5.1" data-path="embeddings.html"><a href="embeddings.html#motivatingsparse"><i class="fa fa-check"></i><b>5.1</b> Motivating embeddings for sparse, high-dimensional data</a></li>
<li class="chapter" data-level="5.2" data-path="embeddings.html"><a href="embeddings.html#understand-word-embeddings-by-finding-them-yourself"><i class="fa fa-check"></i><b>5.2</b> Understand word embeddings by finding them yourself</a></li>
<li class="chapter" data-level="5.3" data-path="embeddings.html"><a href="embeddings.html#exploring-cfpb-word-embeddings"><i class="fa fa-check"></i><b>5.3</b> Exploring CFPB word embeddings</a></li>
<li class="chapter" data-level="5.4" data-path="embeddings.html"><a href="embeddings.html#glove"><i class="fa fa-check"></i><b>5.4</b> Use pre-trained word embeddings</a></li>
<li class="chapter" data-level="5.5" data-path="embeddings.html"><a href="embeddings.html#fairnessembeddings"><i class="fa fa-check"></i><b>5.5</b> Fairness and word embeddings</a></li>
<li class="chapter" data-level="5.6" data-path="embeddings.html"><a href="embeddings.html#using-word-embeddings-in-the-real-world"><i class="fa fa-check"></i><b>5.6</b> Using word embeddings in the real world</a></li>
<li class="chapter" data-level="5.7" data-path="embeddings.html"><a href="embeddings.html#embeddingssummary"><i class="fa fa-check"></i><b>5.7</b> Summary</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="embeddings.html"><a href="embeddings.html#in-this-chapter-you-learned-4"><i class="fa fa-check"></i><b>5.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Machine Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#should-we-even-be-doing-this"><i class="fa fa-check"></i>Should we even be doing this?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-bias-is-already-in-the-data"><i class="fa fa-check"></i>What bias is already in the data?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#can-the-code-and-data-be-audited"><i class="fa fa-check"></i>Can the code and data be audited?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-are-the-error-rates-for-sub-groups"><i class="fa fa-check"></i>What are the error rates for sub-groups?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-is-the-accuracy-of-a-simple-rule-based-alternative"><i class="fa fa-check"></i>What is the accuracy of a simple rule-based alternative?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-processes-are-in-place-to-handle-appeals-or-mistakes"><i class="fa fa-check"></i>What processes are in place to handle appeals or mistakes?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#how-diverse-is-the-team-that-built-it"><i class="fa fa-check"></i>How diverse is the team that built it?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mlregression.html"><a href="mlregression.html"><i class="fa fa-check"></i><b>6</b> Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mlregression.html"><a href="mlregression.html#firstmlregression"><i class="fa fa-check"></i><b>6.1</b> A first regression model</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="mlregression.html"><a href="mlregression.html#firstregression"><i class="fa fa-check"></i><b>6.1.1</b> Building our first regression model</a></li>
<li class="chapter" data-level="6.1.2" data-path="mlregression.html"><a href="mlregression.html#firstregressionevaluation"><i class="fa fa-check"></i><b>6.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="mlregression.html"><a href="mlregression.html#regnull"><i class="fa fa-check"></i><b>6.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="6.3" data-path="mlregression.html"><a href="mlregression.html#comparerf"><i class="fa fa-check"></i><b>6.3</b> Compare to a random forest model</a></li>
<li class="chapter" data-level="6.4" data-path="mlregression.html"><a href="mlregression.html#casestudystopwords"><i class="fa fa-check"></i><b>6.4</b> Case study: removing stop words</a></li>
<li class="chapter" data-level="6.5" data-path="mlregression.html"><a href="mlregression.html#casestudyngrams"><i class="fa fa-check"></i><b>6.5</b> Case study: varying n-grams</a></li>
<li class="chapter" data-level="6.6" data-path="mlregression.html"><a href="mlregression.html#mlregressionlemmatization"><i class="fa fa-check"></i><b>6.6</b> Case study: lemmatization</a></li>
<li class="chapter" data-level="6.7" data-path="mlregression.html"><a href="mlregression.html#case-study-feature-hashing"><i class="fa fa-check"></i><b>6.7</b> Case study: feature hashing</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="mlregression.html"><a href="mlregression.html#text-normalization"><i class="fa fa-check"></i><b>6.7.1</b> Text normalization</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="mlregression.html"><a href="mlregression.html#what-evaluation-metrics-are-appropriate"><i class="fa fa-check"></i><b>6.8</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="6.9" data-path="mlregression.html"><a href="mlregression.html#mlregressionfull"><i class="fa fa-check"></i><b>6.9</b> The full game: regression</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="mlregression.html"><a href="mlregression.html#preprocess-the-data"><i class="fa fa-check"></i><b>6.9.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="6.9.2" data-path="mlregression.html"><a href="mlregression.html#specify-the-model"><i class="fa fa-check"></i><b>6.9.2</b> Specify the model</a></li>
<li class="chapter" data-level="6.9.3" data-path="mlregression.html"><a href="mlregression.html#tune-the-model"><i class="fa fa-check"></i><b>6.9.3</b> Tune the model</a></li>
<li class="chapter" data-level="6.9.4" data-path="mlregression.html"><a href="mlregression.html#regression-final-evaluation"><i class="fa fa-check"></i><b>6.9.4</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="mlregression.html"><a href="mlregression.html#mlregressionsummary"><i class="fa fa-check"></i><b>6.10</b> Summary</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="mlregression.html"><a href="mlregression.html#in-this-chapter-you-learned-5"><i class="fa fa-check"></i><b>6.10.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mlclassification.html"><a href="mlclassification.html"><i class="fa fa-check"></i><b>7</b> Classification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstattemptlookatdata"><i class="fa fa-check"></i><b>7.1</b> A first classification model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstmodel"><i class="fa fa-check"></i><b>7.1.1</b> Building our first classification model</a></li>
<li class="chapter" data-level="7.1.2" data-path="mlclassification.html"><a href="mlclassification.html#evaluation"><i class="fa fa-check"></i><b>7.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="mlclassification.html"><a href="mlclassification.html#classnull"><i class="fa fa-check"></i><b>7.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="7.3" data-path="mlclassification.html"><a href="mlclassification.html#comparetolasso"><i class="fa fa-check"></i><b>7.3</b> Compare to a lasso classification model</a></li>
<li class="chapter" data-level="7.4" data-path="mlclassification.html"><a href="mlclassification.html#tunelasso"><i class="fa fa-check"></i><b>7.4</b> Tuning lasso hyperparameters</a></li>
<li class="chapter" data-level="7.5" data-path="mlclassification.html"><a href="mlclassification.html#casestudysparseencoding"><i class="fa fa-check"></i><b>7.5</b> Case study: sparse encoding</a></li>
<li class="chapter" data-level="7.6" data-path="mlclassification.html"><a href="mlclassification.html#mlmulticlass"><i class="fa fa-check"></i><b>7.6</b> Two-class or multiclass?</a></li>
<li class="chapter" data-level="7.7" data-path="mlclassification.html"><a href="mlclassification.html#case-study-including-non-text-data"><i class="fa fa-check"></i><b>7.7</b> Case study: including non-text data</a></li>
<li class="chapter" data-level="7.8" data-path="mlclassification.html"><a href="mlclassification.html#case-study-data-censoring"><i class="fa fa-check"></i><b>7.8</b> Case study: data censoring</a></li>
<li class="chapter" data-level="7.9" data-path="mlclassification.html"><a href="mlclassification.html#customfeatures"><i class="fa fa-check"></i><b>7.9</b> Case study: custom features</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="mlclassification.html"><a href="mlclassification.html#detect-credit-cards"><i class="fa fa-check"></i><b>7.9.1</b> Detect credit cards</a></li>
<li class="chapter" data-level="7.9.2" data-path="mlclassification.html"><a href="mlclassification.html#calculate-percentage-censoring"><i class="fa fa-check"></i><b>7.9.2</b> Calculate percentage censoring</a></li>
<li class="chapter" data-level="7.9.3" data-path="mlclassification.html"><a href="mlclassification.html#detect-monetary-amounts"><i class="fa fa-check"></i><b>7.9.3</b> Detect monetary amounts</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="mlclassification.html"><a href="mlclassification.html#what-evaluation-metrics-are-appropriate-1"><i class="fa fa-check"></i><b>7.10</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="7.11" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationfull"><i class="fa fa-check"></i><b>7.11</b> The full game: classification</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="mlclassification.html"><a href="mlclassification.html#feature-selection"><i class="fa fa-check"></i><b>7.11.1</b> Feature selection</a></li>
<li class="chapter" data-level="7.11.2" data-path="mlclassification.html"><a href="mlclassification.html#specify-the-model-1"><i class="fa fa-check"></i><b>7.11.2</b> Specify the model</a></li>
<li class="chapter" data-level="7.11.3" data-path="mlclassification.html"><a href="mlclassification.html#classification-final-evaluation"><i class="fa fa-check"></i><b>7.11.3</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationsummary"><i class="fa fa-check"></i><b>7.12</b> Summary</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="mlclassification.html"><a href="mlclassification.html#in-this-chapter-you-learned-6"><i class="fa fa-check"></i><b>7.12.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Deep Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#spending-your-data-budget"><i class="fa fa-check"></i>Spending your data budget</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#feature-engineering"><i class="fa fa-check"></i>Feature engineering</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#fitting-and-tuning"><i class="fa fa-check"></i>Fitting and tuning</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#model-evaluation"><i class="fa fa-check"></i>Model evaluation</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#putting-the-model-process-in-context"><i class="fa fa-check"></i>Putting the model process in context</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="dldnn.html"><a href="dldnn.html"><i class="fa fa-check"></i><b>8</b> Dense neural networks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dldnn.html"><a href="dldnn.html#kickstarter"><i class="fa fa-check"></i><b>8.1</b> Kickstarter data</a></li>
<li class="chapter" data-level="8.2" data-path="dldnn.html"><a href="dldnn.html#firstdlclassification"><i class="fa fa-check"></i><b>8.2</b> A first deep learning model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="dldnn.html"><a href="dldnn.html#dnnrecipe"><i class="fa fa-check"></i><b>8.2.1</b> Preprocessing for deep learning</a></li>
<li class="chapter" data-level="8.2.2" data-path="dldnn.html"><a href="dldnn.html#onehotsequence"><i class="fa fa-check"></i><b>8.2.2</b> One-hot sequence embedding of text</a></li>
<li class="chapter" data-level="8.2.3" data-path="dldnn.html"><a href="dldnn.html#simple-flattened-dense-network"><i class="fa fa-check"></i><b>8.2.3</b> Simple flattened dense network</a></li>
<li class="chapter" data-level="8.2.4" data-path="dldnn.html"><a href="dldnn.html#evaluate-dnn"><i class="fa fa-check"></i><b>8.2.4</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="dldnn.html"><a href="dldnn.html#using-bag-of-words-features"><i class="fa fa-check"></i><b>8.3</b> Using bag-of-words features</a></li>
<li class="chapter" data-level="8.4" data-path="dldnn.html"><a href="dldnn.html#using-pre-trained-word-embeddings"><i class="fa fa-check"></i><b>8.4</b> Using pre-trained word embeddings</a></li>
<li class="chapter" data-level="8.5" data-path="dldnn.html"><a href="dldnn.html#dnncross"><i class="fa fa-check"></i><b>8.5</b> Cross-validation for deep learning models</a></li>
<li class="chapter" data-level="8.6" data-path="dldnn.html"><a href="dldnn.html#compare-and-evaluate-dnn-models"><i class="fa fa-check"></i><b>8.6</b> Compare and evaluate DNN models</a></li>
<li class="chapter" data-level="8.7" data-path="dldnn.html"><a href="dldnn.html#dllimitations"><i class="fa fa-check"></i><b>8.7</b> Limitations of deep learning</a></li>
<li class="chapter" data-level="8.8" data-path="dldnn.html"><a href="dldnn.html#dldnnsummary"><i class="fa fa-check"></i><b>8.8</b> Summary</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="dldnn.html"><a href="dldnn.html#in-this-chapter-you-learned-7"><i class="fa fa-check"></i><b>8.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dllstm.html"><a href="dllstm.html"><i class="fa fa-check"></i><b>9</b> Long short-term memory (LSTM) networks</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dllstm.html"><a href="dllstm.html#firstlstm"><i class="fa fa-check"></i><b>9.1</b> A first LSTM model</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="dllstm.html"><a href="dllstm.html#building-an-lstm"><i class="fa fa-check"></i><b>9.1.1</b> Building an LSTM</a></li>
<li class="chapter" data-level="9.1.2" data-path="dllstm.html"><a href="dllstm.html#lstmevaluation"><i class="fa fa-check"></i><b>9.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="dllstm.html"><a href="dllstm.html#compare-to-a-recurrent-neural-network"><i class="fa fa-check"></i><b>9.2</b> Compare to a recurrent neural network</a></li>
<li class="chapter" data-level="9.3" data-path="dllstm.html"><a href="dllstm.html#bilstm"><i class="fa fa-check"></i><b>9.3</b> Case study: bidirectional LSTM</a></li>
<li class="chapter" data-level="9.4" data-path="dllstm.html"><a href="dllstm.html#case-study-stacking-lstm-layers"><i class="fa fa-check"></i><b>9.4</b> Case study: stacking LSTM layers</a></li>
<li class="chapter" data-level="9.5" data-path="dllstm.html"><a href="dllstm.html#lstmpadding"><i class="fa fa-check"></i><b>9.5</b> Case study: padding</a></li>
<li class="chapter" data-level="9.6" data-path="dllstm.html"><a href="dllstm.html#case-study-training-a-regression-model"><i class="fa fa-check"></i><b>9.6</b> Case study: training a regression model</a></li>
<li class="chapter" data-level="9.7" data-path="dllstm.html"><a href="dllstm.html#case-study-vocabulary-size"><i class="fa fa-check"></i><b>9.7</b> Case study: vocabulary size</a></li>
<li class="chapter" data-level="9.8" data-path="dllstm.html"><a href="dllstm.html#lstmfull"><i class="fa fa-check"></i><b>9.8</b> The full game: LSTM</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="dllstm.html"><a href="dllstm.html#lstmfullpreprocess"><i class="fa fa-check"></i><b>9.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="9.8.2" data-path="dllstm.html"><a href="dllstm.html#lstmfullmodel"><i class="fa fa-check"></i><b>9.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="dllstm.html"><a href="dllstm.html#dllstmsummary"><i class="fa fa-check"></i><b>9.9</b> Summary</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="dllstm.html"><a href="dllstm.html#in-this-chapter-you-learned-8"><i class="fa fa-check"></i><b>9.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dlcnn.html"><a href="dlcnn.html"><i class="fa fa-check"></i><b>10</b> Convolutional neural networks</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dlcnn.html"><a href="dlcnn.html#what-are-cnns"><i class="fa fa-check"></i><b>10.1</b> What are CNNs?</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="dlcnn.html"><a href="dlcnn.html#kernel"><i class="fa fa-check"></i><b>10.1.1</b> Kernel</a></li>
<li class="chapter" data-level="10.1.2" data-path="dlcnn.html"><a href="dlcnn.html#kernel-size"><i class="fa fa-check"></i><b>10.1.2</b> Kernel size</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="dlcnn.html"><a href="dlcnn.html#firstcnn"><i class="fa fa-check"></i><b>10.2</b> A first CNN model</a></li>
<li class="chapter" data-level="10.3" data-path="dlcnn.html"><a href="dlcnn.html#case-study-adding-more-layers"><i class="fa fa-check"></i><b>10.3</b> Case study: adding more layers</a></li>
<li class="chapter" data-level="10.4" data-path="dlcnn.html"><a href="dlcnn.html#case-study-byte-pair-encoding"><i class="fa fa-check"></i><b>10.4</b> Case study: byte pair encoding</a></li>
<li class="chapter" data-level="10.5" data-path="dlcnn.html"><a href="dlcnn.html#lime"><i class="fa fa-check"></i><b>10.5</b> Case study: explainability with LIME</a></li>
<li class="chapter" data-level="10.6" data-path="dlcnn.html"><a href="dlcnn.html#keras-hyperparameter"><i class="fa fa-check"></i><b>10.6</b> Case study: hyperparameter search</a></li>
<li class="chapter" data-level="10.7" data-path="dlcnn.html"><a href="dlcnn.html#cross-validation-for-evaluation"><i class="fa fa-check"></i><b>10.7</b> Cross-validation for evaluation</a></li>
<li class="chapter" data-level="10.8" data-path="dlcnn.html"><a href="dlcnn.html#cnnfull"><i class="fa fa-check"></i><b>10.8</b> The full game: CNN</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullpreprocess"><i class="fa fa-check"></i><b>10.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="10.8.2" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullmodel"><i class="fa fa-check"></i><b>10.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="dlcnn.html"><a href="dlcnn.html#dlcnnsummary"><i class="fa fa-check"></i><b>10.9</b> Summary</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="dlcnn.html"><a href="dlcnn.html#in-this-chapter-you-learned-9"><i class="fa fa-check"></i><b>10.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="" data-path="text-models-in-the-real-world.html"><a href="text-models-in-the-real-world.html"><i class="fa fa-check"></i>Text models in the real world</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="regexp.html"><a href="regexp.html"><i class="fa fa-check"></i><b>A</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="A.1" data-path="regexp.html"><a href="regexp.html#literal-characters"><i class="fa fa-check"></i><b>A.1</b> Literal characters</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="regexp.html"><a href="regexp.html#meta-characters"><i class="fa fa-check"></i><b>A.1.1</b> Meta characters</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="regexp.html"><a href="regexp.html#full-stop-the-wildcard"><i class="fa fa-check"></i><b>A.2</b> Full stop, the wildcard</a></li>
<li class="chapter" data-level="A.3" data-path="regexp.html"><a href="regexp.html#character-classes"><i class="fa fa-check"></i><b>A.3</b> Character classes</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="regexp.html"><a href="regexp.html#shorthand-character-classes"><i class="fa fa-check"></i><b>A.3.1</b> Shorthand character classes</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="regexp.html"><a href="regexp.html#quantifiers"><i class="fa fa-check"></i><b>A.4</b> Quantifiers</a></li>
<li class="chapter" data-level="A.5" data-path="regexp.html"><a href="regexp.html#anchors"><i class="fa fa-check"></i><b>A.5</b> Anchors</a></li>
<li class="chapter" data-level="A.6" data-path="regexp.html"><a href="regexp.html#additional-resources"><i class="fa fa-check"></i><b>A.6</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixdata.html"><a href="appendixdata.html"><i class="fa fa-check"></i><b>B</b> Data</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixdata.html"><a href="appendixdata.html#hcandersen"><i class="fa fa-check"></i><b>B.1</b> Hans Christian Andersen fairy tales</a></li>
<li class="chapter" data-level="B.2" data-path="appendixdata.html"><a href="appendixdata.html#scotus-opinions"><i class="fa fa-check"></i><b>B.2</b> Opinions of the Supreme Court of the United States</a></li>
<li class="chapter" data-level="B.3" data-path="appendixdata.html"><a href="appendixdata.html#cfpb-complaints"><i class="fa fa-check"></i><b>B.3</b> Consumer Financial Protection Bureau (CFPB) complaints</a></li>
<li class="chapter" data-level="B.4" data-path="appendixdata.html"><a href="appendixdata.html#kickstarter-blurbs"><i class="fa fa-check"></i><b>B.4</b> Kickstarter campaign blurbs</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appendixbaseline.html"><a href="appendixbaseline.html"><i class="fa fa-check"></i><b>C</b> Baseline linear classifier</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appendixbaseline.html"><a href="appendixbaseline.html#read-in-the-data"><i class="fa fa-check"></i><b>C.1</b> Read in the data</a></li>
<li class="chapter" data-level="C.2" data-path="appendixbaseline.html"><a href="appendixbaseline.html#split-into-testtrain-and-create-resampling-folds"><i class="fa fa-check"></i><b>C.2</b> Split into test/train and create resampling folds</a></li>
<li class="chapter" data-level="C.3" data-path="appendixbaseline.html"><a href="appendixbaseline.html#recipe-for-data-preprocessing"><i class="fa fa-check"></i><b>C.3</b> Recipe for data preprocessing</a></li>
<li class="chapter" data-level="C.4" data-path="appendixbaseline.html"><a href="appendixbaseline.html#lasso-regularized-classification-model"><i class="fa fa-check"></i><b>C.4</b> Lasso regularized classification model</a></li>
<li class="chapter" data-level="C.5" data-path="appendixbaseline.html"><a href="appendixbaseline.html#a-model-workflow"><i class="fa fa-check"></i><b>C.5</b> A model workflow</a></li>
<li class="chapter" data-level="C.6" data-path="appendixbaseline.html"><a href="appendixbaseline.html#tune-the-workflow"><i class="fa fa-check"></i><b>C.6</b> Tune the workflow</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supervised Machine Learning for Text Analysis in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mlclassification" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Classification<a href="mlclassification.html#mlclassification" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In Chapter <a href="mlregression.html#mlregression">6</a>, we focused on modeling to predict <em>continuous values</em> for documents, such as what year a Supreme Court opinion was published. This is an example of a regression model. We can also use machine learning to predict <em>labels</em> on documents using a classification model. For both types of prediction questions, we develop a learner or model to describe the relationship between a target or outcome variable and our input features; what is different about a classification model is the nature of that outcome.</p>
<ul>
<li><p>A <strong>regression model</strong> predicts a numeric or continuous value.</p></li>
<li><p>A <strong>classification model</strong> predicts a class label or group membership.</p></li>
</ul>
<p>For our classification example in this chapter, let’s consider the data set of consumer complaints submitted to the US Consumer Finance Protection Bureau. Let’s read in the complaint data (Section <a href="appendixdata.html#cfpb-complaints">B.3</a>) with <code>read_csv()</code>.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="mlclassification.html#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb258-2"><a href="mlclassification.html#cb258-2" aria-hidden="true" tabindex="-1"></a>complaints <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/complaints.csv.gz&quot;</span>)</span></code></pre></div>
<p>We can start by taking a quick <code>glimpse()</code> at the data to see what we have to work with. This data set contains a text field with the complaint, along with information regarding what it was for,
how and when it was filed, and the response from the bureau.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="mlclassification.html#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(complaints)</span></code></pre></div>
<pre><code>#&gt; Rows: 117,214
#&gt; Columns: 18
#&gt; $ date_received                &lt;date&gt; 2019-09-24, 2019-10-25, 2019-11-08, 2019…
#&gt; $ product                      &lt;chr&gt; &quot;Debt collection&quot;, &quot;Credit reporting, cre…
#&gt; $ sub_product                  &lt;chr&gt; &quot;I do not know&quot;, &quot;Credit reporting&quot;, &quot;I d…
#&gt; $ issue                        &lt;chr&gt; &quot;Attempts to collect debt not owed&quot;, &quot;Inc…
#&gt; $ sub_issue                    &lt;chr&gt; &quot;Debt is not yours&quot;, &quot;Information belongs…
#&gt; $ consumer_complaint_narrative &lt;chr&gt; &quot;transworld systems inc. \nis trying to c…
#&gt; $ company_public_response      &lt;chr&gt; NA, &quot;Company has responded to the consume…
#&gt; $ company                      &lt;chr&gt; &quot;TRANSWORLD SYSTEMS INC&quot;, &quot;TRANSUNION INT…
#&gt; $ state                        &lt;chr&gt; &quot;FL&quot;, &quot;CA&quot;, &quot;NC&quot;, &quot;RI&quot;, &quot;FL&quot;, &quot;TX&quot;, &quot;SC&quot;,…
#&gt; $ zip_code                     &lt;chr&gt; &quot;335XX&quot;, &quot;937XX&quot;, &quot;275XX&quot;, &quot;029XX&quot;, &quot;333X…
#&gt; $ tags                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
#&gt; $ consumer_consent_provided    &lt;chr&gt; &quot;Consent provided&quot;, &quot;Consent provided&quot;, &quot;…
#&gt; $ submitted_via                &lt;chr&gt; &quot;Web&quot;, &quot;Web&quot;, &quot;Web&quot;, &quot;Web&quot;, &quot;Web&quot;, &quot;Web&quot;,…
#&gt; $ date_sent_to_company         &lt;date&gt; 2019-09-24, 2019-10-25, 2019-11-08, 2019…
#&gt; $ company_response_to_consumer &lt;chr&gt; &quot;Closed with explanation&quot;, &quot;Closed with e…
#&gt; $ timely_response              &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;,…
#&gt; $ consumer_disputed            &lt;chr&gt; &quot;N/A&quot;, &quot;N/A&quot;, &quot;N/A&quot;, &quot;N/A&quot;, &quot;N/A&quot;, &quot;N/A&quot;,…
#&gt; $ complaint_id                 &lt;dbl&gt; 3384392, 3417821, 3433198, 3366475, 33853…</code></pre>
<p>In this chapter, we will build classification models to predict what type of financial <code>product</code> the complaints are referring to, i.e., a label or categorical variable. The goal of predictive modeling with text input features and a categorical outcome is to learn and model the relationship between those input features, typically created through steps as outlined in Chapters <a href="language.html#language">1</a> through <a href="embeddings.html#embeddings">5</a>, and the class label or categorical outcome. Most classification models do predict the probability of a class (a numeric output), but the particular characteristics of this output make classification models different enough from regression models that we handle them differently.</p>
<div id="classfirstattemptlookatdata" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> A first classification model<a href="mlclassification.html#classfirstattemptlookatdata" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For our first model, let’s build a binary classification model to predict whether a submitted complaint is about “Credit reporting, credit repair services, or other personal consumer reports” or not.</p>
<div class="rmdnote">
<p>
This kind of “yes or no” binary classification model is both common and useful in real-world text machine learning problems.
</p>
</div>
<p>The outcome variable <code>product</code> contains more categories than this, so we need to transform this variable to only contain the values “Credit reporting, credit repair services, or other personal consumer reports” and “Other.”</p>
<p>It is always a good idea to look at your data! Here are the first six complaints:</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="mlclassification.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(complaints<span class="sc">$</span>consumer_complaint_narrative)</span></code></pre></div>
<pre><code>#&gt; [1] &quot;transworld systems inc. \nis trying to collect a debt that is not mine,
not owed and is inaccurate.&quot;
#&gt; [2] &quot;I would like to request the suppression of the following items from my
credit report, which are the result of my falling victim to identity theft.
This information does not relate to [ transactions that I have made/accounts
that I have opened ], as the attached supporting documentation can attest. As
such, it should be blocked from appearing on my credit report pursuant to
section 605B of the Fair Credit Reporting Act.&quot;
#&gt; [3] &quot;Over the past 2 weeks, I have been receiving excessive amounts of
telephone calls from the company listed in this complaint. The calls occur
between XXXX XXXX and XXXX XXXX to my cell and at my job. The company does not
have the right to harass me at work and I want this to stop. It is extremely
distracting to be told 5 times a day that I have a call from this collection
agency while at work.&quot;
#&gt; [4] &quot;I was sold access to an event digitally, of which I have all the
screenshots to detail the transactions, transferred the money and was provided
with only a fake of a ticket. I have reported this to paypal and it was for the
amount of {$21.00} including a {$1.00} fee from paypal. \n\nThis occured on
XX/XX/2019, by paypal user who gave two accounts : 1 ) XXXX 2 ) XXXX XXXX&quot;
#&gt; [5] &quot;While checking my credit report I noticed three collections by a
company called ARS that i was unfamiliar with. I disputed these collections
with XXXX, and XXXX and they both replied that they contacted the creditor and
the creditor verified the debt so I asked for proof which both bureaus replied
that they are not required to prove anything. I then mailed a certified letter
to ARS requesting proof of the debts n the form of an original aggrement, or a
proof of a right to the debt, or even so much as the process as to how the bill
was calculated, to which I was simply replied a letter for each collection
claim that listed my name an account number and an amount with no other
information to verify the debts after I sent a clear notice to provide me
evidence. Afterwards I recontacted both XXXX, and XXXX, to redispute on the
premise that it is not my debt if evidence can not be drawn up, I feel as if I
am being personally victimized by ARS on my credit report for debts that are
not owed to them or any party for that matter, and I feel discouraged that the
credit bureaus who control many aspects of my personal finances are so
negligent about my information.&quot;
#&gt; [6] &quot;I would like the credit bureau to correct my XXXX XXXX XXXX XXXX
balance. My correct balance is XXXX&quot;</code></pre>
<p>The complaint narratives contain many series of capital <code>"X"</code>’s. These strings (like “XX/XX” or “XXXX XXXX XXXX XXXX”) are used to to protect personally identifiable information (PII) in this publicly available data set. This is not a universal censoring mechanism; censoring and PII protection will vary from source to source. Hopefully you will be able to find information on PII censoring in a data dictionary, but you should always look at the data yourself to verify.</p>
<p>We also see that monetary amounts are surrounded by curly brackets (like <code>"{$21.00}"</code>); this is another text preprocessing step that has been taken care of for us. We could craft a regular expression to extract all the dollar amounts.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="mlclassification.html#cb263-1" aria-hidden="true" tabindex="-1"></a>complaints<span class="sc">$</span>consumer_complaint_narrative <span class="sc">%&gt;%</span></span>
<span id="cb263-2"><a href="mlclassification.html#cb263-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">str_extract_all</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">{</span><span class="sc">\\</span><span class="st">$[0-9</span><span class="sc">\\</span><span class="st">.]*</span><span class="sc">\\</span><span class="st">}&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb263-3"><a href="mlclassification.html#cb263-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compact</span>() <span class="sc">%&gt;%</span></span>
<span id="cb263-4"><a href="mlclassification.html#cb263-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>()</span></code></pre></div>
<pre><code>#&gt; [[1]]
#&gt; [1] &quot;{$21.00}&quot; &quot;{$1.00}&quot; 
#&gt; 
#&gt; [[2]]
#&gt; [1] &quot;{$2300.00}&quot;
#&gt; 
#&gt; [[3]]
#&gt; [1] &quot;{$200.00}&quot;  &quot;{$5000.00}&quot; &quot;{$5000.00}&quot; &quot;{$770.00}&quot;  &quot;{$800.00}&quot; 
#&gt; [6] &quot;{$5000.00}&quot;
#&gt; 
#&gt; [[4]]
#&gt; [1] &quot;{$15000.00}&quot; &quot;{$11000.00}&quot; &quot;{$420.00}&quot;   &quot;{$15000.00}&quot;
#&gt; 
#&gt; [[5]]
#&gt; [1] &quot;{$0.00}&quot; &quot;{$0.00}&quot; &quot;{$0.00}&quot; &quot;{$0.00}&quot;
#&gt; 
#&gt; [[6]]
#&gt; [1] &quot;{$650.00}&quot;</code></pre>
<p>In Section <a href="mlclassification.html#customfeatures">7.9</a>, we will use an approach like this for custom feature engineering from the text.</p>
<div id="classfirstmodel" class="section level3 hasAnchor" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Building our first classification model<a href="mlclassification.html#classfirstmodel" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This data set includes more possible predictors than the text alone, but for this first model we will only use the text variable <code>consumer_complaint_narrative</code>.
Let’s create a factor outcome variable <code>product</code> with two levels, “Credit” and “Other.”
Then, we split the data into training and testing data sets.
We can use the <code>initial_split()</code> function from <strong>rsample</strong> to create this binary split of the data.
The <code>strata</code> argument ensures that the distribution of <code>product</code> is similar in the training set and testing set.
Since the split uses random sampling, we set a seed so we can reproduce our results.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="mlclassification.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb265-2"><a href="mlclassification.html#cb265-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb265-3"><a href="mlclassification.html#cb265-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb265-4"><a href="mlclassification.html#cb265-4" aria-hidden="true" tabindex="-1"></a>complaints2class <span class="ot">&lt;-</span> complaints <span class="sc">%&gt;%</span></span>
<span id="cb265-5"><a href="mlclassification.html#cb265-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">product =</span> <span class="fu">factor</span>(<span class="fu">if_else</span>(</span>
<span id="cb265-6"><a href="mlclassification.html#cb265-6" aria-hidden="true" tabindex="-1"></a>    product <span class="sc">==</span> <span class="fu">paste</span>(<span class="st">&quot;Credit reporting, credit repair services,&quot;</span>,</span>
<span id="cb265-7"><a href="mlclassification.html#cb265-7" aria-hidden="true" tabindex="-1"></a>                     <span class="st">&quot;or other personal consumer reports&quot;</span>),</span>
<span id="cb265-8"><a href="mlclassification.html#cb265-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Credit&quot;</span>, <span class="st">&quot;Other&quot;</span></span>
<span id="cb265-9"><a href="mlclassification.html#cb265-9" aria-hidden="true" tabindex="-1"></a>  )))</span>
<span id="cb265-10"><a href="mlclassification.html#cb265-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb265-11"><a href="mlclassification.html#cb265-11" aria-hidden="true" tabindex="-1"></a>complaints_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(complaints2class, <span class="at">strata =</span> product)</span>
<span id="cb265-12"><a href="mlclassification.html#cb265-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb265-13"><a href="mlclassification.html#cb265-13" aria-hidden="true" tabindex="-1"></a>complaints_train <span class="ot">&lt;-</span> <span class="fu">training</span>(complaints_split)</span>
<span id="cb265-14"><a href="mlclassification.html#cb265-14" aria-hidden="true" tabindex="-1"></a>complaints_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(complaints_split)</span></code></pre></div>
<p>The dimensions of the two splits show that this first step worked as we planned.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="mlclassification.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(complaints_train)</span></code></pre></div>
<pre><code>#&gt; [1] 87910    18</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="mlclassification.html#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(complaints_test)</span></code></pre></div>
<pre><code>#&gt; [1] 29304    18</code></pre>
<p>Next we need to preprocess this data to prepare it for modeling; we have text data, and we need to build numeric features for machine learning from that text.</p>
<p>The <strong>recipes</strong> package, part of tidymodels, allows us to create a specification of preprocessing steps we want to perform. These transformations are estimated (or “trained”) on the training set so that they can be applied in the same way on the testing set or new data at prediction time, without data leakage.
We initialize our set of preprocessing transformations with the <code>recipe()</code> function, using a formula expression to specify the variables, our outcome plus our predictor, along with the data set.</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="mlclassification.html#cb270-1" aria-hidden="true" tabindex="-1"></a>complaints_rec <span class="ot">&lt;-</span></span>
<span id="cb270-2"><a href="mlclassification.html#cb270-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(product <span class="sc">~</span> consumer_complaint_narrative, <span class="at">data =</span> complaints_train)</span></code></pre></div>
<p>Now we add steps to process the text of the complaints; we use <strong>textrecipes</strong> to handle the <code>consumer_complaint_narrative</code> variable. First we tokenize the text to words with <code>step_tokenize()</code>. By default this uses <code>tokenizers::tokenize_words()</code>.
Before we calculate tf-idf we use <code>step_tokenfilter()</code> to only keep the 1000 most frequent tokens, to avoid creating too many variables in our first model. To finish, we use <code>step_tfidf()</code> to compute tf-idf.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="mlclassification.html#cb271-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(textrecipes)</span>
<span id="cb271-2"><a href="mlclassification.html#cb271-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb271-3"><a href="mlclassification.html#cb271-3" aria-hidden="true" tabindex="-1"></a>complaints_rec <span class="ot">&lt;-</span> complaints_rec <span class="sc">%&gt;%</span></span>
<span id="cb271-4"><a href="mlclassification.html#cb271-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenize</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb271-5"><a href="mlclassification.html#cb271-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenfilter</span>(consumer_complaint_narrative, <span class="at">max_tokens =</span> <span class="fl">1e3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb271-6"><a href="mlclassification.html#cb271-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tfidf</span>(consumer_complaint_narrative)</span></code></pre></div>
<p>Now that we have a full specification of the preprocessing recipe, we can build up a tidymodels <code>workflow()</code> to bundle together our modeling components.</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="mlclassification.html#cb272-1" aria-hidden="true" tabindex="-1"></a>complaint_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb272-2"><a href="mlclassification.html#cb272-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(complaints_rec)</span></code></pre></div>
<p>Let’s start with a naive Bayes model <span class="citation">(<a href="#ref-kim2006" role="doc-biblioref">S. Kim et al. 2006</a>; <a href="#ref-Kibriya2005" role="doc-biblioref">Kibriya et al. 2005</a>; <a href="#ref-Eibe2006" role="doc-biblioref">Frank and Bouckaert 2006</a>)</span>, which is available in the tidymodels package <strong>discrim</strong>.
One of the main advantages of a naive Bayes model is its ability to handle a large number of features, such as those we deal with when using word count methods.
Here we have only kept the 1000 most frequent tokens, but we could have kept more tokens and a naive Bayes model would still be able to handle such predictors well. For now, we will limit the model to a moderate number of tokens.</p>

<div class="rmdpackage">
In <strong>tidymodels</strong>, the package for creating model specifications is <strong>parsnip</strong> <span class="citation">(<a href="#ref-R-parsnip" role="doc-biblioref">Kuhn and Vaughan 2021b</a>)</span>. The <strong>parsnip</strong> package provides the functions for creating all the models we have used so far, but other extra packages provide more. The <strong>discrim</strong> package is an extension package for <strong>parsnip</strong> that contains model definitions for various discriminant analysis models, including naive Bayes.
</div>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="mlclassification.html#cb273-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(discrim)</span>
<span id="cb273-2"><a href="mlclassification.html#cb273-2" aria-hidden="true" tabindex="-1"></a>nb_spec <span class="ot">&lt;-</span> <span class="fu">naive_Bayes</span>() <span class="sc">%&gt;%</span></span>
<span id="cb273-3"><a href="mlclassification.html#cb273-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb273-4"><a href="mlclassification.html#cb273-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;naivebayes&quot;</span>)</span>
<span id="cb273-5"><a href="mlclassification.html#cb273-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb273-6"><a href="mlclassification.html#cb273-6" aria-hidden="true" tabindex="-1"></a>nb_spec</span></code></pre></div>
<pre><code>#&gt; Naive Bayes Model Specification (classification)
#&gt; 
#&gt; Computational engine: naivebayes</code></pre>
<p>Now we have everything we need to fit our first classification model. We can add the naive Bayes model to our workflow, and then we can fit this workflow to our training data.</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="mlclassification.html#cb275-1" aria-hidden="true" tabindex="-1"></a>nb_fit <span class="ot">&lt;-</span> complaint_wf <span class="sc">%&gt;%</span></span>
<span id="cb275-2"><a href="mlclassification.html#cb275-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(nb_spec) <span class="sc">%&gt;%</span></span>
<span id="cb275-3"><a href="mlclassification.html#cb275-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> complaints_train)</span></code></pre></div>
<p>We have trained our first classification model!</p>
</div>
<div id="evaluation" class="section level3 hasAnchor" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Evaluation<a href="mlclassification.html#evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Like we discussed in Section <a href="mlregression.html#firstregressionevaluation">6.1.2</a>, we should not use the test set to compare models or different model parameters. The test set is a precious resource that should only be used at the end of the model training process to estimate performance on new data. Instead, we will use <em>resampling</em> methods to evaluate our model.</p>
<p>Let’s use resampling to estimate the performance of the naive Bayes classification model we just fit. We can do this using resampled data sets built from the training set. Let’s create 10-fold cross-validation sets, and use these resampled sets for performance estimates.</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="mlclassification.html#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb276-2"><a href="mlclassification.html#cb276-2" aria-hidden="true" tabindex="-1"></a>complaints_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(complaints_train)</span>
<span id="cb276-3"><a href="mlclassification.html#cb276-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-4"><a href="mlclassification.html#cb276-4" aria-hidden="true" tabindex="-1"></a>complaints_folds</span></code></pre></div>
<pre><code>#&gt; #  10-fold cross-validation 
#&gt; # A tibble: 10 × 2
#&gt;    splits               id    
#&gt;    &lt;list&gt;               &lt;chr&gt; 
#&gt;  1 &lt;split [79119/8791]&gt; Fold01
#&gt;  2 &lt;split [79119/8791]&gt; Fold02
#&gt;  3 &lt;split [79119/8791]&gt; Fold03
#&gt;  4 &lt;split [79119/8791]&gt; Fold04
#&gt;  5 &lt;split [79119/8791]&gt; Fold05
#&gt;  6 &lt;split [79119/8791]&gt; Fold06
#&gt;  7 &lt;split [79119/8791]&gt; Fold07
#&gt;  8 &lt;split [79119/8791]&gt; Fold08
#&gt;  9 &lt;split [79119/8791]&gt; Fold09
#&gt; 10 &lt;split [79119/8791]&gt; Fold10</code></pre>
<p>Each of these splits contains information about how to create cross-validation folds from the original training data. In this example, 90% of the training data is included in each fold, and the other 10% is held out for evaluation.</p>
<p>For convenience, let’s again use a <code>workflow()</code> for our resampling estimates of performance.</p>
<div class="rmdwarning">
<p>
Using a <code>workflow()</code> isn’t required (you can fit or tune a model plus a preprocessor), but it can make your code easier to read and organize.
</p>
</div>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="mlclassification.html#cb278-1" aria-hidden="true" tabindex="-1"></a>nb_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb278-2"><a href="mlclassification.html#cb278-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(complaints_rec) <span class="sc">%&gt;%</span></span>
<span id="cb278-3"><a href="mlclassification.html#cb278-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(nb_spec)</span>
<span id="cb278-4"><a href="mlclassification.html#cb278-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-5"><a href="mlclassification.html#cb278-5" aria-hidden="true" tabindex="-1"></a>nb_wf</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: naive_Bayes()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 3 Recipe Steps
#&gt; 
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Naive Bayes Model Specification (classification)
#&gt; 
#&gt; Computational engine: naivebayes</code></pre>
<p>In the last section, we fit one time to the training data as a whole. Now, to estimate how well that model performs, let’s fit the model many times, once to each of these resampled folds, and then evaluate on the heldout part of each resampled fold.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="mlclassification.html#cb280-1" aria-hidden="true" tabindex="-1"></a>nb_rs <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb280-2"><a href="mlclassification.html#cb280-2" aria-hidden="true" tabindex="-1"></a>  nb_wf,</span>
<span id="cb280-3"><a href="mlclassification.html#cb280-3" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb280-4"><a href="mlclassification.html#cb280-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">control_resamples</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>)</span>
<span id="cb280-5"><a href="mlclassification.html#cb280-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>We can extract the relevant information using <code>collect_metrics()</code> and <code>collect_predictions()</code>.</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="mlclassification.html#cb281-1" aria-hidden="true" tabindex="-1"></a>nb_rs_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(nb_rs)</span>
<span id="cb281-2"><a href="mlclassification.html#cb281-2" aria-hidden="true" tabindex="-1"></a>nb_rs_predictions <span class="ot">&lt;-</span> <span class="fu">collect_predictions</span>(nb_rs)</span></code></pre></div>
<p>What results do we see, in terms of performance metrics?</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="mlclassification.html#cb282-1" aria-hidden="true" tabindex="-1"></a>nb_rs_metrics</span></code></pre></div>
<pre><code>#&gt; # A tibble: 2 × 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.807    10 0.00469 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.884    10 0.00177 Preprocessor1_Model1</code></pre>
<p>The default performance parameters for binary classification are accuracy and ROC AUC (area under the receiver operator characteristic curve). For these resamples, the average accuracy is 80.7%.</p>



<div class="rmdnote">
<p>
Accuracy and ROC AUC are performance metrics used for classification models. For both, values closer to 1 are better.
</p>
<p>
Accuracy is the proportion of the data that is predicted correctly. Be aware that accuracy can be misleading in some situations, such as for imbalanced data sets.
</p>
<p>
ROC AUC measures how well a classifier performs at different thresholds. The ROC curve plots the true positive rate against the false positive rate; AUC closer to 1 indicates a better-performing model, while AUC closer to 0.5 indicates a model that does no better than random guessing.
</p>
</div>
<p>Figure <a href="mlclassification.html#fig:firstroccurve">7.1</a> shows the ROC curve, a visualization of how well a classification model can distinguish between classes, for our first classification model on each of the resampled data sets.</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="mlclassification.html#cb284-1" aria-hidden="true" tabindex="-1"></a>nb_rs_predictions <span class="sc">%&gt;%</span></span>
<span id="cb284-2"><a href="mlclassification.html#cb284-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb284-3"><a href="mlclassification.html#cb284-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(<span class="at">truth =</span> product, .pred_Credit) <span class="sc">%&gt;%</span></span>
<span id="cb284-4"><a href="mlclassification.html#cb284-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb284-5"><a href="mlclassification.html#cb284-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb284-6"><a href="mlclassification.html#cb284-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="cn">NULL</span>,</span>
<span id="cb284-7"><a href="mlclassification.html#cb284-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;ROC curve for US Consumer Finance Complaints&quot;</span>,</span>
<span id="cb284-8"><a href="mlclassification.html#cb284-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Each resample fold is shown in a different color&quot;</span></span>
<span id="cb284-9"><a href="mlclassification.html#cb284-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:firstroccurve"></span>
<img src="07_ml_classification_files/figure-html/firstroccurve-1.svg" alt="ROC curve for naive Bayes classifier with resamples of US Consumer Finance Bureau complaints" width="672" />
<p class="caption">
FIGURE 7.1: ROC curve for naive Bayes classifier with resamples of US Consumer Finance Bureau complaints
</p>
</div>
<p>The area under each of these curves is the <code>roc_auc</code> metric we have computed. If the curve was close to the diagonal line, then the model’s predictions would be no better than random guessing.</p>
<p>Another way to evaluate our model is to evaluate the confusion matrix. A confusion matrix tabulates a model’s false positives and false negatives for each class.
The function <code>conf_mat_resampled()</code> computes a separate confusion matrix for each resample and takes the average of the cell counts. This allows us to visualize an overall confusion matrix rather than needing to examine each resample individually.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="mlclassification.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">conf_mat_resampled</span>(nb_rs, <span class="at">tidy =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb285-2"><a href="mlclassification.html#cb285-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:firstheatmap"></span>
<img src="07_ml_classification_files/figure-html/firstheatmap-1.svg" alt="Confusion matrix for naive Bayes classifier, showing some bias toward predicting the credit category" width="672" />
<p class="caption">
FIGURE 7.2: Confusion matrix for naive Bayes classifier, showing some bias toward predicting the credit category
</p>
</div>
<p>In Figure <a href="mlclassification.html#fig:firstheatmap">7.2</a>, the squares for “Credit”/“Credit” and “Other”/“Other” have a darker shade than the off-diagonal squares. This is a good sign, meaning that our model is right more often than not! However, this first model is struggling somewhat since many observations from the “Credit” class are being mispredicted as “Other.”</p>
<div class="rmdwarning">
<p>
One metric alone cannot give you a complete picture of how well your classification model is performing. The confusion matrix is a good starting point to get an overview of your model performance, as it includes rich information.
</p>
</div>
<p></p>
<p>This is real data from a government agency, and these kinds of performance metrics must be interpreted in the context of how such a model would be used. What happens if the model we trained gets a classification wrong for a consumer complaint? What impact will it have if more “Other” complaints are correctly identified than “Credit” complaints, either for consumers or for policymakers?</p>
</div>
</div>
<div id="classnull" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Compare to the null model<a href="mlclassification.html#classnull" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Like we did in Section <a href="mlregression.html#regnull">6.2</a>, we can assess a model like this one by comparing its performance to a “null model” or baseline model, a simple, non-informative model that always predicts the largest class for classification. Such a model is perhaps the simplest heuristic or rule-based alternative that we can consider as we assess our modeling efforts.</p>
<p>We can build a classification <code>null_model()</code> specification and add it to a <code>workflow()</code> with the same preprocessing recipe we used in the previous section, to estimate performance.</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="mlclassification.html#cb286-1" aria-hidden="true" tabindex="-1"></a>null_classification <span class="ot">&lt;-</span> <span class="fu">null_model</span>() <span class="sc">%&gt;%</span></span>
<span id="cb286-2"><a href="mlclassification.html#cb286-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;parsnip&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb286-3"><a href="mlclassification.html#cb286-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb286-4"><a href="mlclassification.html#cb286-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb286-5"><a href="mlclassification.html#cb286-5" aria-hidden="true" tabindex="-1"></a>null_rs <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb286-6"><a href="mlclassification.html#cb286-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(complaints_rec) <span class="sc">%&gt;%</span></span>
<span id="cb286-7"><a href="mlclassification.html#cb286-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(null_classification) <span class="sc">%&gt;%</span></span>
<span id="cb286-8"><a href="mlclassification.html#cb286-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit_resamples</span>(</span>
<span id="cb286-9"><a href="mlclassification.html#cb286-9" aria-hidden="true" tabindex="-1"></a>    complaints_folds</span>
<span id="cb286-10"><a href="mlclassification.html#cb286-10" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>What results do we obtain from the null model, in terms of performance metrics?</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="mlclassification.html#cb287-1" aria-hidden="true" tabindex="-1"></a>null_rs <span class="sc">%&gt;%</span></span>
<span id="cb287-2"><a href="mlclassification.html#cb287-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>()</span></code></pre></div>
<pre><code>#&gt; # A tibble: 2 × 6
#&gt;   .metric  .estimator  mean     n std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.526    10 0.00143 Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.5      10 0       Preprocessor1_Model1</code></pre>
<p>The accuracy and ROC AUC indicate that this null model is, like in the regression case, dramatically worse than even our first model. The text of the CFPB complaints is predictive relative to the category we are building models for.</p>
</div>
<div id="comparetolasso" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Compare to a lasso classification model<a href="mlclassification.html#comparetolasso" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Regularized linear models are a class of statistical model that can be used in regression and classification tasks. Linear models are not considered cutting edge in NLP research, but are a workhorse in real-world practice. Here we will use a lasso regularized model <span class="citation">(<a href="#ref-Tibshirani1996" role="doc-biblioref">Tibshirani 1996</a>)</span>, where the regularization method also performs variable selection. In text analysis, we typically have many tokens, which are the features in our machine learning problem.</p>
<div class="rmdnote">
<p>
Using regularization helps us choose a simpler model that we expect to generalize better to new observations, and variable selection helps us identify which features to include in our model.
</p>
</div>
<p>Lasso regression or classification learns how much of a <em>penalty</em> to put on some features (sometimes penalizing all the way down to zero) so that we can select only some features out of the high-dimensional space of original possible variables (tokens) for the final model.</p>
<p>Let’s create a specification of a lasso regularized model. Remember that in tidymodels, specifying a model has three components: the algorithm, the mode, and the computational engine.</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="mlclassification.html#cb289-1" aria-hidden="true" tabindex="-1"></a>lasso_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fl">0.01</span>, <span class="at">mixture =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb289-2"><a href="mlclassification.html#cb289-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb289-3"><a href="mlclassification.html#cb289-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>)</span>
<span id="cb289-4"><a href="mlclassification.html#cb289-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-5"><a href="mlclassification.html#cb289-5" aria-hidden="true" tabindex="-1"></a>lasso_spec</span></code></pre></div>
<pre><code>#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = 0.01
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>Then we can create another <code>workflow()</code> object with the lasso specification. Notice that we can reuse our text preprocessing recipe.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="mlclassification.html#cb291-1" aria-hidden="true" tabindex="-1"></a>lasso_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb291-2"><a href="mlclassification.html#cb291-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(complaints_rec) <span class="sc">%&gt;%</span></span>
<span id="cb291-3"><a href="mlclassification.html#cb291-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(lasso_spec)</span>
<span id="cb291-4"><a href="mlclassification.html#cb291-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-5"><a href="mlclassification.html#cb291-5" aria-hidden="true" tabindex="-1"></a>lasso_wf</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: logistic_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 3 Recipe Steps
#&gt; 
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = 0.01
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>Now we estimate the performance of this first lasso classification model with <code>fit_resamples()</code>.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="mlclassification.html#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb293-2"><a href="mlclassification.html#cb293-2" aria-hidden="true" tabindex="-1"></a>lasso_rs <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb293-3"><a href="mlclassification.html#cb293-3" aria-hidden="true" tabindex="-1"></a>  lasso_wf,</span>
<span id="cb293-4"><a href="mlclassification.html#cb293-4" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb293-5"><a href="mlclassification.html#cb293-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">control_resamples</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>)</span>
<span id="cb293-6"><a href="mlclassification.html#cb293-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Let’s again extract the relevant information using <code>collect_metrics()</code> and <code>collect_predictions()</code></p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="mlclassification.html#cb294-1" aria-hidden="true" tabindex="-1"></a>lasso_rs_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(lasso_rs)</span>
<span id="cb294-2"><a href="mlclassification.html#cb294-2" aria-hidden="true" tabindex="-1"></a>lasso_rs_predictions <span class="ot">&lt;-</span> <span class="fu">collect_predictions</span>(lasso_rs)</span></code></pre></div>
<p>Now we can see that <code>lasso_rs_metrics</code> contains the same default performance metrics we have been using so far in this chapter.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="mlclassification.html#cb295-1" aria-hidden="true" tabindex="-1"></a>lasso_rs_metrics</span></code></pre></div>
<pre><code>#&gt; # A tibble: 2 × 6
#&gt;   .metric  .estimator  mean     n  std_err .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary     0.870    10 0.00126  Preprocessor1_Model1
#&gt; 2 roc_auc  binary     0.939    10 0.000641 Preprocessor1_Model1</code></pre>
<p>This looks pretty promising, considering we haven’t yet done any tuning of the lasso hyperparameters.
Figure <a href="mlclassification.html#fig:lassoroccurve">7.3</a> shows the ROC curves for this regularized model on each of the resampled data sets.</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="mlclassification.html#cb297-1" aria-hidden="true" tabindex="-1"></a>lasso_rs_predictions <span class="sc">%&gt;%</span></span>
<span id="cb297-2"><a href="mlclassification.html#cb297-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb297-3"><a href="mlclassification.html#cb297-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(<span class="at">truth =</span> product, .pred_Credit) <span class="sc">%&gt;%</span></span>
<span id="cb297-4"><a href="mlclassification.html#cb297-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb297-5"><a href="mlclassification.html#cb297-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb297-6"><a href="mlclassification.html#cb297-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="cn">NULL</span>,</span>
<span id="cb297-7"><a href="mlclassification.html#cb297-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;ROC curve for US Consumer Finance Complaints&quot;</span>,</span>
<span id="cb297-8"><a href="mlclassification.html#cb297-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Each resample fold is shown in a different color&quot;</span></span>
<span id="cb297-9"><a href="mlclassification.html#cb297-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lassoroccurve"></span>
<img src="07_ml_classification_files/figure-html/lassoroccurve-1.svg" alt="ROC curve for lasso regularized classifier with resamples of US Consumer Finance Bureau complaints" width="672" />
<p class="caption">
FIGURE 7.3: ROC curve for lasso regularized classifier with resamples of US Consumer Finance Bureau complaints
</p>
</div>
<p>Let’s finish this section by generating a confusion matrix, shown in Figure <a href="mlclassification.html#fig:lassoheatmap">7.4</a>.
Our lasso model is better at separating the classes than the naive Bayes model in Section <a href="mlclassification.html#classfirstmodel">7.1.1</a>, and our results are more symmetrical than those for the naive Bayes model in Figure <a href="mlclassification.html#fig:firstheatmap">7.2</a>.</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="mlclassification.html#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="fu">conf_mat_resampled</span>(lasso_rs, <span class="at">tidy =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb298-2"><a href="mlclassification.html#cb298-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lassoheatmap"></span>
<img src="07_ml_classification_files/figure-html/lassoheatmap-1.svg" alt="Confusion matrix for a lasso regularized classifier, with more symmetric results" width="672" />
<p class="caption">
FIGURE 7.4: Confusion matrix for a lasso regularized classifier, with more symmetric results
</p>
</div>
</div>
<div id="tunelasso" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Tuning lasso hyperparameters<a href="mlclassification.html#tunelasso" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The value <code>penalty = 0.01</code> for regularization in Section <a href="mlclassification.html#comparetolasso">7.3</a> was picked somewhat arbitrarily. How do we know the <em>right</em> or <em>best</em> regularization parameter penalty? This is a model hyperparameter, and we cannot learn its best value during model training, but we can estimate the best value by training many models on resampled data sets and exploring how well all these models perform. Let’s build a new model specification for <strong>model tuning</strong>.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="mlclassification.html#cb299-1" aria-hidden="true" tabindex="-1"></a>tune_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb299-2"><a href="mlclassification.html#cb299-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb299-3"><a href="mlclassification.html#cb299-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>)</span>
<span id="cb299-4"><a href="mlclassification.html#cb299-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb299-5"><a href="mlclassification.html#cb299-5" aria-hidden="true" tabindex="-1"></a>tune_spec</span></code></pre></div>
<pre><code>#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = tune()
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>After the tuning process, we can select a single best numeric value.</p>
<div class="rmdnote">
<p>
Think of <code>tune()</code> here as a placeholder for the regularization penalty.
</p>
</div>
<p>We can create a regular grid of values to try, using a convenience function for <code>penalty()</code>.</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="mlclassification.html#cb301-1" aria-hidden="true" tabindex="-1"></a>lambda_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">penalty</span>(), <span class="at">levels =</span> <span class="dv">30</span>)</span>
<span id="cb301-2"><a href="mlclassification.html#cb301-2" aria-hidden="true" tabindex="-1"></a>lambda_grid</span></code></pre></div>
<pre><code>#&gt; # A tibble: 30 × 1
#&gt;     penalty
#&gt;       &lt;dbl&gt;
#&gt;  1 1   e-10
#&gt;  2 2.21e-10
#&gt;  3 4.89e-10
#&gt;  4 1.08e- 9
#&gt;  5 2.40e- 9
#&gt;  6 5.30e- 9
#&gt;  7 1.17e- 8
#&gt;  8 2.59e- 8
#&gt;  9 5.74e- 8
#&gt; 10 1.27e- 7
#&gt; # … with 20 more rows</code></pre>
<p>The function <code>grid_regular()</code> is from the <strong>dials</strong> package. It chooses sensible values to try for a parameter like the regularization penalty; here, we asked for 30 different possible values.</p>
<p>Now it is time to tune! Let’s use <code>tune_grid()</code> to fit a model at each of the values for the regularization penalty in our regular grid.</p>
<div class="rmdpackage">
<p>
In <strong>tidymodels</strong>, the package for tuning is called <strong>tune</strong>. Tuning a model uses a similar syntax compared to fitting a model to a set of resampled data sets for the purposes of evaluation (<code>fit_resamples()</code>) because the two tasks are so similar. The difference is that when you tune, each model that you fit has <em>different</em> parameters and you want to find the best one.
</p>
</div>
<p>We add our tunable model specification <code>tune_spec</code> to a workflow with the same preprocessing recipe we’ve been using so far, and then fit it to every possible parameter in <code>lambda_grid</code> and every resample in <code>complaints_folds</code> with <code>tune_grid()</code>.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="mlclassification.html#cb303-1" aria-hidden="true" tabindex="-1"></a>tune_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb303-2"><a href="mlclassification.html#cb303-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(complaints_rec) <span class="sc">%&gt;%</span></span>
<span id="cb303-3"><a href="mlclassification.html#cb303-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(tune_spec)</span>
<span id="cb303-4"><a href="mlclassification.html#cb303-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb303-5"><a href="mlclassification.html#cb303-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb303-6"><a href="mlclassification.html#cb303-6" aria-hidden="true" tabindex="-1"></a>tune_rs <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb303-7"><a href="mlclassification.html#cb303-7" aria-hidden="true" tabindex="-1"></a>  tune_wf,</span>
<span id="cb303-8"><a href="mlclassification.html#cb303-8" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb303-9"><a href="mlclassification.html#cb303-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> lambda_grid,</span>
<span id="cb303-10"><a href="mlclassification.html#cb303-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">control_resamples</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>)</span>
<span id="cb303-11"><a href="mlclassification.html#cb303-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb303-12"><a href="mlclassification.html#cb303-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb303-13"><a href="mlclassification.html#cb303-13" aria-hidden="true" tabindex="-1"></a>tune_rs</span></code></pre></div>
<pre><code>#&gt; # Tuning results
#&gt; # 10-fold cross-validation 
#&gt; # A tibble: 10 × 5
#&gt;    splits               id     .metrics          .notes           .predictions
#&gt;    &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      
#&gt;  1 &lt;split [79119/8791]&gt; Fold01 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  2 &lt;split [79119/8791]&gt; Fold02 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  3 &lt;split [79119/8791]&gt; Fold03 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  4 &lt;split [79119/8791]&gt; Fold04 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  5 &lt;split [79119/8791]&gt; Fold05 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  6 &lt;split [79119/8791]&gt; Fold06 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  7 &lt;split [79119/8791]&gt; Fold07 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  8 &lt;split [79119/8791]&gt; Fold08 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  9 &lt;split [79119/8791]&gt; Fold09 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt; 10 &lt;split [79119/8791]&gt; Fold10 &lt;tibble [60 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;</code></pre>
<div class="rmdwarning">
<p>
Like when we used <code>fit_resamples()</code>, tuning in tidymodels can use multiple cores or multiple machines via parallel processing, because the resampled data sets and possible parameters are independent of each other. A discussion of parallel processing for all possible operating systems is beyond the scope of this book, but it is well worth your time to learn how to parallelize your machine learning tasks on <em>your</em> system.
</p>
</div>
<p></p>
<p>Now, instead of one set of metrics, we have a set of metrics for each value of the regularization penalty.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="mlclassification.html#cb305-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(tune_rs)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 60 × 7
#&gt;     penalty .metric  .estimator  mean     n  std_err .config              
#&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                
#&gt;  1 1   e-10 accuracy binary     0.890    10 0.000834 Preprocessor1_Model01
#&gt;  2 1   e-10 roc_auc  binary     0.953    10 0.000517 Preprocessor1_Model01
#&gt;  3 2.21e-10 accuracy binary     0.890    10 0.000834 Preprocessor1_Model02
#&gt;  4 2.21e-10 roc_auc  binary     0.953    10 0.000517 Preprocessor1_Model02
#&gt;  5 4.89e-10 accuracy binary     0.890    10 0.000834 Preprocessor1_Model03
#&gt;  6 4.89e-10 roc_auc  binary     0.953    10 0.000517 Preprocessor1_Model03
#&gt;  7 1.08e- 9 accuracy binary     0.890    10 0.000834 Preprocessor1_Model04
#&gt;  8 1.08e- 9 roc_auc  binary     0.953    10 0.000517 Preprocessor1_Model04
#&gt;  9 2.40e- 9 accuracy binary     0.890    10 0.000834 Preprocessor1_Model05
#&gt; 10 2.40e- 9 roc_auc  binary     0.953    10 0.000517 Preprocessor1_Model05
#&gt; # … with 50 more rows</code></pre>
<p>Let’s visualize these metrics, accuracy and ROC AUC, in Figure <a href="mlclassification.html#fig:complaintstunevis">7.5</a> to see what the best model is.</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="mlclassification.html#cb307-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tune_rs) <span class="sc">+</span></span>
<span id="cb307-2"><a href="mlclassification.html#cb307-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb307-3"><a href="mlclassification.html#cb307-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Lasso model performance across regularization penalties&quot;</span>,</span>
<span id="cb307-4"><a href="mlclassification.html#cb307-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Performance metrics can be used to identity the best penalty&quot;</span></span>
<span id="cb307-5"><a href="mlclassification.html#cb307-5" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:complaintstunevis"></span>
<img src="07_ml_classification_files/figure-html/complaintstunevis-1.svg" alt="We can identify the best regularization penalty from model performance metrics, for example, at the highest ROC AUC. Note the logarithmic scale for the regularization penalty." width="672" />
<p class="caption">
FIGURE 7.5: We can identify the best regularization penalty from model performance metrics, for example, at the highest ROC AUC. Note the logarithmic scale for the regularization penalty.
</p>
</div>
<p>We can view the best results with <code>show_best()</code> and a choice for the metric, such as ROC AUC.</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="mlclassification.html#cb308-1" aria-hidden="true" tabindex="-1"></a>tune_rs <span class="sc">%&gt;%</span></span>
<span id="cb308-2"><a href="mlclassification.html#cb308-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">show_best</span>(<span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 5 × 7
#&gt;        penalty .metric .estimator  mean     n  std_err .config              
#&gt;          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                
#&gt; 1 0.000788     roc_auc binary     0.953    10 0.000502 Preprocessor1_Model21
#&gt; 2 0.000356     roc_auc binary     0.953    10 0.000504 Preprocessor1_Model20
#&gt; 3 0.000161     roc_auc binary     0.953    10 0.000511 Preprocessor1_Model19
#&gt; 4 0.0000728    roc_auc binary     0.953    10 0.000516 Preprocessor1_Model18
#&gt; 5 0.0000000001 roc_auc binary     0.953    10 0.000517 Preprocessor1_Model01</code></pre>
<p>The best value for ROC AUC from this tuning run is 0.953. We can extract the best regularization parameter for this value of ROC AUC from our tuning results with <code>select_best()</code>, or a simpler model with higher regularization with <code>select_by_pct_loss()</code> or <code>select_by_one_std_err()</code> Let’s choose the model with the best ROC AUC within one standard error of the numerically best model <span class="citation">(<a href="#ref-Breiman1984" role="doc-biblioref">Breiman et al. 1984</a>)</span>.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="mlclassification.html#cb310-1" aria-hidden="true" tabindex="-1"></a>chosen_auc <span class="ot">&lt;-</span> tune_rs <span class="sc">%&gt;%</span></span>
<span id="cb310-2"><a href="mlclassification.html#cb310-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_by_one_std_err</span>(<span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>, <span class="sc">-</span>penalty)</span>
<span id="cb310-3"><a href="mlclassification.html#cb310-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-4"><a href="mlclassification.html#cb310-4" aria-hidden="true" tabindex="-1"></a>chosen_auc</span></code></pre></div>
<pre><code>#&gt; # A tibble: 1 × 9
#&gt;    penalty .metric .estimator  mean     n  std_err .config          .best .bound
#&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 0.000788 roc_auc binary     0.953    10 0.000502 Preprocessor1_M… 0.953  0.953</code></pre>
<p>Next, let’s finalize our tunable workflow with this particular regularization penalty. This is the regularization penalty that our tuning results indicate give us the best model.</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="mlclassification.html#cb312-1" aria-hidden="true" tabindex="-1"></a>final_lasso <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(tune_wf, chosen_auc)</span>
<span id="cb312-2"><a href="mlclassification.html#cb312-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb312-3"><a href="mlclassification.html#cb312-3" aria-hidden="true" tabindex="-1"></a>final_lasso</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: logistic_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 3 Recipe Steps
#&gt; 
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = 0.000788046281566992
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>Instead of <code>penalty = tune()</code> like before, now our workflow has finalized values for all arguments. The preprocessing recipe has been evaluated on the training data, and we tuned the regularization penalty so that we have a penalty value of 0.00079. This workflow is ready to go! It can now be fit to our training data.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="mlclassification.html#cb314-1" aria-hidden="true" tabindex="-1"></a>fitted_lasso <span class="ot">&lt;-</span> <span class="fu">fit</span>(final_lasso, complaints_train)</span></code></pre></div>
<p>What does the result look like? We can access the fit using <code>extract_fit_parsnip()</code>, and even <code>tidy()</code> the model coefficient results into a convenient dataframe format.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="mlclassification.html#cb315-1" aria-hidden="true" tabindex="-1"></a>fitted_lasso <span class="sc">%&gt;%</span></span>
<span id="cb315-2"><a href="mlclassification.html#cb315-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb315-3"><a href="mlclassification.html#cb315-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb315-4"><a href="mlclassification.html#cb315-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="sc">-</span>estimate)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 1,001 × 3
#&gt;    term                                         estimate  penalty
#&gt;    &lt;chr&gt;                                           &lt;dbl&gt;    &lt;dbl&gt;
#&gt;  1 tfidf_consumer_complaint_narrative_funds         27.6 0.000788
#&gt;  2 tfidf_consumer_complaint_narrative_appraisal     22.9 0.000788
#&gt;  3 tfidf_consumer_complaint_narrative_escrow        21.0 0.000788
#&gt;  4 tfidf_consumer_complaint_narrative_bonus         20.7 0.000788
#&gt;  5 tfidf_consumer_complaint_narrative_debt          18.5 0.000788
#&gt;  6 tfidf_consumer_complaint_narrative_emailed       16.4 0.000788
#&gt;  7 tfidf_consumer_complaint_narrative_money         16.1 0.000788
#&gt;  8 tfidf_consumer_complaint_narrative_interest      15.7 0.000788
#&gt;  9 tfidf_consumer_complaint_narrative_afford        15.5 0.000788
#&gt; 10 tfidf_consumer_complaint_narrative_merchant      14.9 0.000788
#&gt; # … with 991 more rows</code></pre>
<p>We see here, for the penalty we chose, what terms contribute the most to a complaint <em>not</em> being about credit. The words are largely about mortgages and other financial products.</p>
<p>What terms contribute to a complaint being about credit reporting, for this tuned model? Here we see the names of the credit reporting agencies and words about credit inquiries.</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="mlclassification.html#cb317-1" aria-hidden="true" tabindex="-1"></a>fitted_lasso <span class="sc">%&gt;%</span></span>
<span id="cb317-2"><a href="mlclassification.html#cb317-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb317-3"><a href="mlclassification.html#cb317-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb317-4"><a href="mlclassification.html#cb317-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(estimate)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 1,001 × 3
#&gt;    term                                          estimate  penalty
#&gt;    &lt;chr&gt;                                            &lt;dbl&gt;    &lt;dbl&gt;
#&gt;  1 tfidf_consumer_complaint_narrative_reseller      -90.9 0.000788
#&gt;  2 tfidf_consumer_complaint_narrative_experian      -56.9 0.000788
#&gt;  3 tfidf_consumer_complaint_narrative_transunion    -50.1 0.000788
#&gt;  4 tfidf_consumer_complaint_narrative_equifax       -48.1 0.000788
#&gt;  5 tfidf_consumer_complaint_narrative_compliant     -23.7 0.000788
#&gt;  6 tfidf_consumer_complaint_narrative_reporting     -21.1 0.000788
#&gt;  7 tfidf_consumer_complaint_narrative_freeze        -20.9 0.000788
#&gt;  8 tfidf_consumer_complaint_narrative_inquiries     -19.0 0.000788
#&gt;  9 tfidf_consumer_complaint_narrative_report        -18.6 0.000788
#&gt; 10 tfidf_consumer_complaint_narrative_method        -16.3 0.000788
#&gt; # … with 991 more rows</code></pre>
<div class="rmdnote">
<p>
Since we are using a linear model, the model coefficients are directly interpretable and transparently give us variable importance. Many models useful for machine learning with text do <em>not</em> have such transparent variable importance; in those situations, you can use other model-independent or model-agnostic approaches like <a href="https://juliasilge.com/blog/last-airbender/">permutation variable importance</a>.
</p>
</div>
</div>
<div id="casestudysparseencoding" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Case study: sparse encoding<a href="mlclassification.html#casestudysparseencoding" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can change how our text data is represented to take advantage of its sparsity, especially for models like lasso regularized models. The regularized regression model we have been training in previous sections used <code>set_engine("glmnet")</code>; this computational engine can be more efficient when text data is transformed to a sparse matrix (Section <a href="embeddings.html#motivatingsparse">5.1</a>), rather than a dense dataframe or tibble representation.</p>
<p>To keep our text data sparse throughout modeling and use the sparse capabilities of <code>set_engine("glmnet")</code>, we need to explicitly set a non-default preprocessing blueprint, using the package <strong>hardhat</strong> <span class="citation">(<a href="#ref-R-hardhat" role="doc-biblioref">Vaughan and Kuhn 2020</a>)</span>.</p>
<div class="rmdpackage">
<p>
The <strong>hardhat</strong> package is used by other tidymodels packages like recipes and parsnip under the hood. As a tidymodels user, you typically don’t use hardhat functions directly. The exception is when you need to customize something about your model or preprocessing, like in this sparse data example.
</p>
</div>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="mlclassification.html#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hardhat)</span>
<span id="cb319-2"><a href="mlclassification.html#cb319-2" aria-hidden="true" tabindex="-1"></a>sparse_bp <span class="ot">&lt;-</span> <span class="fu">default_recipe_blueprint</span>(<span class="at">composition =</span> <span class="st">&quot;dgCMatrix&quot;</span>)</span></code></pre></div>
<p>This “blueprint” lets us specify during modeling how we want our data passed around from the preprocessing into the model. The composition <code>"dgCMatrix"</code> is the most common sparse matrix type, from the Matrix package <span class="citation">(<a href="#ref-R-Matrix" role="doc-biblioref">Bates and Maechler 2021</a>)</span>, used in R for modeling. We can use this <code>blueprint</code> argument when we add our recipe to our modeling workflow, to define how the data should be passed into the model.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="mlclassification.html#cb320-1" aria-hidden="true" tabindex="-1"></a>sparse_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb320-2"><a href="mlclassification.html#cb320-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(complaints_rec, <span class="at">blueprint =</span> sparse_bp) <span class="sc">%&gt;%</span></span>
<span id="cb320-3"><a href="mlclassification.html#cb320-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(tune_spec)</span>
<span id="cb320-4"><a href="mlclassification.html#cb320-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-5"><a href="mlclassification.html#cb320-5" aria-hidden="true" tabindex="-1"></a>sparse_wf</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: logistic_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 3 Recipe Steps
#&gt; 
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = tune()
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>The last time we tuned a lasso model, we used the defaults for the penalty parameter and 30 levels. Let’s restrict the values this time using the <code>range</code> argument, so we don’t test out as small values for regularization, and only try 20 levels.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="mlclassification.html#cb322-1" aria-hidden="true" tabindex="-1"></a>smaller_lambda <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">penalty</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">0</span>)), <span class="at">levels =</span> <span class="dv">20</span>)</span>
<span id="cb322-2"><a href="mlclassification.html#cb322-2" aria-hidden="true" tabindex="-1"></a>smaller_lambda</span></code></pre></div>
<pre><code>#&gt; # A tibble: 20 × 1
#&gt;      penalty
#&gt;        &lt;dbl&gt;
#&gt;  1 0.00001  
#&gt;  2 0.0000183
#&gt;  3 0.0000336
#&gt;  4 0.0000616
#&gt;  5 0.000113 
#&gt;  6 0.000207 
#&gt;  7 0.000379 
#&gt;  8 0.000695 
#&gt;  9 0.00127  
#&gt; 10 0.00234  
#&gt; 11 0.00428  
#&gt; 12 0.00785  
#&gt; 13 0.0144   
#&gt; 14 0.0264   
#&gt; 15 0.0483   
#&gt; 16 0.0886   
#&gt; 17 0.162    
#&gt; 18 0.298    
#&gt; 19 0.546    
#&gt; 20 1</code></pre>
<p>We can tune this lasso regression model, in the same way that we did in Section <a href="mlclassification.html#tunelasso">7.4</a>. We will fit and assess each possible regularization parameter on each resampling fold, to find the best amount of regularization.</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="mlclassification.html#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb324-2"><a href="mlclassification.html#cb324-2" aria-hidden="true" tabindex="-1"></a>sparse_rs <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb324-3"><a href="mlclassification.html#cb324-3" aria-hidden="true" tabindex="-1"></a>  sparse_wf,</span>
<span id="cb324-4"><a href="mlclassification.html#cb324-4" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb324-5"><a href="mlclassification.html#cb324-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> smaller_lambda</span>
<span id="cb324-6"><a href="mlclassification.html#cb324-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb324-7"><a href="mlclassification.html#cb324-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb324-8"><a href="mlclassification.html#cb324-8" aria-hidden="true" tabindex="-1"></a>sparse_rs</span></code></pre></div>
<pre><code>#&gt; # Tuning results
#&gt; # 10-fold cross-validation 
#&gt; # A tibble: 10 × 4
#&gt;    splits               id     .metrics          .notes          
#&gt;    &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
#&gt;  1 &lt;split [79119/8791]&gt; Fold01 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  2 &lt;split [79119/8791]&gt; Fold02 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  3 &lt;split [79119/8791]&gt; Fold03 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  4 &lt;split [79119/8791]&gt; Fold04 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  5 &lt;split [79119/8791]&gt; Fold05 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  6 &lt;split [79119/8791]&gt; Fold06 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  7 &lt;split [79119/8791]&gt; Fold07 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  8 &lt;split [79119/8791]&gt; Fold08 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt;  9 &lt;split [79119/8791]&gt; Fold09 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;
#&gt; 10 &lt;split [79119/8791]&gt; Fold10 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt;</code></pre>
<p>How did this model turn out, especially compared to the tuned model that did not use the sparse capabilities of <code>set_engine("glmnet")</code>?</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="mlclassification.html#cb326-1" aria-hidden="true" tabindex="-1"></a>sparse_rs <span class="sc">%&gt;%</span></span>
<span id="cb326-2"><a href="mlclassification.html#cb326-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">show_best</span>(<span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 5 × 7
#&gt;    penalty .metric .estimator  mean     n  std_err .config              
#&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                
#&gt; 1 0.000695 roc_auc binary     0.953    10 0.000502 Preprocessor1_Model08
#&gt; 2 0.000379 roc_auc binary     0.953    10 0.000504 Preprocessor1_Model07
#&gt; 3 0.000207 roc_auc binary     0.953    10 0.000508 Preprocessor1_Model06
#&gt; 4 0.00127  roc_auc binary     0.953    10 0.000501 Preprocessor1_Model09
#&gt; 5 0.000113 roc_auc binary     0.953    10 0.000514 Preprocessor1_Model05</code></pre>
<p>The best ROC AUC is nearly identical; the best ROC AUC for the non-sparse tuned lasso model in Section <a href="mlclassification.html#tunelasso">7.4</a> was 0.953. The best regularization parameter (<code>penalty</code>) is a little different (the best value in Section <a href="mlclassification.html#tunelasso">7.4</a> was 0.00079), but we used a different grid so didn’t try out exactly the same values. We ended up with nearly the same performance and best tuned model.</p>
<p>Importantly, this tuning also took a bit less time to complete.</p>
<ul>
<li><p>The <em>preprocessing</em> was not much faster, because tokenization and computing tf-idf take a long time.</p></li>
<li><p>The <em>model fitting</em> was much faster, because for highly sparse data, this implementation of regularized regression is much faster for sparse matrix input than any dense input.</p></li>
</ul>
<p>Overall, the whole tuning workflow is about 10% faster using the sparse preprocessing blueprint. Depending on how computationally expensive your preprocessing is relative to your model and how sparse your data is, you may expect to see larger (or smaller) gains from moving to a sparse data representation.</p>
<div class="rmdnote">
<p>
Since our model performance is about the same and we see gains in training time, let’s use this sparse representation for the rest of this chapter.
</p>
</div>
</div>
<div id="mlmulticlass" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> Two-class or multiclass?<a href="mlclassification.html#mlmulticlass" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Most of this chapter focuses on binary classification, where we have two classes in our outcome variable (such as “Credit” and “Other”) and each observation can either be one or the other. This is a simple scenario with straightforward evaluation strategies because the results only have a two-by-two contingency matrix.
However, it is not always possible to limit a modeling question to two classes. Let’s explore how to deal with situations where we have more than two classes.
The CFPB complaints data set in this chapter has nine different <code>product</code> classes. In decreasing frequency, they are:</p>
<ul>
<li><p>Credit reporting, credit repair services, or other personal consumer reports</p></li>
<li><p>Debt collection</p></li>
<li><p>Credit card or prepaid card</p></li>
<li><p>Mortgage</p></li>
<li><p>Checking or savings account</p></li>
<li><p>Student loan</p></li>
<li><p>Vehicle loan or lease</p></li>
<li><p>Money transfer, virtual currency, or money service</p></li>
<li><p>Payday loan, title loan, or personal loan</p></li>
</ul>
<p>We assume that there is a reason why these product classes have been created in this fashion by this government agency.
Perhaps complaints from different classes are handled by different people or organizations.
Whatever the reason, in this section we would like to build a multiclass classifier to identify these nine specific product classes.</p>
<p>We need to create a new split of the data using <code>initial_split()</code> on the unmodified <code>complaints</code> data set.</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="mlclassification.html#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb328-2"><a href="mlclassification.html#cb328-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-3"><a href="mlclassification.html#cb328-3" aria-hidden="true" tabindex="-1"></a>multicomplaints_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(complaints, <span class="at">strata =</span> product)</span>
<span id="cb328-4"><a href="mlclassification.html#cb328-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-5"><a href="mlclassification.html#cb328-5" aria-hidden="true" tabindex="-1"></a>multicomplaints_train <span class="ot">&lt;-</span> <span class="fu">training</span>(multicomplaints_split)</span>
<span id="cb328-6"><a href="mlclassification.html#cb328-6" aria-hidden="true" tabindex="-1"></a>multicomplaints_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(multicomplaints_split)</span></code></pre></div>
<p>Before we continue, let us take a look at the number of cases in each of the classes.</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="mlclassification.html#cb329-1" aria-hidden="true" tabindex="-1"></a>multicomplaints_train <span class="sc">%&gt;%</span></span>
<span id="cb329-2"><a href="mlclassification.html#cb329-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(product, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb329-3"><a href="mlclassification.html#cb329-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(n, product)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 9 × 2
#&gt;       n product                                                                 
#&gt;   &lt;int&gt; &lt;chr&gt;                                                                   
#&gt; 1 41678 Credit reporting, credit repair services, or other personal consumer re…
#&gt; 2 16688 Debt collection                                                         
#&gt; 3  8689 Credit card or prepaid card                                             
#&gt; 4  7117 Mortgage                                                                
#&gt; 5  5219 Checking or savings account                                             
#&gt; 6  2927 Student loan                                                            
#&gt; 7  2030 Vehicle loan or lease                                                   
#&gt; 8  1906 Money transfer, virtual currency, or money service                      
#&gt; 9  1656 Payday loan, title loan, or personal loan</code></pre>
<p>There is significant imbalance between the classes that we must address, with over 20 times more cases of the majority class than there is of the smallest class.
This kind of imbalance is a common problem with multiclass classification, with few multiclass data sets in the real world exhibiting balance between classes.</p>
<p>Compared to binary classification, there are several additional issues to keep in mind when working with multiclass classification:</p>
<ul>
<li><p>Many machine learning algorithms do not handle imbalanced data well and are likely to have a hard time predicting minority classes.</p></li>
<li><p>Not all machine learning algorithms are built for multiclass classification at all.</p></li>
<li><p>Many evaluation metrics need to be reformulated to describe multiclass predictions.</p></li>
</ul>
<p>When you have multiple classes in your data, it is possible to formulate the multiclass problem in two ways. With one approach, any given observation can belong to multiple classes. With the other approach, an observation can belong to one and only one class. We will be sticking to the second, “one class per observation” model formulation in this section.</p>
<p>There are many different ways to deal with imbalanced data.
We will demonstrate one of the simplest methods, downsampling, where observations from the majority classes are removed during training to achieve a balanced class distribution.
We will be using the <strong>themis</strong> <span class="citation">(<a href="#ref-R-themis" role="doc-biblioref">Hvitfeldt 2020d</a>)</span> add-on package for recipes which provides the <code>step_downsample()</code> function to perform downsampling.</p>
<div class="rmdpackage">
<p>
The <strong>themis</strong> package provides many more algorithms to deal with imbalanced data during data preprocessing.
</p>
</div>
<p>We have to create a new recipe specification from scratch, since we are dealing with new training data this time.
The specification <code>multicomplaints_rec</code> is similar to what we created in Section <a href="mlclassification.html#classfirstattemptlookatdata">7.1</a>. The only changes are that different data is passed to the <code>data</code> argument in the <code>recipe()</code> function (it is now <code>multicomplaints_train</code>) and we have added <code>step_downsample(product)</code> to the end of the recipe specification to downsample after all the text preprocessing. We want to downsample last so that we still generate features on the full training data set. The downsampling will then <em>only</em> affect the modeling step, not the preprocessing steps, with hopefully better results.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="mlclassification.html#cb331-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(themis)</span>
<span id="cb331-2"><a href="mlclassification.html#cb331-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb331-3"><a href="mlclassification.html#cb331-3" aria-hidden="true" tabindex="-1"></a>multicomplaints_rec <span class="ot">&lt;-</span></span>
<span id="cb331-4"><a href="mlclassification.html#cb331-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(product <span class="sc">~</span> consumer_complaint_narrative,</span>
<span id="cb331-5"><a href="mlclassification.html#cb331-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> multicomplaints_train) <span class="sc">%&gt;%</span></span>
<span id="cb331-6"><a href="mlclassification.html#cb331-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenize</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb331-7"><a href="mlclassification.html#cb331-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenfilter</span>(consumer_complaint_narrative, <span class="at">max_tokens =</span> <span class="fl">1e3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb331-8"><a href="mlclassification.html#cb331-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tfidf</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb331-9"><a href="mlclassification.html#cb331-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_downsample</span>(product)</span></code></pre></div>
<p>We also need a new cross-validation object since we are using a different data set.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="mlclassification.html#cb332-1" aria-hidden="true" tabindex="-1"></a>multicomplaints_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(multicomplaints_train)</span></code></pre></div>
<p>We cannot reuse the tuneable lasso classification specification from Section <a href="mlclassification.html#tunelasso">7.4</a> because it only works for binary classification. Some model algorithms and computational engines (examples are most random forests and SVMs) automatically detect when we perform multiclass classification from the number of classes in the outcome variable and do not require any changes to our model specification. For lasso regularization, we need to create a new special model specification just for the multiclass class using <code>multinom_reg()</code>.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="mlclassification.html#cb333-1" aria-hidden="true" tabindex="-1"></a>multi_spec <span class="ot">&lt;-</span> <span class="fu">multinom_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb333-2"><a href="mlclassification.html#cb333-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb333-3"><a href="mlclassification.html#cb333-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>)</span>
<span id="cb333-4"><a href="mlclassification.html#cb333-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-5"><a href="mlclassification.html#cb333-5" aria-hidden="true" tabindex="-1"></a>multi_spec</span></code></pre></div>
<pre><code>#&gt; Multinomial Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = tune()
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>We used the same arguments for <code>penalty</code> and <code>mixture</code> as in Section <a href="mlclassification.html#tunelasso">7.4</a>, as well as the same mode and engine, but this model specification is set up to handle more than just two classes. We can combine this model specification with our preprocessing recipe for multiclass data in a <code>workflow()</code>.</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="mlclassification.html#cb335-1" aria-hidden="true" tabindex="-1"></a>multi_lasso_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb335-2"><a href="mlclassification.html#cb335-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(multicomplaints_rec, <span class="at">blueprint =</span> sparse_bp) <span class="sc">%&gt;%</span></span>
<span id="cb335-3"><a href="mlclassification.html#cb335-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(multi_spec)</span>
<span id="cb335-4"><a href="mlclassification.html#cb335-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb335-5"><a href="mlclassification.html#cb335-5" aria-hidden="true" tabindex="-1"></a>multi_lasso_wf</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: multinom_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 4 Recipe Steps
#&gt; 
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; • step_downsample()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Multinomial Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = tune()
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>Now we have everything we need to tune the regularization penalty and find an appropriate value. Note that we specify <code>save_pred = TRUE</code>, so we can create ROC curves and a confusion matrix later. This is especially beneficial for multiclass classification.</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="mlclassification.html#cb337-1" aria-hidden="true" tabindex="-1"></a>multi_lasso_rs <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb337-2"><a href="mlclassification.html#cb337-2" aria-hidden="true" tabindex="-1"></a>  multi_lasso_wf,</span>
<span id="cb337-3"><a href="mlclassification.html#cb337-3" aria-hidden="true" tabindex="-1"></a>  multicomplaints_folds,</span>
<span id="cb337-4"><a href="mlclassification.html#cb337-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> smaller_lambda,</span>
<span id="cb337-5"><a href="mlclassification.html#cb337-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">control_resamples</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>)</span>
<span id="cb337-6"><a href="mlclassification.html#cb337-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb337-7"><a href="mlclassification.html#cb337-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-8"><a href="mlclassification.html#cb337-8" aria-hidden="true" tabindex="-1"></a>multi_lasso_rs</span></code></pre></div>
<pre><code>#&gt; # Tuning results
#&gt; # 10-fold cross-validation 
#&gt; # A tibble: 10 × 5
#&gt;    splits               id     .metrics          .notes           .predictions
#&gt;    &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      
#&gt;  1 &lt;split [79119/8791]&gt; Fold01 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  2 &lt;split [79119/8791]&gt; Fold02 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  3 &lt;split [79119/8791]&gt; Fold03 &lt;tibble [40 × 5]&gt; &lt;tibble [1 × 3]&gt; &lt;tibble&gt;    
#&gt;  4 &lt;split [79119/8791]&gt; Fold04 &lt;tibble [40 × 5]&gt; &lt;tibble [1 × 3]&gt; &lt;tibble&gt;    
#&gt;  5 &lt;split [79119/8791]&gt; Fold05 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  6 &lt;split [79119/8791]&gt; Fold06 &lt;tibble [40 × 5]&gt; &lt;tibble [1 × 3]&gt; &lt;tibble&gt;    
#&gt;  7 &lt;split [79119/8791]&gt; Fold07 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  8 &lt;split [79119/8791]&gt; Fold08 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt;  9 &lt;split [79119/8791]&gt; Fold09 &lt;tibble [40 × 5]&gt; &lt;tibble [1 × 3]&gt; &lt;tibble&gt;    
#&gt; 10 &lt;split [79119/8791]&gt; Fold10 &lt;tibble [40 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
#&gt; 
#&gt; There were issues with some computations:
#&gt; 
#&gt;   - Warning(s) x1: from glmnet C++ code (error code -100); Convergence for 100th lam...   - Warning(s) x1: from glmnet C++ code (error code -100); Convergence for 100th lam...   - Warning(s) x1: from glmnet C++ code (error code -100); Convergence for 100th lam...   - Warning(s) x1: from glmnet C++ code (error code -100); Convergence for 100th lam...
#&gt; 
#&gt; Use `collect_notes(object)` for more information.</code></pre>
<p>What do we see, in terms of performance metrics?</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="mlclassification.html#cb339-1" aria-hidden="true" tabindex="-1"></a>best_acc <span class="ot">&lt;-</span> multi_lasso_rs <span class="sc">%&gt;%</span></span>
<span id="cb339-2"><a href="mlclassification.html#cb339-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">show_best</span>(<span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb339-3"><a href="mlclassification.html#cb339-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-4"><a href="mlclassification.html#cb339-4" aria-hidden="true" tabindex="-1"></a>best_acc</span></code></pre></div>
<pre><code>#&gt; # A tibble: 5 × 7
#&gt;    penalty .metric  .estimator  mean     n  std_err .config              
#&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                
#&gt; 1 0.00234  accuracy multiclass 0.756    10 0.00166  Preprocessor1_Model10
#&gt; 2 0.00428  accuracy multiclass 0.751    10 0.00148  Preprocessor1_Model11
#&gt; 3 0.00127  accuracy multiclass 0.750    10 0.000920 Preprocessor1_Model09
#&gt; 4 0.00785  accuracy multiclass 0.741    10 0.00207  Preprocessor1_Model12
#&gt; 5 0.000695 accuracy multiclass 0.741    10 0.00239  Preprocessor1_Model08</code></pre>
<p>The accuracy metric naturally extends to multiclass tasks, but even the very best value is quite low at 75.6%, significantly lower than for the binary case in Section <a href="mlclassification.html#tunelasso">7.4</a>. This is expected since multiclass classification is a harder task than binary classification.</p>
<div class="rmdwarning">
<p>
In binary classification, there is one right answer and one wrong answer; in this multiclass case, there is one right answer and <em>eight</em> wrong answers.
</p>
</div>
<p>To get a more detailed view of how our classifier is performing, let us look at one of the confusion matrices in Figure <a href="mlclassification.html#fig:multiheatmap">7.6</a>.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="mlclassification.html#cb341-1" aria-hidden="true" tabindex="-1"></a>multi_lasso_rs <span class="sc">%&gt;%</span></span>
<span id="cb341-2"><a href="mlclassification.html#cb341-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_predictions</span>() <span class="sc">%&gt;%</span></span>
<span id="cb341-3"><a href="mlclassification.html#cb341-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(penalty <span class="sc">==</span> best_acc<span class="sc">$</span>penalty) <span class="sc">%&gt;%</span></span>
<span id="cb341-4"><a href="mlclassification.html#cb341-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(id <span class="sc">==</span> <span class="st">&quot;Fold01&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb341-5"><a href="mlclassification.html#cb341-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(product, .pred_class) <span class="sc">%&gt;%</span></span>
<span id="cb341-6"><a href="mlclassification.html#cb341-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>) <span class="sc">+</span></span>
<span id="cb341-7"><a href="mlclassification.html#cb341-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_discrete</span>(<span class="at">labels =</span> <span class="cf">function</span>(x) <span class="fu">str_wrap</span>(x, <span class="dv">20</span>)) <span class="sc">+</span></span>
<span id="cb341-8"><a href="mlclassification.html#cb341-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_discrete</span>(<span class="at">labels =</span> <span class="cf">function</span>(x) <span class="fu">str_wrap</span>(x, <span class="dv">20</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multiheatmap"></span>
<img src="07_ml_classification_files/figure-html/multiheatmap-1.svg" alt="Confusion matrix for multiclass lasso regularized classifier, with most of the classifications along the diagonal" width="960" />
<p class="caption">
FIGURE 7.6: Confusion matrix for multiclass lasso regularized classifier, with most of the classifications along the diagonal
</p>
</div>
<p>The diagonal is fairly well populated, which is a good sign. This means that the model generally predicted the right class.
The off-diagonal numbers are all the failures and where we should direct our focus.
It is a little hard to see these cases well since the majority class affects the scale.
A trick to deal with this problem is to remove all the correctly predicted observations.</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="mlclassification.html#cb342-1" aria-hidden="true" tabindex="-1"></a>multi_lasso_rs <span class="sc">%&gt;%</span></span>
<span id="cb342-2"><a href="mlclassification.html#cb342-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_predictions</span>() <span class="sc">%&gt;%</span></span>
<span id="cb342-3"><a href="mlclassification.html#cb342-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(penalty <span class="sc">==</span> best_acc<span class="sc">$</span>penalty) <span class="sc">%&gt;%</span></span>
<span id="cb342-4"><a href="mlclassification.html#cb342-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(id <span class="sc">==</span> <span class="st">&quot;Fold01&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb342-5"><a href="mlclassification.html#cb342-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.pred_class <span class="sc">!=</span> product) <span class="sc">%&gt;%</span></span>
<span id="cb342-6"><a href="mlclassification.html#cb342-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(product, .pred_class) <span class="sc">%&gt;%</span></span>
<span id="cb342-7"><a href="mlclassification.html#cb342-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>) <span class="sc">+</span></span>
<span id="cb342-8"><a href="mlclassification.html#cb342-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_discrete</span>(<span class="at">labels =</span> <span class="cf">function</span>(x) <span class="fu">str_wrap</span>(x, <span class="dv">20</span>)) <span class="sc">+</span></span>
<span id="cb342-9"><a href="mlclassification.html#cb342-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_discrete</span>(<span class="at">labels =</span> <span class="cf">function</span>(x) <span class="fu">str_wrap</span>(x, <span class="dv">20</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multiheatmapminusdiag"></span>
<img src="07_ml_classification_files/figure-html/multiheatmapminusdiag-1.svg" alt="Confusion matrix for multiclass lasso regularized classifier without diagonal" width="960" />
<p class="caption">
FIGURE 7.7: Confusion matrix for multiclass lasso regularized classifier without diagonal
</p>
</div>
<p>Now we can more clearly see where our model breaks down in Figure <a href="mlclassification.html#fig:multiheatmapminusdiag">7.7</a>. Some of the most common errors are “Credit reporting, credit repair services, or other personal consumer reports” complaints being wrongly being predicted as “Debt collection” or “Credit card of prepaid card” complaints. Those mistakes by the model are not hard to understand since all deal with credit and debt and do have overlap in vocabulary.
Knowing what the problem is helps us figure out how to improve our model.
The next step for improving our model is to revisit the data preprocessing steps and model selection.
We can look at different models or model engines that might be able to more easily separate the classes.</p>
<p>Now that we have an idea of where the model isn’t working, we can look more closely at the data and attempt to create features that could distinguish between these classes. In Section <a href="mlclassification.html#customfeatures">7.9</a> we will demonstrate how you can create your own custom features.</p>
</div>
<div id="case-study-including-non-text-data" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> Case study: including non-text data<a href="mlclassification.html#case-study-including-non-text-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We are building a model from a data set that includes more than text data alone. Annotations and labels have been added by the CFPB that we can use during modeling, but we need to ensure that only information that would be available at the time of prediction is included in the model.
Otherwise we will be very disappointed once our model is used to predict on new data!
The variables we identify as available for use as predictors are:</p>
<ul>
<li><p><code>date_received</code></p></li>
<li><p><code>issue</code></p></li>
<li><p><code>sub_issue</code></p></li>
<li><p><code>consumer_complaint_narrative</code></p></li>
<li><p><code>company</code></p></li>
<li><p><code>state</code></p></li>
<li><p><code>zip_code</code></p></li>
<li><p><code>tags</code></p></li>
<li><p><code>submitted_via</code></p></li>
</ul>
<p>Let’s try including <code>date_received</code> in our modeling, along with the text variable we have already used, <code>consumer_complaint_narrative</code>, and a new variable <code>tags</code>.
The <code>submitted_via</code> variable could have been a viable candidate, but all the entries are “web.”
The other variables like ZIP code could be of use too, but they are categorical variables with many values so we will exclude them for now.</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="mlclassification.html#cb343-1" aria-hidden="true" tabindex="-1"></a>more_vars_rec <span class="ot">&lt;-</span></span>
<span id="cb343-2"><a href="mlclassification.html#cb343-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(product <span class="sc">~</span> date_received <span class="sc">+</span> tags <span class="sc">+</span> consumer_complaint_narrative,</span>
<span id="cb343-3"><a href="mlclassification.html#cb343-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> complaints_train)</span></code></pre></div>
<p>How should we preprocess the <code>date_received</code> variable? We can use the <code>step_date()</code> function to extract the month and day of the week (<code>"dow"</code>). Then we remove the original date variable and convert the new month and day-of-the-week columns to indicator variables with <code>step_dummy()</code>.</p>
<div class="rmdnote">
<p>
Categorical variables like the month can be stored as strings or factors, but for some kinds of models, they must be converted to indicator or dummy variables. These are numeric binary variables for the levels of the original categorical variable. For example, a variable called <code>December</code> would be created that is all zeroes and ones specifying which complaints were submitted in December, plus a variable called <code>November</code>, a variable called <code>October</code>, and so on.
</p>
</div>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="mlclassification.html#cb344-1" aria-hidden="true" tabindex="-1"></a>more_vars_rec <span class="ot">&lt;-</span> more_vars_rec <span class="sc">%&gt;%</span></span>
<span id="cb344-2"><a href="mlclassification.html#cb344-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_date</span>(date_received, <span class="at">features =</span> <span class="fu">c</span>(<span class="st">&quot;month&quot;</span>, <span class="st">&quot;dow&quot;</span>), <span class="at">role =</span> <span class="st">&quot;dates&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb344-3"><a href="mlclassification.html#cb344-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rm</span>(date_received) <span class="sc">%&gt;%</span></span>
<span id="cb344-4"><a href="mlclassification.html#cb344-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">has_role</span>(<span class="st">&quot;dates&quot;</span>))</span></code></pre></div>
<p>The <code>tags</code> variable has some missing data. We can deal with this by using <code>step_unknown()</code>, which adds a new level to this factor variable for cases of missing data. Then we “dummify” (create dummy/indicator variables) the variable with <code>step_dummy()</code>.</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="mlclassification.html#cb345-1" aria-hidden="true" tabindex="-1"></a>more_vars_rec <span class="ot">&lt;-</span> more_vars_rec <span class="sc">%&gt;%</span></span>
<span id="cb345-2"><a href="mlclassification.html#cb345-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_unknown</span>(tags) <span class="sc">%&gt;%</span></span>
<span id="cb345-3"><a href="mlclassification.html#cb345-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(tags)</span></code></pre></div>
<p>Now we add steps to process the text of the complaints, as before.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="mlclassification.html#cb346-1" aria-hidden="true" tabindex="-1"></a>more_vars_rec <span class="ot">&lt;-</span> more_vars_rec <span class="sc">%&gt;%</span></span>
<span id="cb346-2"><a href="mlclassification.html#cb346-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenize</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb346-3"><a href="mlclassification.html#cb346-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenfilter</span>(consumer_complaint_narrative, <span class="at">max_tokens =</span> <span class="fl">1e3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb346-4"><a href="mlclassification.html#cb346-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tfidf</span>(consumer_complaint_narrative)</span></code></pre></div>
<p>Let’s combine this more extensive preprocessing recipe that handles more variables together with the tuneable lasso regularized classification model specification.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="mlclassification.html#cb347-1" aria-hidden="true" tabindex="-1"></a>more_vars_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb347-2"><a href="mlclassification.html#cb347-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(more_vars_rec, <span class="at">blueprint =</span> sparse_bp) <span class="sc">%&gt;%</span></span>
<span id="cb347-3"><a href="mlclassification.html#cb347-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(tune_spec)</span>
<span id="cb347-4"><a href="mlclassification.html#cb347-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-5"><a href="mlclassification.html#cb347-5" aria-hidden="true" tabindex="-1"></a>more_vars_wf</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: logistic_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 8 Recipe Steps
#&gt; 
#&gt; • step_date()
#&gt; • step_rm()
#&gt; • step_dummy()
#&gt; • step_unknown()
#&gt; • step_dummy()
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = tune()
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>Let’s tune this <code>workflow()</code> with our resampled data sets, find a good value for the regularization penalty, and estimate the model’s performance.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="mlclassification.html#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb349-2"><a href="mlclassification.html#cb349-2" aria-hidden="true" tabindex="-1"></a>more_vars_rs <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb349-3"><a href="mlclassification.html#cb349-3" aria-hidden="true" tabindex="-1"></a>  more_vars_wf,</span>
<span id="cb349-4"><a href="mlclassification.html#cb349-4" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb349-5"><a href="mlclassification.html#cb349-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> smaller_lambda,</span>
<span id="cb349-6"><a href="mlclassification.html#cb349-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>We can extract the metrics for the best-performing regularization penalties from these results with <code>show_best()</code> with an option like <code>"roc_auc"</code> or <code>"accuracy"</code> if we prefer. How did our chosen performance metric turn out for our model that included more than just the text data?</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="mlclassification.html#cb350-1" aria-hidden="true" tabindex="-1"></a>more_vars_rs <span class="sc">%&gt;%</span></span>
<span id="cb350-2"><a href="mlclassification.html#cb350-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">show_best</span>(<span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 5 × 7
#&gt;    penalty .metric .estimator  mean     n  std_err .config              
#&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;                
#&gt; 1 0.000695 roc_auc binary     0.953    10 0.000509 Preprocessor1_Model08
#&gt; 2 0.000379 roc_auc binary     0.953    10 0.000510 Preprocessor1_Model07
#&gt; 3 0.000207 roc_auc binary     0.953    10 0.000515 Preprocessor1_Model06
#&gt; 4 0.00127  roc_auc binary     0.953    10 0.000507 Preprocessor1_Model09
#&gt; 5 0.000113 roc_auc binary     0.953    10 0.000520 Preprocessor1_Model05</code></pre>
<p>We see here that including more predictors did not measurably improve our model performance or even change the regularization. With only text features in Section <a href="mlclassification.html#casestudysparseencoding">7.5</a> and the same grid and sparse encoding, we achieved an accuracy of 0.953, the same as what we see now by including the features dealing with dates and tags as well. The best regularization penalty in Section <a href="mlclassification.html#casestudysparseencoding">7.5</a> was 0.0007 and is about the same here. We can use <code>tidy()</code> and some <strong>dplyr</strong> manipulation to find at what rank (<code>term_rank</code>) any of the date or tag variables were included in the regularized results, by absolute value of the model coefficient.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="mlclassification.html#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="fu">finalize_workflow</span>(more_vars_wf, </span>
<span id="cb352-2"><a href="mlclassification.html#cb352-2" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">select_best</span>(more_vars_rs, <span class="st">&quot;roc_auc&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb352-3"><a href="mlclassification.html#cb352-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(complaints_train) <span class="sc">%&gt;%</span></span>
<span id="cb352-4"><a href="mlclassification.html#cb352-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb352-5"><a href="mlclassification.html#cb352-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb352-6"><a href="mlclassification.html#cb352-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="sc">-</span><span class="fu">abs</span>(estimate)) <span class="sc">%&gt;%</span> </span>
<span id="cb352-7"><a href="mlclassification.html#cb352-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">term_rank =</span> <span class="fu">row_number</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb352-8"><a href="mlclassification.html#cb352-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">str_detect</span>(term, <span class="st">&quot;tfidf&quot;</span>))</span></code></pre></div>
<pre><code>#&gt; # A tibble: 21 × 4
#&gt;    term                    estimate  penalty term_rank
#&gt;    &lt;chr&gt;                      &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;
#&gt;  1 (Intercept)              0.326   0.000695       701
#&gt;  2 date_received_month_Dec -0.271   0.000695       716
#&gt;  3 date_received_month_Aug -0.105   0.000695       746
#&gt;  4 date_received_dow_Mon    0.102   0.000695       748
#&gt;  5 date_received_month_Apr  0.0763  0.000695       756
#&gt;  6 date_received_month_Feb -0.0547  0.000695       761
#&gt;  7 tags_Servicemember      -0.0426  0.000695       765
#&gt;  8 date_received_dow_Tue    0.0329  0.000695       766
#&gt;  9 date_received_dow_Fri    0.0147  0.000695       770
#&gt; 10 date_received_month_May  0.00337 0.000695       774
#&gt; # … with 11 more rows</code></pre>
<p>In our example here, some of the non-text predictors are included in the model with non-zero coefficients but ranked down in the 700s of all model terms, with smaller coefficients than many text terms. They are not that important.</p>
<div class="rmdnote">
<p>
This whole book focuses on supervised machine learning for text data, but models can combine <em>both</em> text predictors and other kinds of predictors.
</p>
</div>
</div>
<div id="case-study-data-censoring" class="section level2 hasAnchor" number="7.8">
<h2><span class="header-section-number">7.8</span> Case study: data censoring<a href="mlclassification.html#case-study-data-censoring" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The complaints data set already has sensitive information (PII) censored or protected using strings such as “XXXX” and “XX.”
This data censoring can be viewed as data <em>annotation</em>; specific account numbers and birthdays are protected, but we know they were there. These values would be mostly unique anyway, and likely filtered out in their original form.</p>
<p>Figure <a href="mlclassification.html#fig:censoredtrigram">7.8</a> shows the most frequent trigrams (Section <a href="tokenization.html#tokenizingngrams">2.2.3</a>) in our training data set.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="mlclassification.html#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb354-2"><a href="mlclassification.html#cb354-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-3"><a href="mlclassification.html#cb354-3" aria-hidden="true" tabindex="-1"></a>complaints_train <span class="sc">%&gt;%</span></span>
<span id="cb354-4"><a href="mlclassification.html#cb354-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb354-5"><a href="mlclassification.html#cb354-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(trigrams, </span>
<span id="cb354-6"><a href="mlclassification.html#cb354-6" aria-hidden="true" tabindex="-1"></a>                consumer_complaint_narrative, <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>,</span>
<span id="cb354-7"><a href="mlclassification.html#cb354-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">collapse =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span></span>
<span id="cb354-8"><a href="mlclassification.html#cb354-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(trigrams, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb354-9"><a href="mlclassification.html#cb354-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">censored =</span> <span class="fu">str_detect</span>(trigrams, <span class="st">&quot;xx&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb354-10"><a href="mlclassification.html#cb354-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>) <span class="sc">%&gt;%</span></span>
<span id="cb354-11"><a href="mlclassification.html#cb354-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n, <span class="fu">reorder</span>(trigrams, n), <span class="at">fill =</span> censored)) <span class="sc">+</span></span>
<span id="cb354-12"><a href="mlclassification.html#cb354-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb354-13"><a href="mlclassification.html#cb354-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;grey40&quot;</span>, <span class="st">&quot;firebrick&quot;</span>)) <span class="sc">+</span></span>
<span id="cb354-14"><a href="mlclassification.html#cb354-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Trigrams&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:censoredtrigram"></span>
<img src="07_ml_classification_files/figure-html/censoredtrigram-1.svg" alt="Many of the most frequent trigrams feature censored information" width="672" />
<p class="caption">
FIGURE 7.8: Many of the most frequent trigrams feature censored information
</p>
</div>
<p>The vast majority of trigrams in Figure <a href="mlclassification.html#fig:censoredtrigram">7.8</a> include one or more censored words.
Not only do the most used trigrams include some kind of censoring,
but the censoring itself is informative as it is not used uniformly across the product classes.
In Figure <a href="mlclassification.html#fig:trigram25">7.9</a>, we take the top-25 most frequent trigrams that include censoring,
and plot the proportions for “Credit” and “Other.”</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="mlclassification.html#cb355-1" aria-hidden="true" tabindex="-1"></a>top_censored_trigrams <span class="ot">&lt;-</span> complaints_train <span class="sc">%&gt;%</span></span>
<span id="cb355-2"><a href="mlclassification.html#cb355-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb355-3"><a href="mlclassification.html#cb355-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(trigrams, </span>
<span id="cb355-4"><a href="mlclassification.html#cb355-4" aria-hidden="true" tabindex="-1"></a>                consumer_complaint_narrative, <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>,</span>
<span id="cb355-5"><a href="mlclassification.html#cb355-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">collapse =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span></span>
<span id="cb355-6"><a href="mlclassification.html#cb355-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(trigrams, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb355-7"><a href="mlclassification.html#cb355-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(trigrams, <span class="st">&quot;xx&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb355-8"><a href="mlclassification.html#cb355-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>)</span>
<span id="cb355-9"><a href="mlclassification.html#cb355-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb355-10"><a href="mlclassification.html#cb355-10" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> complaints_train <span class="sc">%&gt;%</span></span>
<span id="cb355-11"><a href="mlclassification.html#cb355-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(trigrams, </span>
<span id="cb355-12"><a href="mlclassification.html#cb355-12" aria-hidden="true" tabindex="-1"></a>                consumer_complaint_narrative, <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>,</span>
<span id="cb355-13"><a href="mlclassification.html#cb355-13" aria-hidden="true" tabindex="-1"></a>                <span class="at">collapse =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span></span>
<span id="cb355-14"><a href="mlclassification.html#cb355-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">right_join</span>(top_censored_trigrams, <span class="at">by =</span> <span class="st">&quot;trigrams&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb355-15"><a href="mlclassification.html#cb355-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(trigrams, product, <span class="at">.drop =</span> <span class="cn">FALSE</span>)</span>
<span id="cb355-16"><a href="mlclassification.html#cb355-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb355-17"><a href="mlclassification.html#cb355-17" aria-hidden="true" tabindex="-1"></a>plot_data <span class="sc">%&gt;%</span></span>
<span id="cb355-18"><a href="mlclassification.html#cb355-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n, trigrams, <span class="at">fill =</span> product)) <span class="sc">+</span></span>
<span id="cb355-19"><a href="mlclassification.html#cb355-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="st">&quot;fill&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:trigram25"></span>
<img src="07_ml_classification_files/figure-html/trigram25-1.svg" alt="Many of the most frequent trigrams feature censored words, but there is a difference in how often they are used within each class" width="672" />
<p class="caption">
FIGURE 7.9: Many of the most frequent trigrams feature censored words, but there is a difference in how often they are used within each class
</p>
</div>
<p>There is a difference in these proportions across classes. Tokens like “on xx xx” are used when referencing a date, e.g., “we had a problem on 06/25/2018.”
Remember that the current tokenization engine strips punctuation before tokenizing.
This means that the above example will be turned into “we had a problem on 06 25 2018” before creating n-grams<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.</p>
<p>To crudely simulate what the data might look like before it was censored, we can replace all cases of “XX” and “XXXX” with random integers.
This isn’t quite right since dates will be given values between <code>00</code> and <code>99</code>, and we don’t know for sure that only numerals have been censored, but it gives us a place to start.
Below is a simple function <code>uncensor_vec()</code> that locates all instances of <code>"XX"</code> and replaces them with a number between 11 and 99.
We don’t need to handle the special case of <code>XXXX</code> as it automatically being handled.</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="mlclassification.html#cb356-1" aria-hidden="true" tabindex="-1"></a>uncensor <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb356-2"><a href="mlclassification.html#cb356-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.character</span>(<span class="fu">sample</span>(<span class="fu">seq</span>(<span class="dv">10</span> <span class="sc">^</span> (n <span class="sc">-</span> <span class="dv">1</span>), <span class="dv">10</span> <span class="sc">^</span> n <span class="sc">-</span> <span class="dv">1</span>), <span class="dv">1</span>))</span>
<span id="cb356-3"><a href="mlclassification.html#cb356-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb356-4"><a href="mlclassification.html#cb356-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb356-5"><a href="mlclassification.html#cb356-5" aria-hidden="true" tabindex="-1"></a>uncensor_vec <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb356-6"><a href="mlclassification.html#cb356-6" aria-hidden="true" tabindex="-1"></a>  locs <span class="ot">&lt;-</span> <span class="fu">str_locate_all</span>(x, <span class="st">&quot;XX&quot;</span>)</span>
<span id="cb356-7"><a href="mlclassification.html#cb356-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map2_chr</span>(x, locs, <span class="sc">~</span> {</span>
<span id="cb356-8"><a href="mlclassification.html#cb356-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(.y))) {</span>
<span id="cb356-9"><a href="mlclassification.html#cb356-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">str_sub</span>(.x, .y[i, <span class="dv">1</span>], .y[i, <span class="dv">2</span>]) <span class="ot">&lt;-</span> <span class="fu">uncensor</span>(<span class="dv">2</span>)</span>
<span id="cb356-10"><a href="mlclassification.html#cb356-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb356-11"><a href="mlclassification.html#cb356-11" aria-hidden="true" tabindex="-1"></a>    .x</span>
<span id="cb356-12"><a href="mlclassification.html#cb356-12" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb356-13"><a href="mlclassification.html#cb356-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can run a quick test to see how it works.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="mlclassification.html#cb357-1" aria-hidden="true" tabindex="-1"></a><span class="fu">uncensor_vec</span>(<span class="st">&quot;In XX/XX/XXXX I leased a XXXX vehicle&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1] &quot;In 65/59/1659 I leased a 4598 vehicle&quot;</code></pre>
<p>Now we can produce the same visualization as Figure <a href="mlclassification.html#fig:censoredtrigram">7.8</a> but can also apply our uncensoring function to the text before tokenizing.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="mlclassification.html#cb359-1" aria-hidden="true" tabindex="-1"></a>complaints_train <span class="sc">%&gt;%</span></span>
<span id="cb359-2"><a href="mlclassification.html#cb359-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb359-3"><a href="mlclassification.html#cb359-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">text =</span> <span class="fu">uncensor_vec</span>(consumer_complaint_narrative)) <span class="sc">%&gt;%</span></span>
<span id="cb359-4"><a href="mlclassification.html#cb359-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(trigrams, text, <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>,</span>
<span id="cb359-5"><a href="mlclassification.html#cb359-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">collapse =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span></span>
<span id="cb359-6"><a href="mlclassification.html#cb359-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(trigrams, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb359-7"><a href="mlclassification.html#cb359-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">censored =</span> <span class="fu">str_detect</span>(trigrams, <span class="st">&quot;xx&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb359-8"><a href="mlclassification.html#cb359-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>) <span class="sc">%&gt;%</span></span>
<span id="cb359-9"><a href="mlclassification.html#cb359-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n, <span class="fu">reorder</span>(trigrams, n), <span class="at">fill =</span> censored)) <span class="sc">+</span></span>
<span id="cb359-10"><a href="mlclassification.html#cb359-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb359-11"><a href="mlclassification.html#cb359-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;grey40&quot;</span>, <span class="st">&quot;firebrick&quot;</span>)) <span class="sc">+</span></span>
<span id="cb359-12"><a href="mlclassification.html#cb359-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Trigrams&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:uncensoredtrigram"></span>
<img src="07_ml_classification_files/figure-html/uncensoredtrigram-1.svg" alt="Trigrams without numbers float to the top as the uncensored tokens are too spread out" width="672" />
<p class="caption">
FIGURE 7.10: Trigrams without numbers float to the top as the uncensored tokens are too spread out
</p>
</div>
<p>Here in Figure <a href="mlclassification.html#fig:uncensoredtrigram">7.10</a>, we see the same trigrams that appeared in Figure <a href="mlclassification.html#fig:censoredtrigram">7.8</a>.
However, none of the uncensored words appear, because of our uncensoring function.
This is expected, because while <code>"xx xx 2019"</code> appears in the first plot indicating a date in the year 2019, after we uncensor it, it is split into 365 buckets (actually more, since we used numerical values between <code>00</code> and <code>99</code>).
Censoring the dates in these complaints gives more power to a date as a general construct.</p>
<div class="rmdwarning">
<p>
What happens when we use these censored dates as a feature in supervised machine learning? We have a higher chance of understanding if dates in the complaint text are important to predicting the class, but we are blinded to the possibility that certain dates and months are more important.
</p>
</div>
<p>Data censoring can be a form of preprocessing in your data pipeline.
For example, it is highly unlikely to be useful (or ethical/legal) to have any specific person’s social security number, credit card number, or any other kind of PII embedded into your model. Such values appear rarely and are most likely highly correlated with other known variables in your data set.
More importantly, that information can become embedded in your model and begin to leak as demonstrated by <span class="citation"><a href="#ref-carlini2018secret" role="doc-biblioref">Carlini et al.</a> (<a href="#ref-carlini2018secret" role="doc-biblioref">2019</a>)</span>, <span class="citation"><a href="#ref-Fredrikson2014" role="doc-biblioref">Matthew Fredrikson et al.</a> (<a href="#ref-Fredrikson2014" role="doc-biblioref">2014</a>)</span>, and <span class="citation"><a href="#ref-Fredrikson2015" role="doc-biblioref">Matt Fredrikson, Jha, and Ristenpart</a> (<a href="#ref-Fredrikson2015" role="doc-biblioref">2015</a>)</span>.
Both of these issues are important, and one of them could land you in a lot of legal trouble.
Exposing such PII to modeling is an example of where we should all stop to ask, “Should we even be doing this?” as we discussed in the overview to these chapters.</p>
<p>If you have social security numbers in text data, you should definitely not pass them on to your machine learning model, but you may consider the option of annotating the <em>presence</em> of a social security number.
Since a social security number has a very specific form, we can easily construct a regular expression (Appendix <a href="regexp.html#regexp">A</a>) to locate them.</p>
<div class="rmdnote">
<p>
A social security number comes in the form <code>AAA-BB-CCCC</code> where <code>AAA</code> is a number between <code>001</code> and <code>899</code> excluding <code>666</code>, <code>BB</code> is a number between <code>01</code> and <code>99</code> and <code>CCCC</code> is a number between <code>0001</code> and <code>9999</code>. This gives us the following regex:
</p>
<p>
<code>(?!000|666)[0-8][0-9]{2}-(?!00)[0-9]{2}-(?!0000)[0-9]{4}</code>
</p>
</div>
<p>We can use a function to replace each social security number with an indicator that can be detected later by preprocessing steps.
It’s a good idea to use a “word” that won’t be accidentally broken up by a tokenizer.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="mlclassification.html#cb360-1" aria-hidden="true" tabindex="-1"></a>ssn_text <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;My social security number is 498-08-6333&quot;</span>,</span>
<span id="cb360-2"><a href="mlclassification.html#cb360-2" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;No way, mine is 362-60-9159&quot;</span>,</span>
<span id="cb360-3"><a href="mlclassification.html#cb360-3" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;My parents numbers are 575-32-6985 and 576-36-5202&quot;</span>)</span>
<span id="cb360-4"><a href="mlclassification.html#cb360-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-5"><a href="mlclassification.html#cb360-5" aria-hidden="true" tabindex="-1"></a>ssn_pattern <span class="ot">&lt;-</span>  <span class="st">&quot;(?!000|666)[0-8][0-9]{2}-(?!00)[0-9]{2}-(?!0000)[0-9]{4}&quot;</span></span>
<span id="cb360-6"><a href="mlclassification.html#cb360-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-7"><a href="mlclassification.html#cb360-7" aria-hidden="true" tabindex="-1"></a><span class="fu">str_replace_all</span>(<span class="at">string =</span> ssn_text,</span>
<span id="cb360-8"><a href="mlclassification.html#cb360-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">pattern =</span> ssn_pattern,</span>
<span id="cb360-9"><a href="mlclassification.html#cb360-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">replacement =</span> <span class="st">&quot;ssnindicator&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1] &quot;My social security number is ssnindicator&quot;           
#&gt; [2] &quot;No way, mine is ssnindicator&quot;                        
#&gt; [3] &quot;My parents numbers are ssnindicator and ssnindicator&quot;</code></pre>
<p>This technique isn’t useful only for personally identifiable information but can be used anytime you want to gather similar words in the same bucket; hashtags, email addresses, and usernames can sometimes benefit from being annotated in this way.</p>

<div class="rmdwarning">
The practice of data re-identification or de-anonymization, where seemingly or partially “anonymized” data sets are mined to identify individuals, is out of scope for this section and our book. However, this is a significant and important issue for any data practitioner dealing with PII, and we encourage readers to familiarize themselves with results such as <span class="citation"><a href="#ref-Sweeney2000" role="doc-biblioref">Sweeney</a> (<a href="#ref-Sweeney2000" role="doc-biblioref">2000</a>)</span> and current best practices to protect against such mining.
</div>
</div>
<div id="customfeatures" class="section level2 hasAnchor" number="7.9">
<h2><span class="header-section-number">7.9</span> Case study: custom features<a href="mlclassification.html#customfeatures" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Most of what we have looked at so far has boiled down to counting tokens and weighting them in one way or another.
This approach is quite broad and domain agnostic, but you as a data practitioner often have specific knowledge about your data set that you should use in feature engineering.
Your domain knowledge allows you to build more predictive features than the naive search of simple tokens.
As long as you can reasonably formulate what you are trying to count, chances are you can write a function that can detect it.
This is where having a little bit of knowledge about regular expressions pays off.</p>

<div class="rmdpackage">
The <strong>textfeatures</strong> <span class="citation">(<a href="#ref-R-textfeatures" role="doc-biblioref">Kearney 2019</a>)</span> package includes functions to extract useful features from text, from the number of digits to the number of second-person pronouns and more. These features can be used in textrecipes data preprocessing with the <code>step_textfeature()</code> function.
</div>
<p>Your specific domain knowledge may provide specific guidance about feature engineering for text.
Such custom features can be simple such as the number of URLs or the number of punctuation marks.
They can also be more engineered, such as the percentage of capitalization, whether the text ends with a hashtag, or whether two people’s names are both mentioned in a document.</p>
<p>For our CFPB complaints data, certain patterns may not have adequately been picked up by our model so far, such as the data censoring and the curly bracket annotation for monetary amounts that we saw in Section <a href="mlclassification.html#classfirstattemptlookatdata">7.1</a>. Let’s walk through how to create data preprocessing functions to build the features to:</p>
<ul>
<li><p>detect credit cards,</p></li>
<li><p>calculate percentage censoring, and</p></li>
<li><p>detect monetary amounts.</p></li>
</ul>
<div id="detect-credit-cards" class="section level3 hasAnchor" number="7.9.1">
<h3><span class="header-section-number">7.9.1</span> Detect credit cards<a href="mlclassification.html#detect-credit-cards" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A credit card number is represented as four groups of four capital Xs in this data set.
Since the data is fairly well processed we are fairly sure that spacing will not be an issue and all credit cards will be represented as “XXXX XXXX XXXX XXXX.”
A first naive attempt may be to use <code>str_detect()</code> with “XXXX XXXX XXXX XXXX” to find all the credit cards.</p>

<div class="rmdnote">
<p>
It is a good idea to create a small example regular expression where you know the answer, and then prototype your function before moving to the main data set.
</p>
</div>
<p>We start by creating a vector with two positives, one negative, and one potential false positive.
The last string is more tricky since it has the same shape as a credit card but has one too many groups.</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="mlclassification.html#cb362-1" aria-hidden="true" tabindex="-1"></a>credit_cards <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;my XXXX XXXX XXXX XXXX balance, and XXXX XXXX XXXX XXXX.&quot;</span>,</span>
<span id="cb362-2"><a href="mlclassification.html#cb362-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;card with number XXXX XXXX XXXX XXXX.&quot;</span>,</span>
<span id="cb362-3"><a href="mlclassification.html#cb362-3" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;at XX/XX 2019 my first&quot;</span>,</span>
<span id="cb362-4"><a href="mlclassification.html#cb362-4" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;live at XXXX XXXX XXXX XXXX XXXX SC&quot;</span>)</span>
<span id="cb362-5"><a href="mlclassification.html#cb362-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb362-6"><a href="mlclassification.html#cb362-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb362-7"><a href="mlclassification.html#cb362-7" aria-hidden="true" tabindex="-1"></a><span class="fu">str_detect</span>(credit_cards, <span class="st">&quot;XXXX XXXX XXXX XXXX&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1]  TRUE  TRUE FALSE  TRUE</code></pre>
<p>As we feared, the last vector was falsely detected to be a credit card.
Sometimes you will have to accept a certain number of false positives and/or false negatives, depending on the data and what you are trying to detect.
In this case, we can make the regex a little more complicated to avoid that specific false positive.
We need to make sure that the word coming before the X’s doesn’t end in a capital X and the word following the last X doesn’t start with a capital X.
We place spaces around the credit card and use some negated character classes (Appendix <a href="regexp.html#character-classes">A.3</a>) to detect anything BUT a capital X.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="mlclassification.html#cb364-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_detect</span>(credit_cards, <span class="st">&quot;[^X] XXXX XXXX XXXX XXXX [^X]&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1]  TRUE FALSE FALSE FALSE</code></pre>
<p>Hurray! This fixed the false positive.
But it gave us a false negative in return.
Turns out that this regex doesn’t allow the credit card to be followed by a period since it requires a space.
We can fix this with an alteration to match for a period or a space and a non-X.</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="mlclassification.html#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_detect</span>(credit_cards, <span class="st">&quot;[^X] +XXXX XXXX XXXX XXXX(</span><span class="sc">\\</span><span class="st">.| [^X])&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1]  TRUE  TRUE FALSE FALSE</code></pre>
<p>Now that we have a regular expression we are happy with we can wrap it up in a function we can use.
We can extract the presence of a credit card with <code>str_detect()</code> and the number of credit cards with <code>str_count()</code>.</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="mlclassification.html#cb368-1" aria-hidden="true" tabindex="-1"></a>creditcard_indicator <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb368-2"><a href="mlclassification.html#cb368-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">str_detect</span>(x, <span class="st">&quot;[^X] +XXXX XXXX XXXX XXXX(</span><span class="sc">\\</span><span class="st">.| [^X])&quot;</span>)</span>
<span id="cb368-3"><a href="mlclassification.html#cb368-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb368-4"><a href="mlclassification.html#cb368-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-5"><a href="mlclassification.html#cb368-5" aria-hidden="true" tabindex="-1"></a>creditcard_count <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb368-6"><a href="mlclassification.html#cb368-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">str_count</span>(x, <span class="st">&quot;[^X] +XXXX XXXX XXXX XXXX(</span><span class="sc">\\</span><span class="st">.| [^X])&quot;</span>)</span>
<span id="cb368-7"><a href="mlclassification.html#cb368-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb368-8"><a href="mlclassification.html#cb368-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-9"><a href="mlclassification.html#cb368-9" aria-hidden="true" tabindex="-1"></a><span class="fu">creditcard_indicator</span>(credit_cards)</span></code></pre></div>
<pre><code>#&gt; [1]  TRUE  TRUE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="mlclassification.html#cb370-1" aria-hidden="true" tabindex="-1"></a><span class="fu">creditcard_count</span>(credit_cards)</span></code></pre></div>
<pre><code>#&gt; [1] 2 1 0 0</code></pre>
</div>
<div id="calculate-percentage-censoring" class="section level3 hasAnchor" number="7.9.2">
<h3><span class="header-section-number">7.9.2</span> Calculate percentage censoring<a href="mlclassification.html#calculate-percentage-censoring" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Some of the complaints contain a high proportion of censoring, and we can build a feature to measure the percentage of the text that is censored.</p>
<div class="rmdwarning">
<p>
There are often many ways to get to the same solution when working with regular expressions.
</p>
</div>
<p></p>
<p>Let’s attack this problem by counting the number of X’s in each string, then count the number of alphanumeric characters and divide the two to get a percentage.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="mlclassification.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_count</span>(credit_cards, <span class="st">&quot;X&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1] 32 16  4 20</code></pre>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="mlclassification.html#cb374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_count</span>(credit_cards, <span class="st">&quot;[:alnum:]&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1] 44 30 17 28</code></pre>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="mlclassification.html#cb376-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_count</span>(credit_cards, <span class="st">&quot;X&quot;</span>) <span class="sc">/</span> <span class="fu">str_count</span>(credit_cards, <span class="st">&quot;[:alnum:]&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [1] 0.7272727 0.5333333 0.2352941 0.7142857</code></pre>
<p>We can finish up by creating a function.</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="mlclassification.html#cb378-1" aria-hidden="true" tabindex="-1"></a>percent_censoring <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb378-2"><a href="mlclassification.html#cb378-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">str_count</span>(x, <span class="st">&quot;X&quot;</span>) <span class="sc">/</span> <span class="fu">str_count</span>(x, <span class="st">&quot;[:alnum:]&quot;</span>)</span>
<span id="cb378-3"><a href="mlclassification.html#cb378-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb378-4"><a href="mlclassification.html#cb378-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb378-5"><a href="mlclassification.html#cb378-5" aria-hidden="true" tabindex="-1"></a><span class="fu">percent_censoring</span>(credit_cards)</span></code></pre></div>
<pre><code>#&gt; [1] 0.7272727 0.5333333 0.2352941 0.7142857</code></pre>
</div>
<div id="detect-monetary-amounts" class="section level3 hasAnchor" number="7.9.3">
<h3><span class="header-section-number">7.9.3</span> Detect monetary amounts<a href="mlclassification.html#detect-monetary-amounts" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have already constructed a regular expression that detects the monetary amount from the text in Section <a href="mlclassification.html#classfirstattemptlookatdata">7.1</a>, so now we can look at how to use this information.
Let’s start by creating a little example and see what we can extract.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="mlclassification.html#cb380-1" aria-hidden="true" tabindex="-1"></a>dollar_texts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;That will be {$20.00}&quot;</span>,</span>
<span id="cb380-2"><a href="mlclassification.html#cb380-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;{$3.00}, {$2.00} and {$7.00}&quot;</span>,</span>
<span id="cb380-3"><a href="mlclassification.html#cb380-3" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;I have no money&quot;</span>)</span>
<span id="cb380-4"><a href="mlclassification.html#cb380-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb380-5"><a href="mlclassification.html#cb380-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str_extract_all</span>(dollar_texts, <span class="st">&quot;</span><span class="sc">\\</span><span class="st">{</span><span class="sc">\\</span><span class="st">$[0-9</span><span class="sc">\\</span><span class="st">.]*</span><span class="sc">\\</span><span class="st">}&quot;</span>)</span></code></pre></div>
<pre><code>#&gt; [[1]]
#&gt; [1] &quot;{$20.00}&quot;
#&gt; 
#&gt; [[2]]
#&gt; [1] &quot;{$3.00}&quot; &quot;{$2.00}&quot; &quot;{$7.00}&quot;
#&gt; 
#&gt; [[3]]
#&gt; character(0)</code></pre>
<p>We can create a function that simply detects the dollar amount, and we can count the number of times each amount appears.
Each occurrence also has a value, so it would be nice to include that information as well, such as the mean, minimum, or maximum.</p>
<p>First, let’s extract the number from the strings. We could write a regular expression for this, but the <code>parse_number()</code> function from the readr package does a really good job of pulling out numbers.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="mlclassification.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_extract_all</span>(dollar_texts, <span class="st">&quot;</span><span class="sc">\\</span><span class="st">{</span><span class="sc">\\</span><span class="st">$[0-9</span><span class="sc">\\</span><span class="st">.]*</span><span class="sc">\\</span><span class="st">}&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb382-2"><a href="mlclassification.html#cb382-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map</span>(readr<span class="sc">::</span>parse_number)</span></code></pre></div>
<pre><code>#&gt; [[1]]
#&gt; [1] 20
#&gt; 
#&gt; [[2]]
#&gt; [1] 3 2 7
#&gt; 
#&gt; [[3]]
#&gt; numeric(0)</code></pre>
<p>Now that we have the numbers we can iterate over them with the function of our choice.
Since we are going to have texts with no monetary amounts, we need to handle the case with zero numbers. Defaults for some functions with vectors of length zero can be undesirable; we don’t want <code>-Inf</code> to be a value. Let’s extract the maximum value and give cases with no monetary amounts a maximum of zero.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="mlclassification.html#cb384-1" aria-hidden="true" tabindex="-1"></a>max_money <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb384-2"><a href="mlclassification.html#cb384-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">str_extract_all</span>(x, <span class="st">&quot;</span><span class="sc">\\</span><span class="st">{</span><span class="sc">\\</span><span class="st">$[0-9</span><span class="sc">\\</span><span class="st">.]*</span><span class="sc">\\</span><span class="st">}&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb384-3"><a href="mlclassification.html#cb384-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(readr<span class="sc">::</span>parse_number) <span class="sc">%&gt;%</span></span>
<span id="cb384-4"><a href="mlclassification.html#cb384-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map_dbl</span>(<span class="sc">~</span> <span class="fu">ifelse</span>(<span class="fu">length</span>(.x) <span class="sc">==</span> <span class="dv">0</span>, <span class="dv">0</span>, <span class="fu">max</span>(.x)))</span>
<span id="cb384-5"><a href="mlclassification.html#cb384-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb384-6"><a href="mlclassification.html#cb384-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb384-7"><a href="mlclassification.html#cb384-7" aria-hidden="true" tabindex="-1"></a><span class="fu">max_money</span>(dollar_texts)</span></code></pre></div>
<pre><code>#&gt; [1] 20  7  0</code></pre>
<p>Now that we have created some feature engineering functions, we can use them to (hopefully) make our classification model better.</p>
</div>
</div>
<div id="what-evaluation-metrics-are-appropriate-1" class="section level2 hasAnchor" number="7.10">
<h2><span class="header-section-number">7.10</span> What evaluation metrics are appropriate?<a href="mlclassification.html#what-evaluation-metrics-are-appropriate-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have focused on using accuracy and ROC AUC as metrics for our classification models so far. These are not the only classification metrics available, and your choice will often depend on how much you care about false positives compared to false negatives.</p>
<p>If you know before you fit your model that you want to compute one or more metrics, you can specify them in a call to <code>metric_set()</code>. Let’s set up a tuning grid for two new classification metrics, <code>recall</code> and <code>precision</code>, that focuses not on the overall proportion of observations that are predicted correctly but instead on false positives and false negatives.</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="mlclassification.html#cb386-1" aria-hidden="true" tabindex="-1"></a>nb_rs <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb386-2"><a href="mlclassification.html#cb386-2" aria-hidden="true" tabindex="-1"></a>  nb_wf,</span>
<span id="cb386-3"><a href="mlclassification.html#cb386-3" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb386-4"><a href="mlclassification.html#cb386-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(recall, precision)</span>
<span id="cb386-5"><a href="mlclassification.html#cb386-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>If you have already fit your model, you can still compute and explore non-default metrics as long as you saved the predictions for your resampled data sets using <code>control_resamples(save_pred = TRUE)</code>.</p>
<p>Let’s go back to the naive Bayes model we tuned in Section <a href="mlclassification.html#classfirstmodel">7.1.1</a>, with predictions stored in <code>nb_rs_predictions</code>. We can compute the overall recall.</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="mlclassification.html#cb387-1" aria-hidden="true" tabindex="-1"></a>nb_rs_predictions <span class="sc">%&gt;%</span></span>
<span id="cb387-2"><a href="mlclassification.html#cb387-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recall</span>(product, .pred_class)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 1 × 3
#&gt;   .metric .estimator .estimate
#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
#&gt; 1 recall  binary         0.694</code></pre>
<p>We can also compute the recall for each resample using <code>group_by()</code>.</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="mlclassification.html#cb389-1" aria-hidden="true" tabindex="-1"></a>nb_rs_predictions <span class="sc">%&gt;%</span></span>
<span id="cb389-2"><a href="mlclassification.html#cb389-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb389-3"><a href="mlclassification.html#cb389-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recall</span>(product, .pred_class)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 10 × 4
#&gt;    id     .metric .estimator .estimate
#&gt;    &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
#&gt;  1 Fold01 recall  binary         0.701
#&gt;  2 Fold02 recall  binary         0.730
#&gt;  3 Fold03 recall  binary         0.682
#&gt;  4 Fold04 recall  binary         0.669
#&gt;  5 Fold05 recall  binary         0.710
#&gt;  6 Fold06 recall  binary         0.608
#&gt;  7 Fold07 recall  binary         0.748
#&gt;  8 Fold08 recall  binary         0.714
#&gt;  9 Fold09 recall  binary         0.776
#&gt; 10 Fold10 recall  binary         0.604</code></pre>
<p>Many of the metrics used for classification are functions of the true positive, true negative, false positive, and false negative rates.
The confusion matrix, a contingency table of observed classes and predicted classes, gives us information on these rates directly.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="mlclassification.html#cb391-1" aria-hidden="true" tabindex="-1"></a><span class="fu">conf_mat_resampled</span>(nb_rs, <span class="at">tidy =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>#&gt;        Credit  Other
#&gt; Credit 2892.1  420.1
#&gt; Other  1274.7 4204.1</code></pre>
<p>It is possible with many data sets to achieve high accuracy just by predicting the majority class all the time, but such a model is not useful in the real world. Accuracy alone is often not a good way to assess the performance of classification models.</p>
<div class="rmdnote">
<p>
For the full set of classification metric options, see the <a href="https://yardstick.tidymodels.org/reference/">yardstick documentation</a>.
</p>
</div>
</div>
<div id="mlclassificationfull" class="section level2 hasAnchor" number="7.11">
<h2><span class="header-section-number">7.11</span> The full game: classification<a href="mlclassification.html#mlclassificationfull" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have come a long way from our first classification model in Section <a href="mlclassification.html#classfirstmodel">7.1.1</a>, and it is time to see how we can use what we have learned to improve it.
We started this chapter with a simple naive Bayes model and token counts.
Since then have we looked at different models, preprocessing techniques, and domain-specific feature engineering.
For our final model, let’s use some of the domain-specific features we developed in Section <a href="mlclassification.html#customfeatures">7.9</a> along with our lasso regularized classification model and tune both the regularization penalty, as well as the number of tokens to include. For this final model we will:</p>
<ul>
<li><p>train on the same set of cross-validation resamples used throughout this chapter,</p></li>
<li><p>include text (but not <code>tags</code> or date features, since those did not result in better performance),</p></li>
<li><p>tune the number of tokens used in the model,</p></li>
<li><p>include unigrams only,</p></li>
<li><p>include custom-engineered features,</p></li>
<li><p>finally evaluate on the testing set, which we have not touched at all yet.</p></li>
</ul>
<div class="rmdnote">
<p>
Be aware that the tuning calculations we demonstrate here are computationally expensive, and take a long time to complete.
</p>
</div>
<div id="feature-selection" class="section level3 hasAnchor" number="7.11.1">
<h3><span class="header-section-number">7.11.1</span> Feature selection<a href="mlclassification.html#feature-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We start by creating a new preprocessing recipe, using only the text of the complaints for feature engineering.</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="mlclassification.html#cb393-1" aria-hidden="true" tabindex="-1"></a>complaints_rec_v2 <span class="ot">&lt;-</span></span>
<span id="cb393-2"><a href="mlclassification.html#cb393-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(product <span class="sc">~</span> consumer_complaint_narrative, <span class="at">data =</span> complaints_train)</span></code></pre></div>
<p>After exploring this text data more in Section <a href="mlclassification.html#customfeatures">7.9</a>, we want to add these custom features to our final model.
To do this, we use <code>step_textfeature()</code> to compute custom text features.
We create a list of the custom text features and pass this list to <code>step_textfeature()</code> via the <code>extract_functions</code> argument.
Note how we have to take a copy of <code>consumer_complaint_narrative</code> using <code>step_mutate()</code> as <code>step_textfeature()</code> consumes the column.</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="mlclassification.html#cb394-1" aria-hidden="true" tabindex="-1"></a>extract_funs <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">creditcard_count =</span> creditcard_count,</span>
<span id="cb394-2"><a href="mlclassification.html#cb394-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">percent_censoring =</span> percent_censoring,</span>
<span id="cb394-3"><a href="mlclassification.html#cb394-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">max_money =</span> max_money)</span>
<span id="cb394-4"><a href="mlclassification.html#cb394-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb394-5"><a href="mlclassification.html#cb394-5" aria-hidden="true" tabindex="-1"></a>complaints_rec_v2 <span class="ot">&lt;-</span> complaints_rec_v2 <span class="sc">%&gt;%</span></span>
<span id="cb394-6"><a href="mlclassification.html#cb394-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_mutate</span>(<span class="at">narrative_copy =</span> consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb394-7"><a href="mlclassification.html#cb394-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_textfeature</span>(narrative_copy, <span class="at">extract_functions =</span> extract_funs)</span></code></pre></div>
<p>The tokenization will be similar to the other models in this chapter.
In our original model, we only included 1000 tokens; for our final model, let’s treat the number of tokens as a hyperparameter that we vary when we tune the final model.
Let’s also set the <code>min_times</code> argument to 100, to throw away tokens that appear less than 100 times in the entire corpus.
We want our model to be robust and a token needs to appear enough times before we include it.</p>
<div class="rmdnote">
<p>
This data set has many more than 100 of even the most common 5000 or more tokens, but it can still be good practice to specify <code>min_times</code> to be safe. Your choice for <code>min_times</code> should depend on your data and how robust you need your model to be.
</p>
</div>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="mlclassification.html#cb395-1" aria-hidden="true" tabindex="-1"></a>complaints_rec_v2 <span class="ot">&lt;-</span> complaints_rec_v2 <span class="sc">%&gt;%</span></span>
<span id="cb395-2"><a href="mlclassification.html#cb395-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenize</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb395-3"><a href="mlclassification.html#cb395-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenfilter</span>(consumer_complaint_narrative,</span>
<span id="cb395-4"><a href="mlclassification.html#cb395-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">max_tokens =</span> <span class="fu">tune</span>(), <span class="at">min_times =</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span></span>
<span id="cb395-5"><a href="mlclassification.html#cb395-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tfidf</span>(consumer_complaint_narrative)</span></code></pre></div>
</div>
<div id="specify-the-model-1" class="section level3 hasAnchor" number="7.11.2">
<h3><span class="header-section-number">7.11.2</span> Specify the model<a href="mlclassification.html#specify-the-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We use a lasso regularized classifier since it performed well throughout this chapter. We can reuse parts of the old workflow <code>sparse_wf</code> from Section <a href="mlclassification.html#casestudysparseencoding">7.5</a> and update the recipe specification.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="mlclassification.html#cb396-1" aria-hidden="true" tabindex="-1"></a>sparse_wf_v2 <span class="ot">&lt;-</span> sparse_wf <span class="sc">%&gt;%</span></span>
<span id="cb396-2"><a href="mlclassification.html#cb396-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_recipe</span>(complaints_rec_v2, <span class="at">blueprint =</span> sparse_bp)</span>
<span id="cb396-3"><a href="mlclassification.html#cb396-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb396-4"><a href="mlclassification.html#cb396-4" aria-hidden="true" tabindex="-1"></a>sparse_wf_v2</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: logistic_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 5 Recipe Steps
#&gt; 
#&gt; • step_mutate()
#&gt; • step_textfeature()
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = tune()
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>Before we tune the model, we need to set up a set of possible parameter values to try.</p>
<div class="rmdwarning">
<p>
There are <em>two</em> tunable parameters in this model, the regularization parameter and the maximum number of tokens included in the model.
</p>
</div>
<p>Let’s include different possible values for each parameter, for a combination of 60 models.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="mlclassification.html#cb398-1" aria-hidden="true" tabindex="-1"></a>final_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(</span>
<span id="cb398-2"><a href="mlclassification.html#cb398-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">penalty</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">0</span>)),</span>
<span id="cb398-3"><a href="mlclassification.html#cb398-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">max_tokens</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="fl">1e3</span>, <span class="fl">3e3</span>)),</span>
<span id="cb398-4"><a href="mlclassification.html#cb398-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">levels =</span> <span class="fu">c</span>(<span class="at">penalty =</span> <span class="dv">20</span>, <span class="at">max_tokens =</span> <span class="dv">3</span>)</span>
<span id="cb398-5"><a href="mlclassification.html#cb398-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb398-6"><a href="mlclassification.html#cb398-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb398-7"><a href="mlclassification.html#cb398-7" aria-hidden="true" tabindex="-1"></a>final_grid</span></code></pre></div>
<pre><code>#&gt; # A tibble: 60 × 2
#&gt;     penalty max_tokens
#&gt;       &lt;dbl&gt;      &lt;int&gt;
#&gt;  1 0.0001         1000
#&gt;  2 0.000162       1000
#&gt;  3 0.000264       1000
#&gt;  4 0.000428       1000
#&gt;  5 0.000695       1000
#&gt;  6 0.00113        1000
#&gt;  7 0.00183        1000
#&gt;  8 0.00298        1000
#&gt;  9 0.00483        1000
#&gt; 10 0.00785        1000
#&gt; # … with 50 more rows</code></pre>

<div class="rmdpackage">
We used <code>grid_regular()</code> here where we fit a model at every combination of parameters, but if you have a model with many tuning parameters, you may wish to try a space-filling grid instead, such as <code>grid_max_entropy()</code> or <code>grid_latin_hypercube()</code>. The <strong>tidymodels</strong> package for creating and handling tuning parameters and parameter grids is <strong>dials</strong> <span class="citation">(<a href="#ref-R-dials" role="doc-biblioref">Kuhn 2020</a>)</span>.
</div>
<p>Now it’s time to set up our tuning grid. Let’s save the predictions so we can explore them in more detail, and let’s also set custom metrics instead of using the defaults. Let’s compute accuracy, sensitivity, and specificity during tuning. Sensitivity and specificity are closely related to recall and precision.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="mlclassification.html#cb400-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb400-2"><a href="mlclassification.html#cb400-2" aria-hidden="true" tabindex="-1"></a>tune_rs <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb400-3"><a href="mlclassification.html#cb400-3" aria-hidden="true" tabindex="-1"></a>  sparse_wf_v2,</span>
<span id="cb400-4"><a href="mlclassification.html#cb400-4" aria-hidden="true" tabindex="-1"></a>  complaints_folds,</span>
<span id="cb400-5"><a href="mlclassification.html#cb400-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> final_grid,</span>
<span id="cb400-6"><a href="mlclassification.html#cb400-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(accuracy, sensitivity, specificity)</span>
<span id="cb400-7"><a href="mlclassification.html#cb400-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>We have fitted these classification models!</p>
</div>
<div id="classification-final-evaluation" class="section level3 hasAnchor" number="7.11.3">
<h3><span class="header-section-number">7.11.3</span> Evaluate the modeling<a href="mlclassification.html#classification-final-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that all of the models with possible parameter values have been trained, we can compare their performance. Figure <a href="mlclassification.html#fig:complaintsfinaltunevis">7.11</a> shows us the relationship between performance (as measured by the metrics we chose), the number of tokens, and regularization.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="mlclassification.html#cb401-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tune_rs) <span class="sc">+</span></span>
<span id="cb401-2"><a href="mlclassification.html#cb401-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb401-3"><a href="mlclassification.html#cb401-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;Number of tokens&quot;</span>,</span>
<span id="cb401-4"><a href="mlclassification.html#cb401-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Model performance across regularization penalties and tokens&quot;</span>,</span>
<span id="cb401-5"><a href="mlclassification.html#cb401-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">&quot;We can choose a simpler model with higher regularization&quot;</span>)</span>
<span id="cb401-6"><a href="mlclassification.html#cb401-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:complaintsfinaltunevis"></span>
<img src="07_ml_classification_files/figure-html/complaintsfinaltunevis-1.svg" alt="Model performance is similar for the higher token options so we can choose a simpler model. Note the logarithmic scale on the x-axis for the regularization penalty." width="672" />
<p class="caption">
FIGURE 7.11: Model performance is similar for the higher token options so we can choose a simpler model. Note the logarithmic scale on the x-axis for the regularization penalty.
</p>
</div>
<p>Since this is our final version of this model, we want to choose final parameters and update our model object so we can use it with new data. We have several options for choosing our final parameters, such as selecting the numerically best model. Instead, let’s choose a simpler model within some limit around that numerically best result, with more regularization that gives close-to-best performance. Let’s choose by percent loss compared to the best model (the default choice is 2% loss), and let’s say we care most about overall accuracy (rather than sensitivity or specificity).</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="mlclassification.html#cb402-1" aria-hidden="true" tabindex="-1"></a>choose_acc <span class="ot">&lt;-</span> tune_rs <span class="sc">%&gt;%</span></span>
<span id="cb402-2"><a href="mlclassification.html#cb402-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_by_pct_loss</span>(<span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>, <span class="sc">-</span>penalty)</span>
<span id="cb402-3"><a href="mlclassification.html#cb402-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-4"><a href="mlclassification.html#cb402-4" aria-hidden="true" tabindex="-1"></a>choose_acc</span></code></pre></div>
<pre><code>#&gt; # A tibble: 1 × 10
#&gt;   penalty max_tokens .metric  .estimator  mean     n std_err .config .best .loss
#&gt;     &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;
#&gt; 1 0.00483       1000 accuracy binary     0.882    10 0.00100 Prepro… 0.898  1.74</code></pre>
<p>After we have those parameters, <code>penalty</code> and <code>max_tokens</code>, we can finalize our earlier tunable workflow, by updating it with this value.</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="mlclassification.html#cb404-1" aria-hidden="true" tabindex="-1"></a>final_wf <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(sparse_wf_v2, choose_acc)</span>
<span id="cb404-2"><a href="mlclassification.html#cb404-2" aria-hidden="true" tabindex="-1"></a>final_wf</span></code></pre></div>
<pre><code>#&gt; ══ Workflow ════════════════════════════════════════════════════════════════════
#&gt; Preprocessor: Recipe
#&gt; Model: logistic_reg()
#&gt; 
#&gt; ── Preprocessor ────────────────────────────────────────────────────────────────
#&gt; 5 Recipe Steps
#&gt; 
#&gt; • step_mutate()
#&gt; • step_textfeature()
#&gt; • step_tokenize()
#&gt; • step_tokenfilter()
#&gt; • step_tfidf()
#&gt; 
#&gt; ── Model ───────────────────────────────────────────────────────────────────────
#&gt; Logistic Regression Model Specification (classification)
#&gt; 
#&gt; Main Arguments:
#&gt;   penalty = 0.00483293023857175
#&gt;   mixture = 1
#&gt; 
#&gt; Computational engine: glmnet</code></pre>
<p>The <code>final_wf</code> workflow now has finalized values for <code>max_tokens</code> and <code>penalty</code>.</p>
<p>We can now fit this finalized workflow on training data and <em>finally</em> return to our testing data.</p>
<div class="rmdwarning">
<p>
Notice that this is the first time we have used our testing data during this entire chapter; we tuned and compared models using resampled data sets instead of touching the testing set.
</p>
</div>
<p>We can use the function <code>last_fit()</code> to <strong>fit</strong> our model one last time on our training data and <strong>evaluate</strong> it on our testing data. We only have to pass this function our finalized model/workflow and our data split.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="mlclassification.html#cb406-1" aria-hidden="true" tabindex="-1"></a>final_fitted <span class="ot">&lt;-</span> <span class="fu">last_fit</span>(final_wf, complaints_split)</span>
<span id="cb406-2"><a href="mlclassification.html#cb406-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb406-3"><a href="mlclassification.html#cb406-3" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(final_fitted)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 2 × 4
#&gt;   .metric  .estimator .estimate .config             
#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
#&gt; 1 accuracy binary         0.882 Preprocessor1_Model1
#&gt; 2 roc_auc  binary         0.949 Preprocessor1_Model1</code></pre>
<p>The metrics for the test set look about the same as the resampled training data and indicate we did not overfit during tuning. The accuracy of our final model has improved compared to our earlier models, both because we are combining multiple preprocessing steps and because we have tuned the number of tokens.</p>
<p>The confusion matrix on the testing data in Figure <a href="mlclassification.html#fig:finalheatmap">7.12</a> also yields pleasing results. It appears symmetric with a strong presence on the diagonal, showing that there isn’t any strong bias towards either of the classes.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="mlclassification.html#cb408-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_predictions</span>(final_fitted) <span class="sc">%&gt;%</span></span>
<span id="cb408-2"><a href="mlclassification.html#cb408-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> product, <span class="at">estimate =</span> .pred_class) <span class="sc">%&gt;%</span></span>
<span id="cb408-3"><a href="mlclassification.html#cb408-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:finalheatmap"></span>
<img src="07_ml_classification_files/figure-html/finalheatmap-1.svg" alt="Confusion matrix on the test set for final lasso regularized classifier" width="672" />
<p class="caption">
FIGURE 7.12: Confusion matrix on the test set for final lasso regularized classifier
</p>
</div>
<p>Figure <a href="mlclassification.html#fig:finalroccurve">7.13</a> shows the ROC curve for the testing set, to demonstrate how well this final classification model can distinguish between the two classes.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="mlclassification.html#cb409-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_predictions</span>(final_fitted)  <span class="sc">%&gt;%</span></span>
<span id="cb409-2"><a href="mlclassification.html#cb409-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(<span class="at">truth =</span> product, .pred_Credit) <span class="sc">%&gt;%</span></span>
<span id="cb409-3"><a href="mlclassification.html#cb409-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb409-4"><a href="mlclassification.html#cb409-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb409-5"><a href="mlclassification.html#cb409-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="cn">NULL</span>,</span>
<span id="cb409-6"><a href="mlclassification.html#cb409-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;ROC curve for US Consumer Finance Complaints&quot;</span>,</span>
<span id="cb409-7"><a href="mlclassification.html#cb409-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;With final tuned lasso regularized classifier on the test set&quot;</span></span>
<span id="cb409-8"><a href="mlclassification.html#cb409-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:finalroccurve"></span>
<img src="07_ml_classification_files/figure-html/finalroccurve-1.svg" alt="ROC curve with the test set for final lasso regularized classifier" width="672" />
<p class="caption">
FIGURE 7.13: ROC curve with the test set for final lasso regularized classifier
</p>
</div>
<p>The output of <code>last_fit()</code> also contains a fitted model (a <code>workflow</code>, to be more specific) that has been trained on the <em>training</em> data. We can use the vip package to understand what the most important variables are in the predictions, shown in Figure <a href="mlclassification.html#fig:complaintsvip">7.14</a>.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="mlclassification.html#cb410-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb410-2"><a href="mlclassification.html#cb410-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb410-3"><a href="mlclassification.html#cb410-3" aria-hidden="true" tabindex="-1"></a>complaints_imp <span class="ot">&lt;-</span> <span class="fu">extract_fit_parsnip</span>(final_fitted<span class="sc">$</span>.workflow[[<span class="dv">1</span>]]) <span class="sc">%&gt;%</span></span>
<span id="cb410-4"><a href="mlclassification.html#cb410-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vi</span>(<span class="at">lambda =</span> choose_acc<span class="sc">$</span>penalty)</span>
<span id="cb410-5"><a href="mlclassification.html#cb410-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb410-6"><a href="mlclassification.html#cb410-6" aria-hidden="true" tabindex="-1"></a>complaints_imp <span class="sc">%&gt;%</span></span>
<span id="cb410-7"><a href="mlclassification.html#cb410-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb410-8"><a href="mlclassification.html#cb410-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">Sign =</span> <span class="fu">case_when</span>(Sign <span class="sc">==</span> <span class="st">&quot;POS&quot;</span> <span class="sc">~</span> <span class="st">&quot;Less about credit reporting&quot;</span>,</span>
<span id="cb410-9"><a href="mlclassification.html#cb410-9" aria-hidden="true" tabindex="-1"></a>                     Sign <span class="sc">==</span> <span class="st">&quot;NEG&quot;</span> <span class="sc">~</span> <span class="st">&quot;More about credit reporting&quot;</span>),</span>
<span id="cb410-10"><a href="mlclassification.html#cb410-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">Importance =</span> <span class="fu">abs</span>(Importance),</span>
<span id="cb410-11"><a href="mlclassification.html#cb410-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">Variable =</span> <span class="fu">str_remove_all</span>(Variable, <span class="st">&quot;tfidf_consumer_complaint_narrative_&quot;</span>),</span>
<span id="cb410-12"><a href="mlclassification.html#cb410-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">Variable =</span> <span class="fu">str_remove_all</span>(Variable, <span class="st">&quot;textfeature_narrative_copy_&quot;</span>)</span>
<span id="cb410-13"><a href="mlclassification.html#cb410-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb410-14"><a href="mlclassification.html#cb410-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Sign) <span class="sc">%&gt;%</span></span>
<span id="cb410-15"><a href="mlclassification.html#cb410-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">top_n</span>(<span class="dv">20</span>, Importance) <span class="sc">%&gt;%</span></span>
<span id="cb410-16"><a href="mlclassification.html#cb410-16" aria-hidden="true" tabindex="-1"></a>  ungroup <span class="sc">%&gt;%</span></span>
<span id="cb410-17"><a href="mlclassification.html#cb410-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Importance,</span>
<span id="cb410-18"><a href="mlclassification.html#cb410-18" aria-hidden="true" tabindex="-1"></a>             <span class="at">y =</span> <span class="fu">fct_reorder</span>(Variable, Importance),</span>
<span id="cb410-19"><a href="mlclassification.html#cb410-19" aria-hidden="true" tabindex="-1"></a>             <span class="at">fill =</span> Sign)) <span class="sc">+</span></span>
<span id="cb410-20"><a href="mlclassification.html#cb410-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb410-21"><a href="mlclassification.html#cb410-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb410-22"><a href="mlclassification.html#cb410-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Sign, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb410-23"><a href="mlclassification.html#cb410-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb410-24"><a href="mlclassification.html#cb410-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="cn">NULL</span>,</span>
<span id="cb410-25"><a href="mlclassification.html#cb410-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Variable importance for predicting the topic of a CFPB complaint&quot;</span>,</span>
<span id="cb410-26"><a href="mlclassification.html#cb410-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste0</span>(<span class="st">&quot;These features are the most important in predicting</span><span class="sc">\n</span><span class="st">&quot;</span>,</span>
<span id="cb410-27"><a href="mlclassification.html#cb410-27" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;whether a complaint is about credit or not&quot;</span>)</span>
<span id="cb410-28"><a href="mlclassification.html#cb410-28" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:complaintsvip"></span>
<img src="07_ml_classification_files/figure-html/complaintsvip-1.svg" alt="Some words increase a CFPB complaint's probability of being about credit reporting while some decrease that probability" width="672" />
<p class="caption">
FIGURE 7.14: Some words increase a CFPB complaint’s probability of being about credit reporting while some decrease that probability
</p>
</div>
<p>Tokens like “interest,” “bank,” and “escrow” contribute in this model away from a classification as about credit reporting, while tokens like the names of the credit reporting agencies, “reporting,” and “report” contribute in this model <em>toward</em> classification as about credit reporting.</p>
<div class="rmdnote">
<p>
The top features we see here are all tokens learned directly from the text. None of our hand-crafted custom features, like <code>percent_censoring</code> or <code>max_money</code> are top features in terms of variable importance. In many cases, it can be difficult to create features from text that perform better than the tokens themselves.
</p>
</div>
<p>We can gain some final insight into our model by looking at observations from the test set that it <em>misclassified</em>. Let’s bind together the predictions on the test set with the original <code>complaints_test</code> data. Then let’s look at complaints that were labeled as about credit reporting in the original data but that our final model thought had a low probability of being about credit reporting.</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="mlclassification.html#cb411-1" aria-hidden="true" tabindex="-1"></a>complaints_bind <span class="ot">&lt;-</span> <span class="fu">collect_predictions</span>(final_fitted) <span class="sc">%&gt;%</span></span>
<span id="cb411-2"><a href="mlclassification.html#cb411-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(complaints_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>product))</span>
<span id="cb411-3"><a href="mlclassification.html#cb411-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb411-4"><a href="mlclassification.html#cb411-4" aria-hidden="true" tabindex="-1"></a>complaints_bind <span class="sc">%&gt;%</span></span>
<span id="cb411-5"><a href="mlclassification.html#cb411-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(product <span class="sc">==</span> <span class="st">&quot;Credit&quot;</span>, .pred_Credit <span class="sc">&lt;</span> <span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb411-6"><a href="mlclassification.html#cb411-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb411-7"><a href="mlclassification.html#cb411-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 10 × 1
#&gt;    consumer_complaint_narrative                                                 
#&gt;    &lt;chr&gt;                                                                        
#&gt;  1 &quot;I am writing this complaint due to the lack of communication on the constru…
#&gt;  2 &quot;Enhanced recovery is trying to collect on another account that does not bel…
#&gt;  3 &quot;I am trying to get a mortgage for a house and one of the things they told m…
#&gt;  4 &quot;I subscribed to trans-union for a one month period on their website. They d…
#&gt;  5 &quot;I moved out of the apartment I rented before lease expiration date as it wa…
#&gt;  6 &quot;I have asked both XXXX  and XXXX the collection Agency Riddled with thousan…
#&gt;  7 &quot;I have used my XXXX XXXX credit  card  since XX/XX/XXXX, but closed this ac…
#&gt;  8 &quot;I am looking for a refund on a fraudulent credit card payment with Capital …
#&gt;  9 &quot;Since acquiring my mortgage about 8 months following bankruptcy, the collec…
#&gt; 10 &quot;Old debt is sold or reassigned to another agency at the end of the seven ye…</code></pre>
<p>We can see why some of these would be difficult for our model to classify as about credit reporting, since some are about other topics as well. The original label may also be incorrect in some cases.</p>
<p>What about misclassifications in the other direction, observations in the test set that were <em>not</em> labeled as about credit reporting but that our final model gave a high probability of being about credit reporting?</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="mlclassification.html#cb413-1" aria-hidden="true" tabindex="-1"></a>complaints_bind <span class="sc">%&gt;%</span></span>
<span id="cb413-2"><a href="mlclassification.html#cb413-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(product <span class="sc">==</span> <span class="st">&quot;Other&quot;</span>, .pred_Credit <span class="sc">&gt;</span> <span class="fl">0.8</span>) <span class="sc">%&gt;%</span></span>
<span id="cb413-3"><a href="mlclassification.html#cb413-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(consumer_complaint_narrative) <span class="sc">%&gt;%</span></span>
<span id="cb413-4"><a href="mlclassification.html#cb413-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>#&gt; # A tibble: 10 × 1
#&gt;    consumer_complaint_narrative                                                 
#&gt;    &lt;chr&gt;                                                                        
#&gt;  1 &quot;RCVL PER MNG is reporting inaccurately on my credit report. They are in vio…
#&gt;  2 &quot;First, the company changed it&#39;s name and reporting my account beyond the 7 …
#&gt;  3 &quot;XXXX XXXX collection has been all my report on and off for the last 7 years…
#&gt;  4 &quot;I have attempted on numerous times to dispute an account that has ERRORS. E…
#&gt;  5 &quot;XXXX XXXX, XXXX on XX/XX/19 has not validated the XXXX account and has fail…
#&gt;  6 &quot;My Reports A mess and there credit companies say I owe them but I dont&quot;     
#&gt;  7 &quot;Please remove these accounts as they do not belong to me. XXXX the attached…
#&gt;  8 &quot;CEASE COMMUNICATIONS AND REMOVE ALL CREDIT REPORTING OR BE SUED. FOR XXXX X…
#&gt;  9 &quot;I have made several attempts to delete the following charge off account. Eq…
#&gt; 10 &quot;My Citi Secured Card Never reported to My Credit Report when its suppose to…</code></pre>
<p>Again, these are “mistakes” on the part of the model that we can understand based on the content of these complaints. The original labeling on the complaints looks to be not entirely correct or consistent, typical of real data from the real world.</p>
</div>
</div>
<div id="mlclassificationsummary" class="section level2 hasAnchor" number="7.12">
<h2><span class="header-section-number">7.12</span> Summary<a href="mlclassification.html#mlclassificationsummary" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You can use classification modeling to predict labels or categorical variables from a data set, including data sets that include text.
Naive Bayes models can perform well with text data since each feature is handled independently and thus large numbers of features are computational feasible.
This is important as bag-of-word text models can involve thousands of tokens.
We also saw that regularized linear models, such as lasso, often work well for text data sets.
Your own domain knowledge about your text data is valuable, and using that knowledge in careful engineering of custom features can improve your model in some cases.</p>
<div id="in-this-chapter-you-learned-6" class="section level3 hasAnchor" number="7.12.1">
<h3><span class="header-section-number">7.12.1</span> In this chapter, you learned:<a href="mlclassification.html#in-this-chapter-you-learned-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>how text data can be used in a classification model</p></li>
<li><p>to tune hyperparameters of a model</p></li>
<li><p>how to compare different model types</p></li>
<li><p>that models can combine both text and non-text predictors</p></li>
<li><p>about engineering custom features for machine learning</p></li>
<li><p>about performance metrics for classification models</p></li>
</ul>

</div>
</div>
</div>



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-R-Matrix" class="csl-entry">
Bates, D., and Maechler, M. 2021. <em>Matrix: Sparse and Dense Matrix Classes and Methods</em>. R package version 1.3-2. <a href="https://CRAN.R-project.org/package=Matrix">https://CRAN.R-project.org/package=Matrix</a>.
</div>
<div id="ref-Breiman1984" class="csl-entry">
Breiman, L., Friedman, J., Stone, C. J., and Olshen, R. A. 1984. <em><span class="nocase">Classification and Regression Trees</span></em>. Boca Raton: CRC Press.
</div>
<div id="ref-carlini2018secret" class="csl-entry">
Carlini, N., Liu, C., Erlingsson, Ú., Kos, J., and Song, D. 2019. <span>“The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks.”</span> In <em>Proceedings of the 28th USENIX Conference on Security Symposium</em>, 267–284. SEC’19. USA: USENIX Association.
</div>
<div id="ref-Eibe2006" class="csl-entry">
Frank, E., and Bouckaert, R. R. 2006. <span>“Naive Bayes for Text Classification with Unbalanced Classes.”</span> In <em>Knowledge Discovery in Databases: PKDD 2006</em>, edited by Johannes Fürnkranz, Tobias Scheffer, and Myra Spiliopoulou, 503–510. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/11871637_49">https://doi.org/10.1007/11871637_49</a>.
</div>
<div id="ref-Fredrikson2015" class="csl-entry">
Fredrikson, Matt, Jha, S., and Ristenpart, T. 2015. <span>“Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures.”</span> In, 1322–1333. CCS ’15. New York, NY: Association for Computing Machinery. <a href="https://doi.org/10.1145/2810103.2813677">https://doi.org/10.1145/2810103.2813677</a>.
</div>
<div id="ref-Fredrikson2014" class="csl-entry">
Fredrikson, Matthew, Lantz, E., Jha, S., Lin, S., Page, D., and Ristenpart, T. 2014. <span>“Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing.”</span> In <em>Proceedings of the 23rd USENIX Conference on Security Symposium</em>, 17–32. SEC’14. USA: USENIX Association.
</div>
<div id="ref-R-themis" class="csl-entry">
Hvitfeldt, E. 2020d. <em><span class="nocase">themis</span>: Extra Recipe Steps for Dealing with Unbalanced Data</em>. R package version 0.1.4. <a href="https://CRAN.R-project.org/package=themis">https://CRAN.R-project.org/package=themis</a>.
</div>
<div id="ref-R-textfeatures" class="csl-entry">
Kearney, M. W. 2019. <em><span class="nocase">textfeatures</span>: Extracts Features from Text</em>. R package version 0.3.3. <a href="https://CRAN.R-project.org/package=textfeatures">https://CRAN.R-project.org/package=textfeatures</a>.
</div>
<div id="ref-Kibriya2005" class="csl-entry">
Kibriya, A. M., Frank, E., Pfahringer, B., and Holmes, G. 2005. <span>“Multinomial Naive Bayes for Text Categorization Revisited.”</span> In <em>AI 2004: Advances in Artificial Intelligence</em>, edited by Geoffrey I. Webb and Xinghuo Yu, 488–499. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-540-30549-1_43">https://doi.org/10.1007/978-3-540-30549-1_43</a>.
</div>
<div id="ref-kim2006" class="csl-entry">
Kim, S., Han, K., Rim, H., and Myaeng, S. H. 2006. <span>“Some Effective Techniques for Naive Bayes Text Classification.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 18 (11): 1457–1466. <a href="https://doi.org/10.1109/TKDE.2006.180">https://doi.org/10.1109/TKDE.2006.180</a>.
</div>
<div id="ref-R-dials" class="csl-entry">
Kuhn, M. 2020. <em><span class="nocase">dials</span>: Tools for Creating Tuning Parameter Values</em>. R package version 0.0.9. <a href="https://CRAN.R-project.org/package=dials">https://CRAN.R-project.org/package=dials</a>.
</div>
<div id="ref-R-parsnip" class="csl-entry">
Kuhn, M., and Vaughan, D. 2021b. <em><span class="nocase">parsnip</span>: A Common API to Modeling and Analysis Functions</em>. R package version 0.1.6. <a href="https://CRAN.R-project.org/package=parsnip">https://CRAN.R-project.org/package=parsnip</a>.
</div>
<div id="ref-Sweeney2000" class="csl-entry">
Sweeney, L. 2000. <em>Simple Demographics Often Identify People Uniquely</em>. Data Privacy Working Paper 3. Carnegie Mellon University. <a href="https://dataprivacylab.org/projects/identifiability/">https://dataprivacylab.org/projects/identifiability/</a>.
</div>
<div id="ref-Tibshirani1996" class="csl-entry">
Tibshirani, R. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 58 (1). [Royal Statistical Society, Wiley]: 267–288. <a href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</a>.
</div>
<div id="ref-R-hardhat" class="csl-entry">
Vaughan, D., and Kuhn, M. 2020. <em><span class="nocase">hardhat</span>: Construct Modeling Packages</em>. R package version 0.1.5. <a href="https://CRAN.R-project.org/package=hardhat">https://CRAN.R-project.org/package=hardhat</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>The censored trigrams that include “oh” seem mysterious but upon closer examination, they come from censored addresses, with “oh” representing the US state of Ohio. Most two-letter state abbreviations are censored, but this one is not since it is ambiguous. This highlights the real challenge of anonymizing text.<a href="mlclassification.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mlregression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dloverview.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": null,
"edit": {
"link": "https://github.com/EmilHvitfeldt/smltar/edit/master/07_ml_classification.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

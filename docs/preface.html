<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Preface | Supervised Machine Learning for Text Analysis in R</title>
  <meta name="description" content="Preface | Supervised Machine Learning for Text Analysis in R" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="Preface | Supervised Machine Learning for Text Analysis in R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://smltar.com" />
  <meta property="og:image" content="https://smltar.com/cover.jpg" />
  <meta property="og:description" content="Preface | Supervised Machine Learning for Text Analysis in R" />
  <meta name="github-repo" content="EmilHvitfeldt/smltar" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Preface | Supervised Machine Learning for Text Analysis in R" />
  
  <meta name="twitter:description" content="Preface | Supervised Machine Learning for Text Analysis in R" />
  <meta name="twitter:image" content="https://smltar.com/cover.jpg" />

<meta name="author" content="Emil Hvitfeldt and Julia Silge" />


<meta name="date" content="2021-10-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="language.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/plot_text_explanations-0.1.0/plot_text_explanations.css" rel="stylesheet" />
<script src="libs/plot_text_explanations-binding-0.5.2/plot_text_explanations.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="smltar.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Supervised Machine Learning for Text Analysis in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome to Supervised Machine Learning for Text Analysis in R</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#topics-this-book-will-not-cover"><i class="fa fa-check"></i>Topics this book will not cover</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who is this book for?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#colophon"><i class="fa fa-check"></i>Colophon</a></li>
</ul></li>
<li class="part"><span><b>I Natural Language Features</b></span></li>
<li class="chapter" data-level="1" data-path="language.html"><a href="language.html"><i class="fa fa-check"></i><b>1</b> Language and modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="language.html"><a href="language.html#linguistics-for-text-analysis"><i class="fa fa-check"></i><b>1.1</b> Linguistics for text analysis</a></li>
<li class="chapter" data-level="1.2" data-path="language.html"><a href="language.html#morphology"><i class="fa fa-check"></i><b>1.2</b> A glimpse into one area: morphology</a></li>
<li class="chapter" data-level="1.3" data-path="language.html"><a href="language.html#different-languages"><i class="fa fa-check"></i><b>1.3</b> Different languages</a></li>
<li class="chapter" data-level="1.4" data-path="language.html"><a href="language.html#other-ways-text-can-vary"><i class="fa fa-check"></i><b>1.4</b> Other ways text can vary</a></li>
<li class="chapter" data-level="1.5" data-path="language.html"><a href="language.html#languagesummary"><i class="fa fa-check"></i><b>1.5</b> Summary</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="language.html"><a href="language.html#in-this-chapter-you-learned"><i class="fa fa-check"></i><b>1.5.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tokenization.html"><a href="tokenization.html"><i class="fa fa-check"></i><b>2</b> Tokenization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tokenization.html"><a href="tokenization.html#what-is-a-token"><i class="fa fa-check"></i><b>2.1</b> What is a token?</a></li>
<li class="chapter" data-level="2.2" data-path="tokenization.html"><a href="tokenization.html#types-of-tokens"><i class="fa fa-check"></i><b>2.2</b> Types of tokens</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="tokenization.html"><a href="tokenization.html#character-tokens"><i class="fa fa-check"></i><b>2.2.1</b> Character tokens</a></li>
<li class="chapter" data-level="2.2.2" data-path="tokenization.html"><a href="tokenization.html#word-tokens"><i class="fa fa-check"></i><b>2.2.2</b> Word tokens</a></li>
<li class="chapter" data-level="2.2.3" data-path="tokenization.html"><a href="tokenization.html#tokenizingngrams"><i class="fa fa-check"></i><b>2.2.3</b> Tokenizing by n-grams</a></li>
<li class="chapter" data-level="2.2.4" data-path="tokenization.html"><a href="tokenization.html#lines-sentence-and-paragraph-tokens"><i class="fa fa-check"></i><b>2.2.4</b> Lines, sentence, and paragraph tokens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="tokenization.html"><a href="tokenization.html#where-does-tokenization-break-down"><i class="fa fa-check"></i><b>2.3</b> Where does tokenization break down?</a></li>
<li class="chapter" data-level="2.4" data-path="tokenization.html"><a href="tokenization.html#building-your-own-tokenizer"><i class="fa fa-check"></i><b>2.4</b> Building your own tokenizer</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="tokenization.html"><a href="tokenization.html#tokenize-to-characters-only-keeping-letters"><i class="fa fa-check"></i><b>2.4.1</b> Tokenize to characters, only keeping letters</a></li>
<li class="chapter" data-level="2.4.2" data-path="tokenization.html"><a href="tokenization.html#allow-for-hyphenated-words"><i class="fa fa-check"></i><b>2.4.2</b> Allow for hyphenated words</a></li>
<li class="chapter" data-level="2.4.3" data-path="tokenization.html"><a href="tokenization.html#wrapping-it-in-a-function"><i class="fa fa-check"></i><b>2.4.3</b> Wrapping it in a function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tokenization.html"><a href="tokenization.html#tokenization-for-non-latin-alphabets"><i class="fa fa-check"></i><b>2.5</b> Tokenization for non-Latin alphabets</a></li>
<li class="chapter" data-level="2.6" data-path="tokenization.html"><a href="tokenization.html#tokenization-benchmark"><i class="fa fa-check"></i><b>2.6</b> Tokenization benchmark</a></li>
<li class="chapter" data-level="2.7" data-path="tokenization.html"><a href="tokenization.html#tokensummary"><i class="fa fa-check"></i><b>2.7</b> Summary</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="tokenization.html"><a href="tokenization.html#in-this-chapter-you-learned-1"><i class="fa fa-check"></i><b>2.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stopwords.html"><a href="stopwords.html"><i class="fa fa-check"></i><b>3</b> Stop words</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stopwords.html"><a href="stopwords.html#premadestopwords"><i class="fa fa-check"></i><b>3.1</b> Using premade stop word lists</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="stopwords.html"><a href="stopwords.html#stop-word-removal-in-r"><i class="fa fa-check"></i><b>3.1.1</b> Stop word removal in R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="stopwords.html"><a href="stopwords.html#homemadestopwords"><i class="fa fa-check"></i><b>3.2</b> Creating your own stop words list</a></li>
<li class="chapter" data-level="3.3" data-path="stopwords.html"><a href="stopwords.html#all-stop-word-lists-are-context-specific"><i class="fa fa-check"></i><b>3.3</b> All stop word lists are context-specific</a></li>
<li class="chapter" data-level="3.4" data-path="stopwords.html"><a href="stopwords.html#what-happens-when-you-remove-stop-words"><i class="fa fa-check"></i><b>3.4</b> What happens when you remove stop words</a></li>
<li class="chapter" data-level="3.5" data-path="stopwords.html"><a href="stopwords.html#stop-words-in-languages-other-than-english"><i class="fa fa-check"></i><b>3.5</b> Stop words in languages other than English</a></li>
<li class="chapter" data-level="3.6" data-path="stopwords.html"><a href="stopwords.html#stopwordssummary"><i class="fa fa-check"></i><b>3.6</b> Summary</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="stopwords.html"><a href="stopwords.html#in-this-chapter-you-learned-2"><i class="fa fa-check"></i><b>3.6.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stemming.html"><a href="stemming.html"><i class="fa fa-check"></i><b>4</b> Stemming</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stemming.html"><a href="stemming.html#how-to-stem-text-in-r"><i class="fa fa-check"></i><b>4.1</b> How to stem text in R</a></li>
<li class="chapter" data-level="4.2" data-path="stemming.html"><a href="stemming.html#should-you-use-stemming-at-all"><i class="fa fa-check"></i><b>4.2</b> Should you use stemming at all?</a></li>
<li class="chapter" data-level="4.3" data-path="stemming.html"><a href="stemming.html#understand-a-stemming-algorithm"><i class="fa fa-check"></i><b>4.3</b> Understand a stemming algorithm</a></li>
<li class="chapter" data-level="4.4" data-path="stemming.html"><a href="stemming.html#handling-punctuation-when-stemming"><i class="fa fa-check"></i><b>4.4</b> Handling punctuation when stemming</a></li>
<li class="chapter" data-level="4.5" data-path="stemming.html"><a href="stemming.html#compare-some-stemming-options"><i class="fa fa-check"></i><b>4.5</b> Compare some stemming options</a></li>
<li class="chapter" data-level="4.6" data-path="stemming.html"><a href="stemming.html#lemmatization"><i class="fa fa-check"></i><b>4.6</b> Lemmatization and stemming</a></li>
<li class="chapter" data-level="4.7" data-path="stemming.html"><a href="stemming.html#stemming-and-stop-words"><i class="fa fa-check"></i><b>4.7</b> Stemming and stop words</a></li>
<li class="chapter" data-level="4.8" data-path="stemming.html"><a href="stemming.html#stemmingsummary"><i class="fa fa-check"></i><b>4.8</b> Summary</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="stemming.html"><a href="stemming.html#in-this-chapter-you-learned-3"><i class="fa fa-check"></i><b>4.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="embeddings.html"><a href="embeddings.html"><i class="fa fa-check"></i><b>5</b> Word Embeddings</a>
<ul>
<li class="chapter" data-level="5.1" data-path="embeddings.html"><a href="embeddings.html#motivatingsparse"><i class="fa fa-check"></i><b>5.1</b> Motivating embeddings for sparse, high-dimensional data</a></li>
<li class="chapter" data-level="5.2" data-path="embeddings.html"><a href="embeddings.html#understand-word-embeddings-by-finding-them-yourself"><i class="fa fa-check"></i><b>5.2</b> Understand word embeddings by finding them yourself</a></li>
<li class="chapter" data-level="5.3" data-path="embeddings.html"><a href="embeddings.html#exploring-cfpb-word-embeddings"><i class="fa fa-check"></i><b>5.3</b> Exploring CFPB word embeddings</a></li>
<li class="chapter" data-level="5.4" data-path="embeddings.html"><a href="embeddings.html#glove"><i class="fa fa-check"></i><b>5.4</b> Use pre-trained word embeddings</a></li>
<li class="chapter" data-level="5.5" data-path="embeddings.html"><a href="embeddings.html#fairnessembeddings"><i class="fa fa-check"></i><b>5.5</b> Fairness and word embeddings</a></li>
<li class="chapter" data-level="5.6" data-path="embeddings.html"><a href="embeddings.html#using-word-embeddings-in-the-real-world"><i class="fa fa-check"></i><b>5.6</b> Using word embeddings in the real world</a></li>
<li class="chapter" data-level="5.7" data-path="embeddings.html"><a href="embeddings.html#embeddingssummary"><i class="fa fa-check"></i><b>5.7</b> Summary</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="embeddings.html"><a href="embeddings.html#in-this-chapter-you-learned-4"><i class="fa fa-check"></i><b>5.7.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Machine Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#should-we-even-be-doing-this"><i class="fa fa-check"></i>Should we even be doing this?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-bias-is-already-in-the-data"><i class="fa fa-check"></i>What bias is already in the data?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#can-the-code-and-data-be-audited"><i class="fa fa-check"></i>Can the code and data be audited?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-are-the-error-rates-for-sub-groups"><i class="fa fa-check"></i>What are the error rates for sub-groups?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-is-the-accuracy-of-a-simple-rule-based-alternative"><i class="fa fa-check"></i>What is the accuracy of a simple rule-based alternative?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#what-processes-are-in-place-to-handle-appeals-or-mistakes"><i class="fa fa-check"></i>What processes are in place to handle appeals or mistakes?</a></li>
<li class="chapter" data-level="" data-path="mloverview.html"><a href="mloverview.html#how-diverse-is-the-team-that-built-it"><i class="fa fa-check"></i>How diverse is the team that built it?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mlregression.html"><a href="mlregression.html"><i class="fa fa-check"></i><b>6</b> Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mlregression.html"><a href="mlregression.html#firstmlregression"><i class="fa fa-check"></i><b>6.1</b> A first regression model</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="mlregression.html"><a href="mlregression.html#firstregression"><i class="fa fa-check"></i><b>6.1.1</b> Building our first regression model</a></li>
<li class="chapter" data-level="6.1.2" data-path="mlregression.html"><a href="mlregression.html#firstregressionevaluation"><i class="fa fa-check"></i><b>6.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="mlregression.html"><a href="mlregression.html#regnull"><i class="fa fa-check"></i><b>6.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="6.3" data-path="mlregression.html"><a href="mlregression.html#comparerf"><i class="fa fa-check"></i><b>6.3</b> Compare to a random forest model</a></li>
<li class="chapter" data-level="6.4" data-path="mlregression.html"><a href="mlregression.html#casestudystopwords"><i class="fa fa-check"></i><b>6.4</b> Case study: removing stop words</a></li>
<li class="chapter" data-level="6.5" data-path="mlregression.html"><a href="mlregression.html#casestudyngrams"><i class="fa fa-check"></i><b>6.5</b> Case study: varying n-grams</a></li>
<li class="chapter" data-level="6.6" data-path="mlregression.html"><a href="mlregression.html#mlregressionlemmatization"><i class="fa fa-check"></i><b>6.6</b> Case study: lemmatization</a></li>
<li class="chapter" data-level="6.7" data-path="mlregression.html"><a href="mlregression.html#case-study-feature-hashing"><i class="fa fa-check"></i><b>6.7</b> Case study: feature hashing</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="mlregression.html"><a href="mlregression.html#text-normalization"><i class="fa fa-check"></i><b>6.7.1</b> Text normalization</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="mlregression.html"><a href="mlregression.html#what-evaluation-metrics-are-appropriate"><i class="fa fa-check"></i><b>6.8</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="6.9" data-path="mlregression.html"><a href="mlregression.html#mlregressionfull"><i class="fa fa-check"></i><b>6.9</b> The full game: regression</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="mlregression.html"><a href="mlregression.html#preprocess-the-data"><i class="fa fa-check"></i><b>6.9.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="6.9.2" data-path="mlregression.html"><a href="mlregression.html#specify-the-model"><i class="fa fa-check"></i><b>6.9.2</b> Specify the model</a></li>
<li class="chapter" data-level="6.9.3" data-path="mlregression.html"><a href="mlregression.html#tune-the-model"><i class="fa fa-check"></i><b>6.9.3</b> Tune the model</a></li>
<li class="chapter" data-level="6.9.4" data-path="mlregression.html"><a href="mlregression.html#regression-final-evaluation"><i class="fa fa-check"></i><b>6.9.4</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="mlregression.html"><a href="mlregression.html#mlregressionsummary"><i class="fa fa-check"></i><b>6.10</b> Summary</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="mlregression.html"><a href="mlregression.html#in-this-chapter-you-learned-5"><i class="fa fa-check"></i><b>6.10.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mlclassification.html"><a href="mlclassification.html"><i class="fa fa-check"></i><b>7</b> Classification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstattemptlookatdata"><i class="fa fa-check"></i><b>7.1</b> A first classification model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="mlclassification.html"><a href="mlclassification.html#classfirstmodel"><i class="fa fa-check"></i><b>7.1.1</b> Building our first classification model</a></li>
<li class="chapter" data-level="7.1.2" data-path="mlclassification.html"><a href="mlclassification.html#evaluation"><i class="fa fa-check"></i><b>7.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="mlclassification.html"><a href="mlclassification.html#classnull"><i class="fa fa-check"></i><b>7.2</b> Compare to the null model</a></li>
<li class="chapter" data-level="7.3" data-path="mlclassification.html"><a href="mlclassification.html#comparetolasso"><i class="fa fa-check"></i><b>7.3</b> Compare to a lasso classification model</a></li>
<li class="chapter" data-level="7.4" data-path="mlclassification.html"><a href="mlclassification.html#tunelasso"><i class="fa fa-check"></i><b>7.4</b> Tuning lasso hyperparameters</a></li>
<li class="chapter" data-level="7.5" data-path="mlclassification.html"><a href="mlclassification.html#casestudysparseencoding"><i class="fa fa-check"></i><b>7.5</b> Case study: sparse encoding</a></li>
<li class="chapter" data-level="7.6" data-path="mlclassification.html"><a href="mlclassification.html#mlmulticlass"><i class="fa fa-check"></i><b>7.6</b> Two-class or multiclass?</a></li>
<li class="chapter" data-level="7.7" data-path="mlclassification.html"><a href="mlclassification.html#case-study-including-non-text-data"><i class="fa fa-check"></i><b>7.7</b> Case study: including non-text data</a></li>
<li class="chapter" data-level="7.8" data-path="mlclassification.html"><a href="mlclassification.html#case-study-data-censoring"><i class="fa fa-check"></i><b>7.8</b> Case study: data censoring</a></li>
<li class="chapter" data-level="7.9" data-path="mlclassification.html"><a href="mlclassification.html#customfeatures"><i class="fa fa-check"></i><b>7.9</b> Case study: custom features</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="mlclassification.html"><a href="mlclassification.html#detect-credit-cards"><i class="fa fa-check"></i><b>7.9.1</b> Detect credit cards</a></li>
<li class="chapter" data-level="7.9.2" data-path="mlclassification.html"><a href="mlclassification.html#calculate-percentage-censoring"><i class="fa fa-check"></i><b>7.9.2</b> Calculate percentage censoring</a></li>
<li class="chapter" data-level="7.9.3" data-path="mlclassification.html"><a href="mlclassification.html#detect-monetary-amounts"><i class="fa fa-check"></i><b>7.9.3</b> Detect monetary amounts</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="mlclassification.html"><a href="mlclassification.html#what-evaluation-metrics-are-appropriate-1"><i class="fa fa-check"></i><b>7.10</b> What evaluation metrics are appropriate?</a></li>
<li class="chapter" data-level="7.11" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationfull"><i class="fa fa-check"></i><b>7.11</b> The full game: classification</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="mlclassification.html"><a href="mlclassification.html#feature-selection"><i class="fa fa-check"></i><b>7.11.1</b> Feature selection</a></li>
<li class="chapter" data-level="7.11.2" data-path="mlclassification.html"><a href="mlclassification.html#specify-the-model-1"><i class="fa fa-check"></i><b>7.11.2</b> Specify the model</a></li>
<li class="chapter" data-level="7.11.3" data-path="mlclassification.html"><a href="mlclassification.html#classification-final-evaluation"><i class="fa fa-check"></i><b>7.11.3</b> Evaluate the modeling</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="mlclassification.html"><a href="mlclassification.html#mlclassificationsummary"><i class="fa fa-check"></i><b>7.12</b> Summary</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="mlclassification.html"><a href="mlclassification.html#in-this-chapter-you-learned-6"><i class="fa fa-check"></i><b>7.12.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Deep Learning Methods</b></span></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#spending-your-data-budget"><i class="fa fa-check"></i>Spending your data budget</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#feature-engineering"><i class="fa fa-check"></i>Feature engineering</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#fitting-and-tuning"><i class="fa fa-check"></i>Fitting and tuning</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#model-evaluation"><i class="fa fa-check"></i>Model evaluation</a></li>
<li class="chapter" data-level="" data-path="dloverview.html"><a href="dloverview.html#putting-the-model-process-in-context"><i class="fa fa-check"></i>Putting the model process in context</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="dldnn.html"><a href="dldnn.html"><i class="fa fa-check"></i><b>8</b> Dense neural networks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dldnn.html"><a href="dldnn.html#kickstarter"><i class="fa fa-check"></i><b>8.1</b> Kickstarter data</a></li>
<li class="chapter" data-level="8.2" data-path="dldnn.html"><a href="dldnn.html#firstdlclassification"><i class="fa fa-check"></i><b>8.2</b> A first deep learning model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="dldnn.html"><a href="dldnn.html#dnnrecipe"><i class="fa fa-check"></i><b>8.2.1</b> Preprocessing for deep learning</a></li>
<li class="chapter" data-level="8.2.2" data-path="dldnn.html"><a href="dldnn.html#onehotsequence"><i class="fa fa-check"></i><b>8.2.2</b> One-hot sequence embedding of text</a></li>
<li class="chapter" data-level="8.2.3" data-path="dldnn.html"><a href="dldnn.html#simple-flattened-dense-network"><i class="fa fa-check"></i><b>8.2.3</b> Simple flattened dense network</a></li>
<li class="chapter" data-level="8.2.4" data-path="dldnn.html"><a href="dldnn.html#evaluate-dnn"><i class="fa fa-check"></i><b>8.2.4</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="dldnn.html"><a href="dldnn.html#using-bag-of-words-features"><i class="fa fa-check"></i><b>8.3</b> Using bag-of-words features</a></li>
<li class="chapter" data-level="8.4" data-path="dldnn.html"><a href="dldnn.html#using-pre-trained-word-embeddings"><i class="fa fa-check"></i><b>8.4</b> Using pre-trained word embeddings</a></li>
<li class="chapter" data-level="8.5" data-path="dldnn.html"><a href="dldnn.html#dnncross"><i class="fa fa-check"></i><b>8.5</b> Cross-validation for deep learning models</a></li>
<li class="chapter" data-level="8.6" data-path="dldnn.html"><a href="dldnn.html#compare-and-evaluate-dnn-models"><i class="fa fa-check"></i><b>8.6</b> Compare and evaluate DNN models</a></li>
<li class="chapter" data-level="8.7" data-path="dldnn.html"><a href="dldnn.html#dllimitations"><i class="fa fa-check"></i><b>8.7</b> Limitations of deep learning</a></li>
<li class="chapter" data-level="8.8" data-path="dldnn.html"><a href="dldnn.html#dldnnsummary"><i class="fa fa-check"></i><b>8.8</b> Summary</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="dldnn.html"><a href="dldnn.html#in-this-chapter-you-learned-7"><i class="fa fa-check"></i><b>8.8.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dllstm.html"><a href="dllstm.html"><i class="fa fa-check"></i><b>9</b> Long short-term memory (LSTM) networks</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dllstm.html"><a href="dllstm.html#firstlstm"><i class="fa fa-check"></i><b>9.1</b> A first LSTM model</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="dllstm.html"><a href="dllstm.html#building-an-lstm"><i class="fa fa-check"></i><b>9.1.1</b> Building an LSTM</a></li>
<li class="chapter" data-level="9.1.2" data-path="dllstm.html"><a href="dllstm.html#lstmevaluation"><i class="fa fa-check"></i><b>9.1.2</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="dllstm.html"><a href="dllstm.html#compare-to-a-recurrent-neural-network"><i class="fa fa-check"></i><b>9.2</b> Compare to a recurrent neural network</a></li>
<li class="chapter" data-level="9.3" data-path="dllstm.html"><a href="dllstm.html#bilstm"><i class="fa fa-check"></i><b>9.3</b> Case study: bidirectional LSTM</a></li>
<li class="chapter" data-level="9.4" data-path="dllstm.html"><a href="dllstm.html#case-study-stacking-lstm-layers"><i class="fa fa-check"></i><b>9.4</b> Case study: stacking LSTM layers</a></li>
<li class="chapter" data-level="9.5" data-path="dllstm.html"><a href="dllstm.html#lstmpadding"><i class="fa fa-check"></i><b>9.5</b> Case study: padding</a></li>
<li class="chapter" data-level="9.6" data-path="dllstm.html"><a href="dllstm.html#case-study-training-a-regression-model"><i class="fa fa-check"></i><b>9.6</b> Case study: training a regression model</a></li>
<li class="chapter" data-level="9.7" data-path="dllstm.html"><a href="dllstm.html#case-study-vocabulary-size"><i class="fa fa-check"></i><b>9.7</b> Case study: vocabulary size</a></li>
<li class="chapter" data-level="9.8" data-path="dllstm.html"><a href="dllstm.html#lstmfull"><i class="fa fa-check"></i><b>9.8</b> The full game: LSTM</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="dllstm.html"><a href="dllstm.html#lstmfullpreprocess"><i class="fa fa-check"></i><b>9.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="9.8.2" data-path="dllstm.html"><a href="dllstm.html#lstmfullmodel"><i class="fa fa-check"></i><b>9.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="dllstm.html"><a href="dllstm.html#dllstmsummary"><i class="fa fa-check"></i><b>9.9</b> Summary</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="dllstm.html"><a href="dllstm.html#in-this-chapter-you-learned-8"><i class="fa fa-check"></i><b>9.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dlcnn.html"><a href="dlcnn.html"><i class="fa fa-check"></i><b>10</b> Convolutional neural networks</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dlcnn.html"><a href="dlcnn.html#what-are-cnns"><i class="fa fa-check"></i><b>10.1</b> What are CNNs?</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="dlcnn.html"><a href="dlcnn.html#kernel"><i class="fa fa-check"></i><b>10.1.1</b> Kernel</a></li>
<li class="chapter" data-level="10.1.2" data-path="dlcnn.html"><a href="dlcnn.html#kernel-size"><i class="fa fa-check"></i><b>10.1.2</b> Kernel size</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="dlcnn.html"><a href="dlcnn.html#firstcnn"><i class="fa fa-check"></i><b>10.2</b> A first CNN model</a></li>
<li class="chapter" data-level="10.3" data-path="dlcnn.html"><a href="dlcnn.html#case-study-adding-more-layers"><i class="fa fa-check"></i><b>10.3</b> Case study: adding more layers</a></li>
<li class="chapter" data-level="10.4" data-path="dlcnn.html"><a href="dlcnn.html#case-study-byte-pair-encoding"><i class="fa fa-check"></i><b>10.4</b> Case study: byte pair encoding</a></li>
<li class="chapter" data-level="10.5" data-path="dlcnn.html"><a href="dlcnn.html#lime"><i class="fa fa-check"></i><b>10.5</b> Case study: explainability with LIME</a></li>
<li class="chapter" data-level="10.6" data-path="dlcnn.html"><a href="dlcnn.html#keras-hyperparameter"><i class="fa fa-check"></i><b>10.6</b> Case study: hyperparameter search</a></li>
<li class="chapter" data-level="10.7" data-path="dlcnn.html"><a href="dlcnn.html#cross-validation-for-evaluation"><i class="fa fa-check"></i><b>10.7</b> Cross-validation for evaluation</a></li>
<li class="chapter" data-level="10.8" data-path="dlcnn.html"><a href="dlcnn.html#cnnfull"><i class="fa fa-check"></i><b>10.8</b> The full game: CNN</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullpreprocess"><i class="fa fa-check"></i><b>10.8.1</b> Preprocess the data</a></li>
<li class="chapter" data-level="10.8.2" data-path="dlcnn.html"><a href="dlcnn.html#cnnfullmodel"><i class="fa fa-check"></i><b>10.8.2</b> Specify the model</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="dlcnn.html"><a href="dlcnn.html#dlcnnsummary"><i class="fa fa-check"></i><b>10.9</b> Summary</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="dlcnn.html"><a href="dlcnn.html#in-this-chapter-you-learned-9"><i class="fa fa-check"></i><b>10.9.1</b> In this chapter, you learned:</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="" data-path="text-models-in-the-real-world.html"><a href="text-models-in-the-real-world.html"><i class="fa fa-check"></i>Text models in the real world</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="regexp.html"><a href="regexp.html"><i class="fa fa-check"></i><b>A</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="A.1" data-path="regexp.html"><a href="regexp.html#literal-characters"><i class="fa fa-check"></i><b>A.1</b> Literal characters</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="regexp.html"><a href="regexp.html#meta-characters"><i class="fa fa-check"></i><b>A.1.1</b> Meta characters</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="regexp.html"><a href="regexp.html#full-stop-the-wildcard"><i class="fa fa-check"></i><b>A.2</b> Full stop, the wildcard</a></li>
<li class="chapter" data-level="A.3" data-path="regexp.html"><a href="regexp.html#character-classes"><i class="fa fa-check"></i><b>A.3</b> Character classes</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="regexp.html"><a href="regexp.html#shorthand-character-classes"><i class="fa fa-check"></i><b>A.3.1</b> Shorthand character classes</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="regexp.html"><a href="regexp.html#quantifiers"><i class="fa fa-check"></i><b>A.4</b> Quantifiers</a></li>
<li class="chapter" data-level="A.5" data-path="regexp.html"><a href="regexp.html#anchors"><i class="fa fa-check"></i><b>A.5</b> Anchors</a></li>
<li class="chapter" data-level="A.6" data-path="regexp.html"><a href="regexp.html#additional-resources"><i class="fa fa-check"></i><b>A.6</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixdata.html"><a href="appendixdata.html"><i class="fa fa-check"></i><b>B</b> Data</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixdata.html"><a href="appendixdata.html#hcandersen"><i class="fa fa-check"></i><b>B.1</b> Hans Christian Andersen fairy tales</a></li>
<li class="chapter" data-level="B.2" data-path="appendixdata.html"><a href="appendixdata.html#scotus-opinions"><i class="fa fa-check"></i><b>B.2</b> Opinions of the Supreme Court of the United States</a></li>
<li class="chapter" data-level="B.3" data-path="appendixdata.html"><a href="appendixdata.html#cfpb-complaints"><i class="fa fa-check"></i><b>B.3</b> Consumer Financial Protection Bureau (CFPB) complaints</a></li>
<li class="chapter" data-level="B.4" data-path="appendixdata.html"><a href="appendixdata.html#kickstarter-blurbs"><i class="fa fa-check"></i><b>B.4</b> Kickstarter campaign blurbs</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appendixbaseline.html"><a href="appendixbaseline.html"><i class="fa fa-check"></i><b>C</b> Baseline linear classifier</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appendixbaseline.html"><a href="appendixbaseline.html#read-in-the-data"><i class="fa fa-check"></i><b>C.1</b> Read in the data</a></li>
<li class="chapter" data-level="C.2" data-path="appendixbaseline.html"><a href="appendixbaseline.html#split-into-testtrain-and-create-resampling-folds"><i class="fa fa-check"></i><b>C.2</b> Split into test/train and create resampling folds</a></li>
<li class="chapter" data-level="C.3" data-path="appendixbaseline.html"><a href="appendixbaseline.html#recipe-for-data-preprocessing"><i class="fa fa-check"></i><b>C.3</b> Recipe for data preprocessing</a></li>
<li class="chapter" data-level="C.4" data-path="appendixbaseline.html"><a href="appendixbaseline.html#lasso-regularized-classification-model"><i class="fa fa-check"></i><b>C.4</b> Lasso regularized classification model</a></li>
<li class="chapter" data-level="C.5" data-path="appendixbaseline.html"><a href="appendixbaseline.html#a-model-workflow"><i class="fa fa-check"></i><b>C.5</b> A model workflow</a></li>
<li class="chapter" data-level="C.6" data-path="appendixbaseline.html"><a href="appendixbaseline.html#tune-the-workflow"><i class="fa fa-check"></i><b>C.6</b> Tune the workflow</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supervised Machine Learning for Text Analysis in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<p>Modeling as a statistical practice can encompass a wide variety of activities. This book focuses on <em>supervised or predictive modeling for text</em>, using text data to make predictions about the world around us. We use the <a href="https://www.tidymodels.org/">tidymodels</a> framework for modeling, a consistent and flexible collection of R packages developed to encourage good statistical practice.</p>
<p>Supervised machine learning using text data involves building a statistical model to estimate some output from input that includes language. The two types of models we train in this book are regression and classification. Think of regression models as predicting numeric or continuous outputs, such as predicting the year of a United States Supreme Court opinion from the text of that opinion. Think of classification models as predicting outputs that are discrete quantities or class labels, such as predicting whether a GitHub issue is about documentation or not from the text of the issue. Models like these can be used to make predictions for new observations, to understand what features or characteristics contribute to differences in the output, and more. We can evaluate our models using performance metrics to determine which are best, which are acceptable for our specific context, and even which are fair.</p>
<div class="rmdnote">
<p>
Text data is important for many domains, from healthcare to marketing to the digital humanities, but specialized approaches are necessary to create features (predictors) for machine learning from language.
</p>
</div>
<p>Natural language that we as speakers and/or writers use must be dramatically transformed to a machine-readable, numeric representation to be ready for computation. In this book, we explore typical text preprocessing steps from the ground up and consider the effects of these steps. We also show how to fluently use the <strong>textrecipes</strong> R package <span class="citation">(<a href="#ref-textrecipes" role="doc-biblioref">Hvitfeldt 2020a</a>)</span> to prepare text data within a modeling pipeline.</p>
<p><span class="citation"><a href="#ref-Silge2017" role="doc-biblioref">Silge and Robinson</a> (<a href="#ref-Silge2017" role="doc-biblioref">2017</a>)</span> provides a practical introduction to text mining with R using tidy data principles, based on the <strong>tidytext</strong> package. If you have already started on the path of gaining insight from your text data, a next step is using that text directly in predictive modeling. Text data contains within it latent information that can be used for insight, understanding, and better decision-making, and predictive modeling with text can bring that information and insight to light. If you have already explored how to analyze text as demonstrated in <span class="citation"><a href="#ref-Silge2017" role="doc-biblioref">Silge and Robinson</a> (<a href="#ref-Silge2017" role="doc-biblioref">2017</a>)</span>, this book will move one step further to show you how to <em>learn and make predictions</em> from that text data with supervised models. If you are unfamiliar with this previous work, this book will still provide a robust introduction to how text can be represented in useful ways for modeling and a diverse set of supervised modeling approaches for text.</p>
<div id="outline" class="section level2 unnumbered">
<h2>Outline</h2>
<p>The book is divided into three sections. We make a (perhaps arbitrary) distinction between <em>machine learning methods</em> and <em>deep learning methods</em> by defining deep learning as any kind of multilayer neural network (LSTM, bi-LSTM, CNN) and machine learning as anything else (regularized regression, naive Bayes, SVM, random forest). We make this distinction both because these different methods use separate software packages and modeling infrastructure, and from a pragmatic point of view, it is helpful to split up the chapters this way.</p>
<ul>
<li><p><strong>Natural language features:</strong> How do we transform text data into a representation useful for modeling? In these chapters, we explore the most common preprocessing steps for text, when they are helpful, and when they are not.</p></li>
<li><p><strong>Machine learning methods:</strong> We investigate the power of some of the simpler and more lightweight models in our toolbox.</p></li>
<li><p><strong>Deep learning methods:</strong> Given more time and resources, we see what is possible once we turn to neural networks.</p></li>
</ul>
<p>Some of the topics in the second and third sections overlap as they provide different approaches to the same tasks.</p>
<p>Throughout the book, we will demonstrate with examples and build models using a selection of text data sets. A description of these data sets can be found in Appendix <a href="appendixdata.html#appendixdata">B</a>.</p>
<div class="rmdnote">
<p>
We use three kinds of info boxes throughout the book to invite attention to notes and other ideas.
</p>
</div>
<div class="rmdwarning">
<p>
Some boxes call out warnings or possible problems to watch out for.
</p>
</div>
<div class="rmdpackage">
<p>
Boxes marked with hexagons highlight information about specific R packages and how they are used. We use <strong>bold</strong> for the names of R packages.
</p>
</div>
</div>
<div id="topics-this-book-will-not-cover" class="section level2 unnumbered">
<h2>Topics this book will not cover</h2>
<p>This book serves as a thorough introduction to prediction and modeling with text, along with detailed practical examples, but there are many areas of natural language processing we do not cover. The <a href="https://cran.r-project.org/web/views/NaturalLanguageProcessing.html"><em>CRAN Task View on Natural Language Processing</em></a> provides details on other ways to use R for computational linguistics. Specific topics we do not cover include:</p>
<ul>
<li><p><strong>Reading text data into memory:</strong> Text data may come to a data practitioner in any of a long list of heterogeneous formats. Text data exists in PDFs, databases, plain text files (single or multiple for a given project), websites, APIs, literal paper, and more. The skills needed to access and sometimes wrangle text data sets so that they are in memory and ready for analysis are so varied and extensive that we cannot hope to cover them in this book. We point readers to R packages such as <strong>readr</strong> <span class="citation">(<a href="#ref-R-readr" role="doc-biblioref">Wickham and Hester 2020</a>)</span>, <strong>pdftools</strong> <span class="citation">(<a href="#ref-R-pdftools" role="doc-biblioref">Ooms 2020a</a>)</span>, and <strong>httr</strong> <span class="citation">(<a href="#ref-R-httr" role="doc-biblioref">Wickham 2020</a>)</span>, which we have found helpful in these tasks.</p></li>
<li><p><strong>Unsupervised machine learning for text:</strong> <span class="citation"><a href="#ref-Silge2017" role="doc-biblioref">Silge and Robinson</a> (<a href="#ref-Silge2017" role="doc-biblioref">2017</a>)</span> provide an introduction to one method of unsupervised text modeling, and Chapter <a href="embeddings.html#embeddings">5</a> does dive deep into word embeddings, which learn from the latent structure in text data. However, many more unsupervised machine learning algorithms can be used for the goal of learning about the structure or distribution of text data when there are no outcome or output variables to predict.</p></li>
<li><p><strong>Text generation:</strong> The deep learning model architectures we discuss in Chapters <a href="dldnn.html#dldnn">8</a>, <a href="dllstm.html#dllstm">9</a>, and <a href="dlcnn.html#dlcnn">10</a> can be used to generate new text, as well as to model existing text. <span class="citation"><a href="#ref-Chollet2018" role="doc-biblioref">Chollet and Allaire</a> (<a href="#ref-Chollet2018" role="doc-biblioref">2018</a>)</span> provide details on how to use neural network architectures and training data for text generation.</p></li>
<li><p><strong>Speech processing:</strong> Models that detect words in audio recordings of speech are typically based on many of the principles outlined in this book, but the training data is <em>audio</em> rather than written text. R users can access pre-trained speech-to-text models via large cloud providers, such as Google Cloud’s Speech-to-Text API accessible in R through the <strong>googleLanguageR</strong> package <span class="citation">(<a href="#ref-R-googleLanguageR" role="doc-biblioref">Edmondson 2020</a>)</span>.</p></li>
<li><p><strong>Machine translation:</strong> Machine translation of text between languages, based on either older statistical methods or newer neural network methods, is a complex, involved topic. Today, the most successful and well-known implementations of machine translation are proprietary, because large tech companies have access to both the right expertise and enough data in multiple languages to train successful models for general machine translation. Google is one such example, and Google Cloud’s Translation API is again available in R through the <strong>googleLanguageR</strong> package.</p></li>
</ul>
</div>
<div id="who-is-this-book-for" class="section level2 unnumbered">
<h2>Who is this book for?</h2>
<p>This book is designed to provide practical guidance and directly applicable knowledge for data scientists and analysts who want to integrate text into their modeling pipelines.</p>
<p>We assume that the reader is somewhat familiar with R, predictive modeling concepts for non-text data, and the <a href="https://www.tidyverse.org/"><strong>tidyverse</strong></a> family of packages <span class="citation">(<a href="#ref-Wickham2019" role="doc-biblioref">Wickham et al. 2019</a>)</span>. For users who don’t have this background with tidyverse code, we recommend <a href="http://r4ds.had.co.nz/"><em>R for Data Science</em></a> <span class="citation">(<a href="#ref-Wickham2017" role="doc-biblioref">Wickham and Grolemund 2017</a>)</span>. Helpful resources for getting started with modeling and machine learning include a <a href="https://supervised-ml-course.netlify.com/">free interactive course</a> developed by one of the authors (JS) and <a href="https://bradleyboehmke.github.io/HOML/"><em>Hands-On Machine Learning with R</em></a> <span class="citation">(<a href="#ref-Boehmke2019" role="doc-biblioref">Boehmke and Greenwell 2019</a>)</span>, as well as <a href="http://faculty.marshall.usc.edu/gareth-james/ISL/"><em>An Introduction to Statistical Learning</em></a> <span class="citation">(<a href="#ref-James2013" role="doc-biblioref">James et al. 2013</a>)</span>.</p>
<p>We don’t assume an extensive background in text analysis, but <a href="https://www.tidytextmining.com/"><em>Text Mining with R</em></a> <span class="citation">(<a href="#ref-Silge2017" role="doc-biblioref">Silge and Robinson 2017</a>)</span>, by one of the authors (JS) and David Robinson, provides helpful skills in exploratory data analysis for text that will promote successful text modeling. This book is more advanced than <em>Text Mining with R</em> and will help practitioners use their text data in ways not covered in that book.</p>
</div>
<div id="acknowledgments" class="section level2 unnumbered">
<h2>Acknowledgments</h2>
<p>We are so thankful for the contributions, help, and perspectives of people who have supported us in this project. There are several we would like to thank in particular.</p>
<p>We would like to thank Max Kuhn and Davis Vaughan for their investment in the <strong>tidymodels</strong> packages, David Robinson for his collaboration on the <strong>tidytext</strong> package, and Yihui Xie for his work on <strong>knitr</strong>, <strong>bookdown</strong>, and the R Markdown ecosystem. Thank you to Desirée De Leon for the site design of the online work and to Sarah Lin for the expert creation of the published work’s index. We would also like to thank Carol Haney, Kasia Kulma, David Mimno, Kanishka Misra, and an additional anonymous technical reviewer for their detailed, insightful feedback that substantively improved this book, as well as our editor John Kimmel for his perspective and guidance during the process of writing and publishing.</p>
<p>This book was written in the open, and multiple people contributed via pull requests or issues. Special thanks goes to the four people who contributed via GitHub pull requests (in alphabetical order by username): @fellennert, Riva Quiroga (@rivaquiroga), Darrin Speegle (@speegled), Tanner Stauss (@tmstauss).</p>
<p>Note box icons by Smashicons from flaticon.com.</p>
</div>
<div id="colophon" class="section level2 unnumbered">
<h2>Colophon</h2>
<p>This book was written in <a href="https://www.rstudio.com/ide/">RStudio</a> using <a href="https://bookdown.org"><strong>bookdown</strong></a>. The <a href="https://smltar.com">website</a> is hosted via <a href="https://pages.github.com">GitHub Pages</a>, and the complete source is available on <a href="https://github.com/EmilHvitfeldt/smltar">GitHub</a>. We generated all plots in this book using <a href="https://ggplot2.tidyverse.org"><strong>ggplot2</strong></a> and its light theme (<code>theme_light()</code>). The <code>autoplot()</code> method for <a href="https://yardstick.tidymodels.org/reference/conf_mat.html"><code>conf_mat()</code></a> has been modified slightly to allow colors; modified code can be found <a href="https://github.com/EmilHvitfeldt/smltar/blob/master/_common.R">online</a>.</p>
<p>This version of the book was built with R version 4.1.0 (2021-05-18) and the following packages:</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
<th align="left">source</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bench</td>
<td align="left">1.1.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">bookdown</td>
<td align="left">0.23</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">broom</td>
<td align="left">0.7.9</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">corpus</td>
<td align="left">0.10.2</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">dials</td>
<td align="left">0.0.9</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">discrim</td>
<td align="left">0.1.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">doParallel</td>
<td align="left">1.0.16</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">glmnet</td>
<td align="left">4.1-1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">gt</td>
<td align="left">0.3.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">hcandersenr</td>
<td align="left">0.2.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">htmltools</td>
<td align="left">0.5.1.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">htmlwidgets</td>
<td align="left">1.5.3</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">hunspell</td>
<td align="left">3.0.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">irlba</td>
<td align="left">2.3.3</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">jiebaR</td>
<td align="left">0.11</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">jsonlite</td>
<td align="left">1.7.2</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">kableExtra</td>
<td align="left">1.3.4</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">keras</td>
<td align="left">2.4.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">klaR</td>
<td align="left">0.6-15</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">LiblineaR</td>
<td align="left">2.10-12</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">lime</td>
<td align="left">0.5.2</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">lobstr</td>
<td align="left">1.1.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">naivebayes</td>
<td align="left">0.9.7</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">parsnip</td>
<td align="left">0.1.6</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">prismatic</td>
<td align="left">1.0.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">quanteda</td>
<td align="left">3.1.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">ranger</td>
<td align="left">0.13.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">recipes</td>
<td align="left">0.1.16</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">remotes</td>
<td align="left">2.4.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">reticulate</td>
<td align="left">1.20</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">rsample</td>
<td align="left">0.1.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">rsparse</td>
<td align="left">0.4.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">scico</td>
<td align="left">1.2.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">scotus</td>
<td align="left">1.0.0</td>
<td align="left">Github (EmilHvitfeldt/scotus)</td>
</tr>
<tr class="odd">
<td align="left">servr</td>
<td align="left">0.23</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">sessioninfo</td>
<td align="left">1.1.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">slider</td>
<td align="left">0.2.2</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">SnowballC</td>
<td align="left">0.7.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">spacyr</td>
<td align="left">1.2.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">stopwords</td>
<td align="left">2.2</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">styler</td>
<td align="left">1.5.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">text2vec</td>
<td align="left">0.6</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">textdata</td>
<td align="left">0.4.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">textfeatures</td>
<td align="left">0.3.3</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">textrecipes</td>
<td align="left">0.4.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">tfruns</td>
<td align="left">1.5.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">themis</td>
<td align="left">0.1.4</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">tidymodels</td>
<td align="left">0.1.3</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">tidytext</td>
<td align="left">0.3.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">tidyverse</td>
<td align="left">1.3.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">tokenizers</td>
<td align="left">0.2.1</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">tokenizers.bpe</td>
<td align="left">0.1.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">tufte</td>
<td align="left">0.10</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">tune</td>
<td align="left">0.1.5</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">UpSetR</td>
<td align="left">1.4.0</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">vip</td>
<td align="left">0.3.2</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">widyr</td>
<td align="left">0.1.4</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="even">
<td align="left">workflows</td>
<td align="left">0.2.3</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
<tr class="odd">
<td align="left">yardstick</td>
<td align="left">0.0.8</td>
<td align="left">CRAN (R 4.1.0)</td>
</tr>
</tbody>
</table>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Boehmke2019" class="csl-entry">
Boehmke, B., and Greenwell, B. M. 2019. <em><span class="nocase">Hands-on Machine Learning with R</span></em>. Boca Raton: CRC Press.
</div>
<div id="ref-Chollet2018" class="csl-entry">
Chollet, F., and Allaire, J. J. 2018. <em>Deep Learning with <span>R</span></em>. Shelter Island, NY: Manning Publications. <a href="https://www.manning.com/books/deep-learning-with-r">https://www.manning.com/books/deep-learning-with-r</a>.
</div>
<div id="ref-R-googleLanguageR" class="csl-entry">
Edmondson, M. 2020. <em><span class="nocase">googleLanguageR</span>: Call Google’s <span>‘Natural Language’</span> API, <span>‘Cloud Translation’</span> API, <span>‘Cloud Speech’</span> API and <span>‘Cloud Text-to-Speech’</span> API</em>. R package version 0.3.0. <a href="https://CRAN.R-project.org/package=googleLanguageR">https://CRAN.R-project.org/package=googleLanguageR</a>.
</div>
<div id="ref-textrecipes" class="csl-entry">
Hvitfeldt, E. 2020a. <em><span class="nocase">textrecipes</span>: Extra <span>‘Recipes’</span> for Text Processing</em>. R package version 0.4.1. <a href="https://CRAN.R-project.org/package=textrecipes">https://CRAN.R-project.org/package=textrecipes</a>.
</div>
<div id="ref-James2013" class="csl-entry">
James, G., Witten, D., Hastie, T., and Tibshirani, R. 2013. <em>An Introduction to Statistical Learning</em>. New York: Springer.
</div>
<div id="ref-R-pdftools" class="csl-entry">
Ooms, J. 2020a. <em><span class="nocase">pdftools</span>: Text Extraction, Rendering and Converting of PDF Documents</em>. R package version 2.3.1. <a href="https://CRAN.R-project.org/package=pdftools">https://CRAN.R-project.org/package=pdftools</a>.
</div>
<div id="ref-Silge2017" class="csl-entry">
Silge, J., and Robinson, D. 2017. <em>Text Mining with <span>R</span>: A Tidy Approach</em>. Sebastopol: O’Reilly Media, Inc.
</div>
<div id="ref-R-httr" class="csl-entry">
Wickham, H. 2020. <em><span class="nocase">httr</span>: Tools for Working with URLs and HTTP</em>. R package version 1.4.2. <a href="https://CRAN.R-project.org/package=httr">https://CRAN.R-project.org/package=httr</a>.
</div>
<div id="ref-Wickham2019" class="csl-entry">
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., et al. 2019. <span>“Welcome to the Tidyverse.”</span> <em>Journal of Open Source Software</em> 4 (43). The Open Journal: 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div>
<div id="ref-Wickham2017" class="csl-entry">
Wickham, H., and Grolemund, G. 2017. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. Sebastopol: O’Reilly Media, Inc.
</div>
<div id="ref-R-readr" class="csl-entry">
Wickham, H., and Hester, J. 2020. <em><span class="nocase">readr</span>: Read Rectangular Text Data</em>. R package version 1.4.0. <a href="https://CRAN.R-project.org/package=readr">https://CRAN.R-project.org/package=readr</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="language.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": null,
"edit": {
"link": "https://github.com/EmilHvitfeldt/smltar/edit/master/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
